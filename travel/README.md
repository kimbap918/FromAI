# 여행 & 날씨 기사 생성기

## 1. 프로젝트 개요

이 프로젝트는 전국 여행지 데이터를 수집하고, 수집된 데이터와 실시간 날씨 정보를 바탕으로 AI를 통해 여행 및 날씨 관련 기사를 생성하는 데스크톱 애플리케이션입니다.

프로젝트는 크게 두 가지 주요 부분으로 구성됩니다.
1.  데이터 크롤러: 전국의 법정동 정보를 기반으로 네이버 지도의 장소 정보를 수집하여 데이터베이스를 구축합니다. (`crawl_main.py`)
2.  GUI 애플리케이션: 구축된 데이터를 활용하여 사용자가 원하는 조건의 여행지를 필터링하고, AI를 통해 기사를 생성하는 PyQt5 기반 프로그램입니다. (`article_generator_app.py`)

## 2. 주요 기능

### 데이터 수집
- 전국 법정동 CSV 파일을 기반으로 지역별 검색어 자동 생성
- Selenium을 이용해 네이버 지도에서 장소 정보(주소, 카테고리, 리뷰 수, 소개 등) 크롤링
- 수집된 데이터를 SQLite 데이터베이스에 저장 및 관리 (중복 방지 포함)
- 크롤링 진행 상황을 JSON 파일로 관리하여 중단 시 이어하기 기능 제공

### 기사 생성 애플리케이션
- 여행지 검색 및 필터링
  - 다단계 지역 필터 (도/시/군/구/동) 및 자동완성 검색 기능
  - 장소 카테고리 및 방문자 리뷰 키워드 기반의 상세 필터링
  - 리뷰 수, 이름, 주소 등 다양한 기준으로 결과 정렬
- AI 기사 생성
  - Google Gemini API를 활용한 자연스러운 여행 기사 자동 생성
  - 기사 생성 전, 선택한 장소의 최신 정보를 실시간으로 다시 크롤링하여 반영
  - 기사 내용에 현재 날씨 정보를 선택적으로 포함하는 기능
- 날씨 정보 및 기사
  - 기상청 API와 연동하여 전국 모든 지역의 상세 날씨 및 기상특보 조회
  - 조회된 날씨 데이터를 바탕으로 AI 날씨 기사 생성

## 3. 기술 스택

- GUI: PyQt5
- AI: Google Gemini
- 웹 크롤링: Selenium
- 데이터베이스: SQLite
- API 연동: 카카오 API, 기상청 공공데이터 API

## 4. 설치 및 설정

### 사전 요구사항
- Python 3.8 이상
- Google Chrome 브라우저

### 설치 과정
1.  가상환경 생성 (권장)
    ```bash
    python -m venv venv
    # Windows
    venv\Scripts\activate
    # macOS/Linux
    source venv/bin/activate
    ```

2.  의존성 설치
    ```bash
    pip install -r requirements.txt
    ```

### 환경변수 설정 (`.env`)
프로젝트 루트 폴더에 `.env` 파일을 생성하고 아래의 API 키를 입력합니다. 각 API 키는 해당 서비스의 개발자 센터에서 발급받을 수 있습니다.

```env
# Google Gemini AI API (기사 생성에 필수)
GOOGLE_API_KEY="발급받은 Google API 키"

# 카카오 API (날씨 조회 기능에 필요)
KAKAO_API_KEY="발급받은 Kakao API 키"

# 기상청 API (날씨 조회 기능에 필요)
KMA_API_KEY="발급받은 기상청 API 키"
```

## 5. 사용 방법

### 1단계: 데이터 수집 (최초 1회 또는 데이터 업데이트 시 실행)
애플리케이션을 사용하기 전에 여행지 데이터베이스를 구축해야 합니다.

1.  `crw_data` 폴더에 `전국 법정동.csv` 파일이 있는지 확인합니다.
2.  아래 명령어를 실행하여 데이터 수집을 시작합니다.
    ```bash
    python crawl_main.py
    ```
    - 크롤링은 시간이 오래 걸릴 수 있으며, 중간에 중단해도 `crawling_progress.json` 파일에 진행 상황이 저장되어 자동으로 이어집니다.
    - 완료되면 `crw_data` 폴더에 `naver_travel_places.db` 파일이 생성됩니다.

### 2단계: 기사 생성기 실행
데이터베이스 구축이 완료된 후, 메인 애플리케이션을 실행합니다.

```bash
python article_generator_app.py
```

## 6. 프로젝트 구조

- 메인 실행 및 데이터 수집
  - `article_generator_app.py`: PyQt5 애플리케이션의 메인 실행 파일. UI를 초기화하고 '여행' 및 '날씨' 탭을 생성하며, 데이터베이스, 챗봇, API 등 모든 구성 요소를 연결합니다.
  - `crawl_main.py`: 대규모 데이터 수집을 위한 메인 크롤러. '전국법정동.csv' 파일을 기반으로 검색어를 생성하고, Selenium을 이용해 네이버 지도에서 장소 정보를 수집하여 SQLite DB에 저장합니다. 크롤링 중단 시 이어하기 기능이 포함되어 있습니다.

- 핵심 기능: 여행 기사
  - `travel_tab.py`: '여행지 검색' 탭의 UI 이벤트를 처리하는 컨트롤러. 필터 변경, 검색, 기사 생성 등 사용자 요청을 받아 `travel_logic.py`에 전달하고 UI를 업데이트합니다.
  - `travel_logic.py`: 여행 관련 핵심 비즈니스 로직. UI와 독립적으로 동작하며, 복잡한 조건(지역, 카테고리, 리뷰)에 따른 장소 필터링 및 검색을 수행합니다. 또한, 실시간 크롤링 및 기사 생성을 백그라운드 스레드로 처리하여 UI 응답성을 유지합니다.
  - `chatbot_app.py`: Google Gemini API를 사용하여 여행 기사를 생성하는 모듈. 사용자 검색어, 선택된 장소 목록, 날씨 정보를 조합하여 상세한 프롬프트를 구성하고 AI를 호출합니다.
  - `prompts.py`: AI 여행 기사 생성을 위한 프롬프트 템플릿. AI의 역할, 기사 스타일, 준수 규칙 등을 상세히 정의하여 일관된 품질의 결과물을 생성하도록 유도합니다.
  - `realtime_crawler.py`: 기사 생성 직전, 특정 장소의 최신 '소개' 정보만 실시간으로 다시 수집하는 경량 크롤러. 정보의 최신성을 보장하며, 크롤링 차단 방지 기술이 적용되어 있습니다.

- 핵심 기능: 날씨 기사
  - `weather_tab.py`: '상세 날씨 조회' 탭의 UI를 제어하는 컨트롤러. 지역별 날씨 검색, 전국 기상특보 조회를 처리하고, `weather_api.py`와 `weather_ai_generator.py`를 호출하여 결과를 화면에 표시합니다.
  - `weather_api.py`: 날씨 데이터를 수집하는 모듈. 카카오 API로 입력된 지역명을 좌표로 변환한 뒤, 기상청 격자 좌표로 다시 변환하여 기상청 API를 호출합니다. 초단기실황과 단기예보 데이터를 조합하여 종합적인 날씨 정보를 생성합니다.
  - `weather_warning.py`: 기상청의 전국 기상특보를 조회하고 파싱하는 전용 모듈. 복잡한 단일 텍스트로 제공되는 전국 특보를 개별 특보(종류, 해당 지역) 목록으로 구조화하는 핵심 로직을 포함합니다.
  - `weather_ai_generator.py`: 날씨 데이터를 기반으로 AI 날씨 기사를 생성합니다. 일반 날씨 정보 또는 기상특보 상황에 맞춰 각각 다른 스타일의 기사를 생성하며, 동일한 특보에 대한 중복 기사 생성을 방지하는 순환 로직을 갖추고 있습니다.
  - `weather_article_prompts.py`: AI 날씨 기사 생성에 특화된 프롬프트 템플릿 모음. 일반 날씨와 기상특보 상황에 맞는 별도의 프롬프트를 제공하여, 각 시나리오에 최적화된 기사를 생성하도록 합니다.

- UI 및 공용 컴포넌트
  - `travel_ui.py`: '여행지 검색' 탭의 UI 레이아웃을 정의하는 View 역할의 파일. 위젯의 배치와 형태 등 순수 시각적 구조만 담당하며, 기능 로직은 포함하지 않습니다.
  - `ui_components.py`: 앱 전반에서 재사용되는 커스텀 PyQt5 위젯 모음. 다중 선택이 가능한 콤보박스(`CheckableComboBox`), 숫자 데이터의 올바른 정렬을 지원하는 테이블 아이템(`IntItem`) 등이 포함되어 있습니다.

- 유틸리티 및 설정
  - `db_manager.py`: SQLite 데이터베이스와의 모든 상호작용을 관리하는 데이터 접근 계층. DB 초기화, 데이터 저장 및 계층적 지역 검색 등 복잡한 쿼리를 수행하는 함수들을 제공합니다.
  - `category_utils.py`: 네이버 지도의 다양한 장소 카테고리를 표준화된 UI용 카테고리로 통합하는 유틸리티. 키워드 매칭을 통해 필터링 효율을 높입니다.
  - `visitor_reviews_utils.py`: '주차하기 편해요'와 같은 방문자 리뷰 키워드를 '접근성/편의성' 등 표준화된 태그로 변환하여, 리뷰 기반 필터링을 가능하게 합니다.
  - `config.py`: API 키, URL 등 프로젝트의 전역 설정을 관리합니다. `.env` 파일에서 민감한 정보를 안전하게 로드하여 코드와 분리합니다.
  - `data.py`: 대한민국 행정구역 목록이나 지역명 축약어 등, 코드 내에서 사용되는 정적 데이터를 보관합니다.

- 기타 스크립트
  - `crw_data/brand_remove.py`: 데이터 정제용 보조 스크립트. 수집된 DB에서 '스타벅스'와 같이 여행지에 해당하지 않는 프랜차이즈 브랜드 데이터를 삭제하는 역할을 합니다.

## 7. 개발자

- 하승주, 홍석원
