import os
import sys
import json
import re
import time  
import google.generativeai as genai
from news.src.utils.common_utils import get_today_kst_str
from dotenv import load_dotenv
from datetime import datetime
from pathlib import Path
import logging

try:
    from news.src.utils.article_utils import extract_publish_datetime
except Exception:
    extract_publish_datetime = None
# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë‹¤ì–‘í•œ ì‹¤í–‰ í™˜ê²½(.py, PyInstaller)ì—ì„œ .env íŒŒì¼ ë¡œë“œ
# ------------------------------------------------------------------
def _ensure_env_loaded():
    """
    GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì—¬ëŸ¬ ì˜ˆìƒ ê²½ë¡œì—ì„œ .env íŒŒì¼ì„ ì°¾ì•„ ë¡œë“œ
    """
    if os.getenv("GOOGLE_API_KEY"):
        return
    
    if getattr(sys, "frozen", False):
        search_paths = [
            os.path.dirname(sys.executable),
            os.path.join(os.path.expanduser("~"), "Desktop"),
            os.path.join(os.getenv("APPDATA", ""), "NewsGenerator"),
            os.getcwd(),
        ]
        meipass = getattr(sys, "_MEIPASS", None)
        if meipass:
            search_paths.insert(0, meipass)
        for path in search_paths:
            if path and os.path.exists(path):
                env_path = os.path.join(path, ".env")
                if os.path.exists(env_path):
                    load_dotenv(env_path)
                    if os.getenv("GOOGLE_API_KEY"):
                        print(f"âœ… .env íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {env_path}")
                        return
    else:
        load_dotenv()
        if os.getenv("GOOGLE_API_KEY"):
            return
        module_dir = os.path.dirname(__file__)
        load_dotenv(os.path.join(module_dir, ".env"))
        if os.getenv("GOOGLE_API_KEY"):
            return
        if getattr(sys, "frozen", False):
            exe_dir = os.path.dirname(sys.executable)
            load_dotenv(os.path.join(exe_dir, ".env"))
            if os.getenv("GOOGLE_API_KEY"):
                return
        meipass = getattr(sys, "_MEIPASS", None)
        if meipass:
            load_dotenv(os.path.join(meipass, ".env"))

_ensure_env_loaded()

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError(".envì—ì„œ GOOGLE_API_KEYë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
genai.configure(api_key=api_key)

model = genai.GenerativeModel("gemini-2.5-flash")


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì•ˆì „í•œ ë¬¸ìì—´ë¡œ í‚¤ì›Œë“œë¥¼ ë³€í™˜
# ------------------------------------------------------------------
def _safe_keyword(name: str) -> str:
    """
    ë¬¸ìì—´ì—ì„œ ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±, í•˜ì´í”ˆ, ì–¸ë”ìŠ¤ì½”ì–´ë§Œ ë‚¨ê¸°ê³  ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
    :param name: ì›ë³¸ ë¬¸ìì—´
    :return: íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ìì—´
    """
    name = "".join(c for c in name if c.isalnum() or c in (" ", "-", "_")).strip()
    return name.replace(" ", "_") or "log"

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : í”„ë¡œê·¸ë¨ì˜ ê¸°ë³¸ ì‹¤í–‰ ë””ë ‰í† ë¦¬ ê²½ë¡œ íšë“
# ------------------------------------------------------------------
def _get_base_dir() -> Path:
    """
    ê°œë°œ í™˜ê²½ê³¼ PyInstaller ë¹Œë“œ í™˜ê²½ì„ êµ¬ë¶„í•˜ì—¬ ë¡œê·¸ íŒŒì¼ ë“±ì„ ì €ì¥í•  ê¸°ë³¸ ê²½ë¡œë¥¼ ë°˜í™˜
    :return: ê¸°ë³¸ ë””ë ‰í† ë¦¬ì˜ Path ê°ì²´
    """
    if getattr(sys, "frozen", False):
        return Path(sys.executable).parent
    return Path.cwd()

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ê³¼ì •ì„ ê¸°ë¡í•  ë¡œê±°(Logger) ì„¤ì •
# ------------------------------------------------------------------
def setup_check_logging(keyword: str) -> tuple[logging.Logger, str]:
    """
    'ê¸°ì‚¬ ì¬ìƒì„±' í´ë” ë‚´ì— ì˜¤ëŠ˜ ë‚ ì§œì˜ í´ë”ë¥¼ ë§Œë“¤ê³ , í‚¤ì›Œë“œë¥¼ íŒŒì¼ëª…ìœ¼ë¡œ í•˜ëŠ” ë¡œê·¸ íŒŒì¼ì„ ì„¤ì •
    ê¸°ì¡´ news_LLM ë¡œê·¸ íŒŒì¼ì— ì´ì–´ì„œ ê¸°ë¡(mode="a")
    :param keyword: ë¡œê·¸ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  í‚¤ì›Œë“œ
    :return: ì„¤ì •ëœ ë¡œê±° ê°ì²´ì™€ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    """
    current_date = datetime.now().strftime("%Y%m%d")
    base_dir = _get_base_dir()
    log_dir = base_dir / "ê¸°ì‚¬ ì¬ìƒì„±" / f"ì¬ìƒì„±{current_date}"
    log_dir.mkdir(parents=True, exist_ok=True)

    safe_keyword = _safe_keyword(keyword)
    log_filepath = str(log_dir / f"{safe_keyword}.txt")

    logger_name = f"check_llm_{safe_keyword}"
    logger = logging.getLogger(logger_name)
    logger.setLevel(logging.INFO)

    if not logger.handlers:
        fh = logging.FileHandler(log_filepath, encoding="utf-8", mode="a")
        fh.setLevel(logging.INFO)
        fh.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)
        ch.setFormatter(logging.Formatter("%(message)s"))

        logger.addHandler(fh)
        logger.addHandler(ch)

    return logger, log_filepath

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë©”ì‹œì§€ë¥¼ ë¡œê±°ì™€ ì½˜ì†”ì— ë™ì‹œ ì¶œë ¥
# ------------------------------------------------------------------
def log_and_print(logger, message: str, level: str = "info"):
    """
    ì£¼ì–´ì§„ ë©”ì‹œì§€ë¥¼ ì§€ì •ëœ ë¡œê·¸ ë ˆë²¨ë¡œ íŒŒì¼ê³¼ ì½˜ì†”ì— ê¸°ë¡
    :param logger: ì‚¬ìš©í•  ë¡œê±° ê°ì²´
    :param message: ê¸°ë¡í•  ë©”ì‹œì§€
    :param level: ë¡œê·¸ ë ˆë²¨ ('info', 'warning', 'error', 'debug')
    """
    if level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "debug":
        logger.debug(message)


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
# ------------------------------------------------------------------
def generate_check_prompt(keyword: str = "", published_kst: str | None = None) -> str:
    today_kst = get_today_kst_str()
    keyword_info = f"- í‚¤ì›Œë“œ: {keyword}\n" if keyword else ""
    published_line = (
        f"- ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): {published_kst}\n"
        if (published_kst and str(published_kst).strip())
        else "- ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): í™•ì¸ ë¶ˆê°€\n"
    )

    prompt = f"""
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‘ ê°œì˜ ê¸°ì‚¬('ìƒì„±ëœ ê¸°ì‚¬'ì™€ 'ì›ë¬¸ ê¸°ì‚¬')ë¥¼ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ë¥¼ íŒë‹¨í•˜ë¼.
        ì‚¬ìš©ìëŠ” '=' êµ¬ë¶„ì„ ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ê¸°ì‚¬ë¥¼ êµ¬ë¶„í•˜ë©°, ì²« ë²ˆì§¸ê°€ 'ìƒì„±ëœ ê¸°ì‚¬', ë‘ ë²ˆì§¸ê°€ 'ì›ë¬¸ ê¸°ì‚¬'ì´ë‹¤.

        [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]
        - ì˜¤ëŠ˜ ë‚ ì§œ(Asia/Seoul): {today_kst}
        - ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): {published_line}

        [í‚¤ì›Œë“œ]
        {keyword_info}

        [íŒì • ì›ì¹™]
        - ë‚´ë¶€ì ìœ¼ë¡œ ì´ìŠˆë¥¼ 'ê²½ë¯¸'ì™€ 'ì¤‘ëŒ€'ë¡œ êµ¬ë¶„í•˜ë˜, JSONì˜ verdictëŠ” ë‹¤ìŒì„ ë”°ë¥¸ë‹¤.
        * ê²½ë¯¸ ì´ìŠˆë§Œ ìˆëŠ” ê²½ìš° â†’ "OK" (ì¬ì‘ì„± ìœ ë„ ê¸ˆì§€)
        * ì¤‘ëŒ€ ì´ìŠˆê°€ 1ê°œ ì´ìƒì¸ ê²½ìš° â†’ "ERROR" (í•„ìš” ìµœì†Œ ìˆ˜ì • í¬í•¨)
        - 'ê²½ë¯¸'ëŠ” ì‚¬ì‹¤ ì™œê³¡ì´ ì—†ê³ , ì˜ë¯¸Â·ìˆ˜ì¹˜Â·ë‚ ì§œÂ·ì¸ìš©Â·ê³ ìœ ëª…ì‚¬ ì •í•©ì„±ì— ì˜í–¥ì´ ì—†ëŠ” í¸ì§‘/í‘œí˜„ ì°¨ì´ë¥¼ ë§í•œë‹¤.
        - 'ì¤‘ëŒ€'ëŠ” ì‚¬ì‹¤ ì™œê³¡Â·ì¶”ê°€ ì‚¬ì‹¤ ì‚½ì…Â·í•µì‹¬ ìˆ˜ì¹˜/ë‚ ì§œ/ê³ ìœ ëª…ì‚¬/ì§í•¨/ì¸ìš© ë³€ê²½, ë¶ˆí™•ì •ì„ ë‹¨ì •ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤.

        [ë¹„êµ ê¸°ì¤€]
        - ì™„ì „íˆ ë™ì¼í•˜ê±°ë‚˜ ì˜ë¯¸ê°€ ë™ì¼ â†’ "âœ… ì‚¬ì‹¤ê´€ê³„ì— ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤."
        - í‘œí˜„ ë°©ì‹ë§Œ ë‹¤ë¥´ë©° ì˜ë¯¸ ë™ì¼ â†’ "âœ… í‘œí˜„ ë°©ì‹ì´ ë‹¤ë¥´ì§€ë§Œ, ì‚¬ì‹¤ê´€ê³„ëŠ” ì¼ì¹˜í•©ë‹ˆë‹¤."
        - ì¼ë¶€ ë‚´ìš©ì´ ë‹¤ë¥´ê±°ë‚˜ ë¹ ì¡Œìœ¼ë‚˜ í•µì‹¬ ì‚¬ì‹¤ ìœ ì§€(ê²½ë¯¸) â†’ ìƒê¸° ë©”ì‹œì§€ ì¤‘ í•˜ë‚˜ë¡œ í†µê³¼(OK).
        - ëª…í™•í•œ ì˜¤ë¥˜(ì¤‘ëŒ€)ê°€ ìˆëŠ” ê²½ìš° â†’ "âŒ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤." + ì–´ë–¤ ë¶€ë¶„ì´ í‹€ë ¸ëŠ”ì§€ ì„¤ëª…í•˜ê³  ERROR.

        [ê²½ë¯¸ ì´ìŠˆ(OK ì²˜ë¦¬) ì˜ˆì‹œ]
        - ë¬¸ì¥ ìˆœì„œ ë³€ê²½, ìš”ì•½Â·ì••ì¶•Â·ì¤‘ë³µ ì œê±°(í•µì‹¬ ì˜ë¯¸ ë³´ì¡´ ì‹œ)
        - ì¸ìš©ë¬¸ì˜ ë”°ì˜´í‘œ ì¢…ë¥˜Â·ë¬¸ì¥ë¶€í˜¸ ì°¨ì´(ë‹¨ì–´Â·í™”ì ë™ì¼ ì‹œ)
        - ìˆ«ì ìë¦¬ìˆ˜ í‘œê¸°Â·í¼ì„¼íŠ¸ ë°˜ì˜¬ë¦¼/ë‚´ë¦¼ ë“± ê²½ë¯¸í•œ í‘œê¸° ì°¨(ì •í™•í•œ ìˆ˜ì¹˜ê°€ ë³€í•˜ì§€ ì•ŠëŠ” ë²”ìœ„)
        - ë³¸ë¬¸ ê¸¸ì´ 260~880ì ë²”ìœ„ ë‚´ì˜ ê²½ë¯¸í•œ í¸ì°¨(ê°€ë…ì„± ëª©ì ì˜ ìƒëµ/ì••ì¶• í¬í•¨)
        - í•´ì‹œíƒœê·¸ê°€ 2~6ê°œ ë²”ìœ„ì˜ ê²½ë¯¸í•œ í¸ì°¨(ì¶”ì •/í—ˆìœ„ íƒœê·¸ë§Œ ì•„ë‹ˆë¼ë©´)
        - ë™ì¼ ì˜ë¯¸ì˜ ì‹œì œÂ·ìƒëŒ€ì‹œì  í‘œí˜„(â€˜ì§€ë‚œ/ì˜¤ëŠ”/ì´ë‚ /ìµœê·¼/ì´ì „â€™ ë“±) ë° ë‚ ì§œ ë…¸ì¶œ ìƒëµ
        - ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´Â·ê°€ì¹˜ íŒë‹¨ì–´ ì œê±° ë˜ëŠ” ì™„í™”(ì‚¬ì‹¤ ì™œê³¡ì´ ì—†ì„ ë•Œ)

        [ì¤‘ëŒ€ ì´ìŠˆ(ERROR ì²˜ë¦¬) ì˜ˆì‹œ]
        - ì›ë¬¸ì— ì—†ëŠ” ì‚¬ì‹¤/ìˆ˜ì¹˜/ë‚ ì§œ/ì¸ë¬¼Â·ì§í•¨Â·ì§€ëª…Â·ì œí’ˆ ì¶”ê°€
        - ì›ë¬¸ì˜ ë¶ˆí™•ì •(ì˜ˆì •/ì¶”ì§„/ê°€ëŠ¥ì„±)ì„ ë‹¨ì •ìœ¼ë¡œ ë³€ê²½
        - í•µì‹¬ ìˆ˜ì¹˜Â·ë‚ ì§œÂ·ì¸ë¬¼Â·ì§í•¨Â·ê³ ìœ ëª…ì‚¬Â·ì¸ìš©ë¬¸(ë‹¨ì–´/í™”ì) ë³€ê²½ ë˜ëŠ” ëˆ„ë½ìœ¼ë¡œ ì˜ë¯¸ê°€ ë°”ë€ŒëŠ” ê²½ìš°
        - ì‚¬ê±´ì˜ ì‹œì ì„ ì˜ëª» ë°”ê¿” ì˜ë¯¸ë¥¼ ì™œê³¡(ê³¼ê±°â†”í˜„ì¬â†”ë¯¸ë˜ í˜¼ë™)
        - ì›ë¬¸ í•µì‹¬ ì£¼ì¥Â·ê²°ë¡ ì˜ ë°˜ì „/ì™œê³¡

        [ì‹œì œ/ë‚ ì§œ í—ˆìš© ê·œì¹™(ì˜¤ë¥˜ ì•„ë‹˜)]
        1) 'ì§€ë‚œ Oì›”/OOì¼/OOOOë…„', 'ì˜¤ëŠ” Oì›”/OOì¼/OOOOë…„' ë“± ìƒëŒ€ ì‹œì  í‘œí˜„
        2) 'ì´ë‚ ', 'ì˜¤ëŠ˜' ë“± ë¶ˆí•„ìš”í•œ ì‹œì  ìƒëµ
        3) ë°©ì†¡Â·í–‰ì‚¬ ë“± ë³µìˆ˜ ì¼ì ì¤‘ **ê°€ì¥ ìµœê·¼** ê¸°ì¤€ ì„œìˆ 
        4) [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ê³¼ ë¹„êµí•´ ê³¼ê±°/ë¯¸ë˜ë¥¼ ì •í™•íˆ ë°˜ì˜í•œ ì‹œì œ ì¡°ì •
        5) ì›ë¬¸ ë°œí–‰ì¼ì´ ë” ê³¼ê±°ì¸ ê²½ìš° ê³¼ê±° ì‹œì œë¡œ í†µì¼

        [ì˜ˆì™¸ ì‚¬í•­ - ì‚¬ì‹¤ ì˜¤ë¥˜ë¡œ ê°„ì£¼í•˜ì§€ ë§ ê²ƒ]
        - ë‚ ì§œ í‘œê¸° í˜•ì‹ë§Œ ë‹¤ë¥¸ ê²½ìš°(ì˜ˆ: '2025-09-16' â†” '9ì›” 16ì¼' â†” '16ì¼')
        - ì„œìˆ  ì–´ë¯¸/ë¬¸ì²´ í†µì¼(ì´ë‹¤/í–ˆë‹¤/í•œë‹¤)ë¡œì˜ ë³€ê²½
        - ë§í¬Â·ì‚¬ì§„ ìº¡ì…˜Â·SNS ì„ë² ë“œÂ·ì €ì‘ê¶Œ ê³ ì§€ ë“± ë¹„í•µì‹¬ ë©”íƒ€ìš”ì†Œì˜ ì¶”ê°€/ì œê±°
        - ê³ ìœ ëª…ì‚¬ í‘œê¸° ì°¨ì´(ë„ì–´ì“°ê¸°/í•˜ì´í”ˆ/ì¤‘ì /ëŒ€ì†Œë¬¸ì/í•œì˜ ë³€í™˜)ë¡œ ì¸í•œ **ë™ì¼ ì£¼ì²´** í‘œê¸° êµì²´
        - ì§í•¨Â·ê¸°ê´€ ì•½ì¹­ ì‚¬ìš©(ì˜ˆ: 'ì„œìš¸ì¤‘ì•™ì§€ë°©ë²•ì›' â†” 'ì„œìš¸ì¤‘ì•™ì§€ë²•', 'ëŒ€í‘œì´ì‚¬' â†” 'ëŒ€í‘œ') â€” ì˜ë¯¸ ë™ì¼ ì‹œ
        - ì œí’ˆ/ì„œë¹„ìŠ¤ëª… ë’¤ ë³´ì¡°ì–´(ì•±/í”Œë«í¼/ì„œë¹„ìŠ¤ ë“±) ìƒëµ ë˜ëŠ” ë¶€ê°€ â€” ì£¼ì²´ ë™ì¼Â·í˜¼ë™ ì—†ìŒ
        - ë‹¨ìœ„Â·ê¸°í˜¸ í‘œê¸°ë§Œ ë‹¤ë¥¸ ê²½ìš°(ì˜ˆ: â„ƒ â†” ë„, km â†” í‚¬ë¡œë¯¸í„°, ì› â†” KRW) â€” **ìˆ˜ì¹˜ê°’ ë¶ˆë³€**
        - ì²œ ë‹¨ìœ„ êµ¬ë¶„ê¸°í˜¸Â·ê³µë°±Â·ì–µ/ë§Œ í™˜ì‚° ë“± í‘œê¸° ì°¨ â€” **ê°’ ë™ì¼**ì¼ ë•Œ
        - ì œëª©ì˜ ìš”ì•½Â·ê°„ê²°í™”Â·ì–´ìˆœ ì¡°ì • â€” ì˜ë¯¸ ë™ì¼ ì‹œ
        - [ì œëª©]/[í•´ì‹œíƒœê·¸]ì— ì‚¬ìš©ìê°€ ì…ë ¥í•œ [í‚¤ì›Œë“œ]ì˜ í¬í•¨/ë¯¸í¬í•¨ **ë§Œìœ¼ë¡œ** ì˜¤ë¥˜ íŒë‹¨ ê¸ˆì§€

        [ì ê²€ ì‚¬í•­]
        1) ë¹„êµëŠ” ì˜¤ë¡œì§€ 'ì›ë¬¸ ê¸°ì‚¬' ë‚´ìš©ì— í•œì •í•œë‹¤(ì™¸ë¶€ ì •ë³´ ê¸ˆì§€).
        2) ì¸ë¬¼ ì§í•¨/íšŒì‚¬ëª…/ì œí’ˆ/ì„œë¹„ìŠ¤/ìˆ˜ì¹˜/ë‚ ì§œ/ì§€ëª…/ì¸ìš©ë¬¸ì€ ì›ë¬¸ê³¼ ì¼ì¹˜í•´ì•¼ í•œë‹¤.
        3) ì›ë¬¸ì— ì—†ëŠ” ì •ë³´ê°€ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆì—ˆìœ¼ë©´ 'í—ˆìœ„ ì •ë³´'ë¡œ ê°„ì£¼(ì¤‘ëŒ€).
        4) ë¶ˆí™•ì • í‘œí˜„ì„ ë‹¨ì •ìœ¼ë¡œ ë°”ê¾¸ì—ˆëŠ”ì§€ í™•ì¸(ì¤‘ëŒ€).
        5) ê°„ê²°í•´ì ¸ë„ í•µì‹¬ ì˜ë¯¸ê°€ ë³´ì¡´ë˜ë©´ ê²½ë¯¸ë¡œ ë³¸ë‹¤(OK).
        6) ê¸¸ì´Â·í•´ì‹œíƒœê·¸ ê°œìˆ˜ëŠ” **ê¶Œê³  ê¸°ì¤€**ìœ¼ë¡œ ë³´ë˜, ê³¼ë„í•œ ì¼íƒˆ(ì˜ˆ: 200ì ë¯¸ë§Œ, 1000ì ì´ˆê³¼, í•´ì‹œíƒœê·¸ 3ê°œ ì´í•˜/7ê°œ ì´ìƒ)ì€ í’ˆì§ˆ ì €í•˜ë¡œë§Œ ì§€ì í•˜ë¼(ê°€ëŠ¥í•˜ë©´ OK ìœ ì§€).
        7) ì œëª©/í•´ì‹œíƒœê·¸ê°€ ì›ë¬¸ê³¼ ë¶ˆì¼ì¹˜í•˜ë”ë¼ë„ ì‚¬ì‹¤ ì™œê³¡ì´ ì•„ë‹ˆë©´ ê²½ë¯¸ë¡œ ê°„ì£¼í•œë‹¤. ë‹¨, í—ˆìœ„Â·ì¶”ì • íƒœê·¸ëŠ” ì¤‘ëŒ€.
        8) ì œëª©ì´ë‚˜ í•´ì‹œíƒœê·¸ê°€ ì›ë¬¸ê³¼ ë¶ˆì¼ì¹˜í•˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš°ì— ë‹¨ìˆœ ì‚­ì œí•˜ì§€ ë§ê³ , ì›ë¬¸ ê¸°ì‚¬ ë‚´ìš©ì— ë§ëŠ” ì˜¬ë°”ë¥¸ ì œëª©ê³¼ í•´ì‹œíƒœê·¸ë¡œ êµì²´í•˜ì—¬ ë°˜ë“œì‹œ ê¸°ì¡´ì— ìƒì„±ëœ ê°œìˆ˜ë¥¼ ìœ ì§€
        - [ì œëª©] ì„¹ì…˜ì€ í•­ìƒ 3ê°œ ì œëª©ì„ í¬í•¨í•´ì•¼ í•œë‹¤.
        - [í•´ì‹œíƒœê·¸] ì„¹ì…˜ì€ í•­ìƒ 3~5ê°œì˜ í•´ì‹œíƒœê·¸ë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤.

        [ì‘ë‹µ ì •ì±…]
        - 'ì¤‘ëŒ€'ì— í•´ë‹¹í•  ë•Œë§Œ verdict="ERROR"ë¡œ í•˜ê³ , ìµœì†Œ ìˆ˜ì •ë§Œ ë°˜ì˜í•œ corrected_articleì„ ì œê³µí•œë‹¤.
        - 'ê²½ë¯¸'ë§Œ ìˆìœ¼ë©´ verdict="OK"ë¡œ í†µê³¼ì‹œí‚¤ë©° corrected_articleì€ ë¹„ì›Œ ë‘”ë‹¤(ë˜ëŠ” ìƒëµ).
        - nonfactual_phrasesì—ëŠ” **ì¤‘ëŒ€ ì´ìŠˆë§Œ** ë‹´ëŠ”ë‹¤(ê²½ë¯¸ ì´ìŠˆëŠ” ë‹´ì§€ ì•ŠëŠ”ë‹¤).

        [ì‘ë‹µ í˜•ì‹]
        - ì•„ë˜ JSON í•˜ë‚˜ë§Œ ì •í™•íˆ ì¶œë ¥í•˜ë¼(ê·¸ ì™¸ í…ìŠ¤íŠ¸Â·ì„¤ëª…Â·ì¶”ê°€ JSON ê¸ˆì§€)
        - corrected_articleëŠ” 'ì‚¬ì‹¤ì´ ì•„ë‹Œ ë¶€ë¶„ë§Œ ìµœì†Œ ìˆ˜ì •' ì›ì¹™ìœ¼ë¡œ ì‘ì„±í•˜ë¼(ë¶ˆí•„ìš”í•œ ì¬ì„œìˆ  ê¸ˆì§€).
        - corrected_articleëŠ” ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì¶œë ¥í•˜ë¼(ê°ì²´/ë°°ì—´ ê¸ˆì§€), [ì œëª©]/[í•´ì‹œíƒœê·¸]/[ë³¸ë¬¸] ì„¹ì…˜ì„ í¬í•¨í•  ê²ƒ.
        - verdictê°€ "OK"ì¸ ê²½ìš° corrected_articleë¥¼ ë¹„ì›Œë‘ê±°ë‚˜ í‚¤ ìì²´ë¥¼ ìƒëµí•œë‹¤.

        [ìµœì¢… ì¶œë ¥: JSON ì „ìš©]
        {{
        "verdict": "OK" ë˜ëŠ” "ERROR",
        "nonfactual_phrases": [
            {{ "phrase": "ë¬¸ì œ êµ¬ì ˆ1", "reason": "ì´ìœ  ì„¤ëª…" }},
            {{ "phrase": "ë¬¸ì œ êµ¬ì ˆ2", "reason": "ì´ìœ  ì„¤ëª…" }}
        ],
        "corrected_article": "ìˆ˜ì •ëœ ì „ì²´ ê¸°ì‚¬ (ERRORì¼ ë•Œë§Œ, [ì œëª©]/[í•´ì‹œíƒœê·¸]/[ë³¸ë¬¸] í¬í•¨)"
        }}
        """
    return prompt


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ ì¶”ì¶œ
# ------------------------------------------------------------------
def _extract_json_block(text: str):
    """
    LLM ì‘ë‹µì—ì„œ í•˜ë‚˜ ì´ìƒì˜ JSON í›„ë³´ë¥¼ ì°¾ì•„ ê°€ì¥ ì í•©í•œ ê°ì²´(dict)ë¥¼ ë°˜í™˜.

    ì²˜ë¦¬ ìˆœì„œ:
    1) ```json ...``` ì½”ë“œíœìŠ¤ ë‚´ JSON í›„ë³´ ìˆ˜ì§‘(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
    2) ì¼ë°˜ ``` ... ``` ì½”ë“œíœìŠ¤ ë‚´ì—ì„œ { ... } ë¸”ë¡ ìˆ˜ì§‘
    3) ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ê´„í˜¸ ê· í˜•ìœ¼ë¡œ { ... } ë¸”ë¡ ìˆ˜ì§‘(ì •ê·œì‹ í•œê³„ ë³´ì™„)
    4) ëª¨ë“  í›„ë³´ì— ëŒ€í•´ json.loads ì‹œë„ í›„, í•µì‹¬ í‚¤ í¬í•¨ ì—¬ë¶€ë¡œ ìŠ¤ì½”ì–´ë§í•˜ì—¬ ìµœì  í›„ë³´ ì„ íƒ

    :param text: LLMì´ ìƒì„±í•œ ì „ì²´ í…ìŠ¤íŠ¸
    :return: ìµœì ìœ¼ë¡œ íŒë‹¨ëœ dict(JSON ê°ì²´), ì‹¤íŒ¨ ì‹œ None
    """
    if not text:
        return None

    candidates: list[tuple[int, str]] = []  # (priority, payload)

    # 1) ```json ì½”ë“œíœìŠ¤ (ê°€ì¥ ì‹ ë¢°)
    for m in re.finditer(r"```json\s*(\{[\s\S]*?\})\s*```", text, flags=re.I):
        candidates.append((3, m.group(1)))

    # 2) ì¼ë°˜ ì½”ë“œíœìŠ¤ ë‚´ì—ì„œ { ... }ë§Œ ì¶”ì¶œ
    for m in re.finditer(r"```\s*([\s\S]*?)\s*```", text):
        block = m.group(1)
        # ê°„ë‹¨í•œ ì¤‘ê´„í˜¸ ê· í˜• ì¶”ì¶œ
        buf = []
        depth = 0
        start = -1
        for i, ch in enumerate(block):
            if ch == '{':
                if depth == 0:
                    start = i
                depth += 1
            elif ch == '}':
                depth -= 1
                if depth == 0 and start != -1:
                    buf.append(block[start:i+1])
                    start = -1
        for b in buf:
            candidates.append((2, b))

    # 3) ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ê´„í˜¸ ê· í˜• ê¸°ë°˜ ìŠ¤ìº”
    depth = 0
    start = -1
    for i, ch in enumerate(text):
        if ch == '{':
            if depth == 0:
                start = i
            depth += 1
        elif ch == '}':
            if depth > 0:
                depth -= 1
                if depth == 0 and start != -1:
                    candidates.append((1, text[start:i+1]))
                    start = -1

    # ì¤‘ë³µ ì œê±°(ë‚´ìš© ê¸°ì¤€)
    seen = set()
    uniq_candidates: list[tuple[int, str]] = []
    for prio, payload in candidates:
        key = payload.strip()
        if key not in seen:
            seen.add(key)
            uniq_candidates.append((prio, payload))

    # íŒŒì‹± ë° ìŠ¤ì½”ì–´ë§
    best_obj = None
    best_score = -1
    for prio, payload in uniq_candidates:
        try:
            obj = json.loads(payload)
        except Exception:
            continue
        if not isinstance(obj, dict):
            continue
        # í•µì‹¬ í‚¤ ê°€ì¤‘ì¹˜
        score = 0
        score += 3 if 'verdict' in obj else 0
        score += 2 if 'corrected_article' in obj else 0
        score += 1 if 'nonfactual_phrases' in obj else 0
        score += prio  # ì½”ë“œíœìŠ¤ ë“± ì‹ ë¢°ë„ ë°˜ì˜
        if score > best_score:
            best_score = score
            best_obj = obj

    return best_obj

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : LLMì´ ìƒì„±í•œ ë‹¤ì–‘í•œ í˜•íƒœì˜ íŒì •(verdict)ì„ 'OK' ë˜ëŠ” 'ERROR'ë¡œ ì •ê·œí™”
# ------------------------------------------------------------------
def _normalize_verdict(raw: str, json_obj: dict) -> str:
    """
    'âœ…', 'ì¼ì¹˜' ë“±ì˜ ê¸ì • í‘œí˜„ì€ 'OK'ë¡œ, 'âŒ', 'ì˜¤ë¥˜' ë“±ì˜ ë¶€ì • í‘œí˜„ì€ 'ERROR'ë¡œ ë³€í™˜
    :param raw: LLMì´ ìƒì„±í•œ ì›ë³¸ verdict ë¬¸ìì—´
    :param json_obj: nonfactual_phrases ì¡´ì¬ ì—¬ë¶€ í™•ì¸ì„ ìœ„í•œ JSON ê°ì²´
    :return: 'OK' ë˜ëŠ” 'ERROR' ë¬¸ìì—´
    """
    v = (raw or "").strip()
    vu = v.upper()
    if vu in ("OK", "ERROR"):
        return vu
    # ì˜ë¯¸ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±
    if "âœ…" in v or ("ì¼ì¹˜" in v and "ì‚¬ì‹¤" in v):
        return "OK"
    if "âŒ" in v or "ì˜¤ë¥˜" in v or "í‹€ë ¸" in v or "ë‹¤ë¦…" in v:
        return "ERROR"
    if "âš ï¸" in v or "ì£¼ì˜" in v or "ê²½ê³ " in v:
        return "ERROR"
    nf = json_obj.get("nonfactual_phrases") or []
    return "ERROR" if nf else "OK"

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ êµ¬ë¬¸(nonfactual_phrases) ëª©ë¡ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
# ------------------------------------------------------------------
def _normalize_nonfactual(nf) -> list[dict]:
    """
    ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì˜¤ë¥˜ êµ¬ë¬¸ ëª©ë¡ì„ {"phrase": ..., "reason": ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ í†µì¼
    :param nf: LLMì´ ìƒì„±í•œ nonfactual_phrases
    :return: ì •ê·œí™”ëœ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    items = []
    if isinstance(nf, list):
        for it in nf:
            if isinstance(it, dict):
                phrase = str(it.get("phrase") or it.get("ë¬¸ì œ êµ¬ì ˆ") or "").strip()
                reason = str(it.get("reason") or it.get("ì´ìœ ") or "").strip()
            else:
                phrase = str(it).strip()
                reason = ""
            if phrase:
                items.append({"phrase": phrase, "reason": reason})
    return items

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : í…ìŠ¤íŠ¸ì— [ì œëª©], [í•´ì‹œíƒœê·¸], [ë³¸ë¬¸] ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ìµœì†Œí•œì˜ ê¸°ë³¸ í‹€ì„ ìƒì„±í•˜ì—¬ ë³´ì¥
# ------------------------------------------------------------------
def _ensure_sections(text: str) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— í•„ìˆ˜ ì„¹ì…˜ì´ ëˆ„ë½ëœ ê²½ìš°, ê¸°ë³¸ ì œëª©ê³¼ í•´ì‹œíƒœê·¸ë¥¼ ì¶”ê°€í•˜ì—¬ ì™„ì „í•œ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    :param text: ë³´ì •í•  í…ìŠ¤íŠ¸
    :return: ì„¹ì…˜ì´ ë³´ì¥ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        text = ""
    has_title = "[ì œëª©]" in text
    has_tags  = "[í•´ì‹œíƒœê·¸]" in text
    has_body  = "[ë³¸ë¬¸]" in text
    if has_title and has_tags and has_body:
        return text.strip()
    # ë³¸ë¬¸ ì¶”ì •
    body = text
    m = re.search(r"\[ë³¸ë¬¸\]\s*(.*)\Z", text, flags=re.S)
    if m:
        body = m.group(1).strip()
    # ê¸°ë³¸ í‹€ ìƒì„±
    rebuilt = []
    rebuilt.append("[ì œëª©]")
    rebuilt.append("ìˆ˜ì • ê¸°ì‚¬ 1")
    rebuilt.append("ìˆ˜ì • ê¸°ì‚¬ 2")
    rebuilt.append("ìˆ˜ì • ê¸°ì‚¬ 3")
    rebuilt.append("")
    rebuilt.append("[í•´ì‹œíƒœê·¸]")
    # í•´ì‹œíƒœê·¸ í›„ë³´ ì¶”ì¶œ
    candidates = list(dict.fromkeys(re.findall(r"#\S+", text)))[:5]
    if not candidates:
        candidates = ["#ë‰´ìŠ¤", "#ì •ë³´", "#ì‚¬ì‹¤ê²€ì¦"]
    rebuilt.append(" ".join(candidates[:5]))
    rebuilt.append("")
    rebuilt.append("[ë³¸ë¬¸]")
    rebuilt.append(body.strip())
    return "\n".join(rebuilt).strip()

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ìˆ˜ì •ëœ ê¸°ì‚¬ê°€ ì—†ì„ ë•Œ, ì˜¤ë¥˜ êµ¬ì ˆì„ ì›ë³¸ì—ì„œ ì œê±°í•˜ì—¬ ìµœì†Œí•œì˜ ìˆ˜ì •ì„ ìˆ˜í–‰
# ------------------------------------------------------------------
def _auto_minimal_patch(generated_article: str, nonfactual_list: list[dict]) -> str:
    """
    LLMì´ ì˜¤ë¥˜(ERROR)ë¡œ íŒì •í–ˆìœ¼ë‚˜ ìˆ˜ì •ëœ ê¸°ì‚¬ë¥¼ ì œê³µí•˜ì§€ ì•Šì€ ê²½ìš°,
    ê°ì§€ëœ ì˜¤ë¥˜ êµ¬ë¬¸(nonfactual_phrases)ì„ ìƒì„±ëœ ê¸°ì‚¬ì—ì„œ ì‚­ì œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìë™ ìˆ˜ì •
    :param generated_article: LLMì´ ìƒì„±í•œ ì›ë³¸ ê¸°ì‚¬
    :param nonfactual_list: ì‚¬ì‹¤ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ íŒë³„ëœ êµ¬ë¬¸ ë¦¬ìŠ¤íŠ¸
    :return: ìµœì†Œí•œìœ¼ë¡œ ìˆ˜ì •ëœ ê¸°ì‚¬
    """
    if not generated_article:
        return ""
    patched = generated_article
    for item in nonfactual_list:
        phrase = item.get("phrase", "")
        if phrase:
            # ê³¼ê²©í•œ ì¹˜í™˜ ë°©ì§€: ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” êµ¬ì ˆë§Œ ì œê±°
            patched = patched.replace(phrase, "")
    return _ensure_sections(patched)


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ìƒì„±ëœ ê¸°ì‚¬ì™€ ì›ë¬¸ ê¸°ì‚¬ë¥¼ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ë¥¼ ê²€ì¦í•˜ëŠ” ë©”ì¸ ë¡œì§
# ------------------------------------------------------------------
def check_article_facts(
    generated_article: str,
    original_article: str,
    keyword: str = "check_LLM",
    source_url: str | None = None,        # âœ… (2) ì‘ì„±ì¼ì‹œ ì£¼ì…ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¶”ê°€
    published_kst: str | None = None      # âœ… (2) ì™¸ë¶€ì—ì„œ ì§ì ‘ ì „ë‹¬ ê°€ëŠ¥
) -> dict:
    """
    ë‘ ê¸°ì‚¬ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ê³ , ì˜¤ë¥˜ê°€ ìˆì„ ê²½ìš° ìˆ˜ì •ëœ ê¸°ì‚¬ë¥¼ í¬í•¨í•œ JSONì„ ë°˜í™˜
    :param generated_article: news_LLMì´ ìƒì„±í•œ ê¸°ì‚¬
    :param original_article: ì›ë³¸ ê¸°ì‚¬ ë³¸ë¬¸
    :param keyword: ë¡œê¹… ë° í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  í‚¤ì›Œë“œ
    :param source_url: ì›ë¬¸ ê¸°ì‚¬ URL(ìˆë‹¤ë©´ ë°œí–‰ì¼ ì¬ì¶”ì¶œ ì‹œë„)
    :param published_kst: 'YYYY-MM-DD HH:MM' ë“± ê°€ë…í˜• KST ë¬¸ìì—´(ìš°ì„  ì£¼ì…)
    :return: ê²€ì¦ ê²°ê³¼ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ('explanation', 'json', 'error' í¬í•¨)
    """
    logger, log_filepath = setup_check_logging(keyword)

    log_and_print(logger, "\n" + "="*80)
    log_and_print(logger, "ğŸ” CHECK_LLM - ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ì‹œì‘")
    log_and_print(logger, "="*80)
    log_and_print(logger, f"\nğŸ“¥ ì…ë ¥ ë°ì´í„°:")
    log_and_print(logger, f"  - ìƒì„±ëœ ê¸°ì‚¬ ê¸¸ì´: {len(generated_article)}ì")
    log_and_print(logger, f"  - ì›ë¬¸ ê¸°ì‚¬ ê¸¸ì´: {len(original_article)}ì")
    log_and_print(logger, f"  - ë¡œê·¸ íŒŒì¼: {log_filepath}")
    if source_url:
        log_and_print(logger, f"  - source_url: {source_url}")

    # âœ… (2) ì‘ì„±ì¼ì‹œ ì£¼ì…: ìš°ì„ ìˆœìœ„ published_kst ì¸ì â†’ URL ì¶”ì¶œ â†’ ë¯¸í™•ì¸
    published_kst_str = (published_kst or "").strip() or None
    if not published_kst_str and source_url and extract_publish_datetime:
        try:
            dt_raw = extract_publish_datetime(source_url)  # ì˜ˆ: '20250901 08:39' ë˜ëŠ” None
            if dt_raw:
                m = re.match(r"^(\d{4})(\d{2})(\d{2})\s+(\d{2}:\d{2})$", dt_raw)
                published_kst_str = (
                    f"{m.group(1)}-{m.group(2)}-{m.group(3)} {m.group(4)}" if m else dt_raw
                )
                log_and_print(logger, f"  - ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(KST): {published_kst_str}")
        except Exception as e:
            log_and_print(logger, f"  - ì‘ì„±ì¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}", "warning")

    try:
        log_and_print(logger, f"\nğŸ¤– AI ëª¨ë¸ í˜¸ì¶œ:")
        # âœ… (2) í”„ë¡¬í”„íŠ¸ì— ì‘ì„±ì¼ì‹œ ì£¼ì…
        system_prompt = generate_check_prompt(keyword=keyword, published_kst=published_kst_str)
        user_request = (
            f"ìƒì„±ëœ ê¸°ì‚¬: {generated_article}\n" 
            f"=\n" 
            f"ì›ë¬¸ ê¸°ì‚¬: {original_article}"
        )
        log_and_print(logger, f"  - ëª¨ë¸: gemini-2.5-flash")
        log_and_print(logger, f"  - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(system_prompt)}ì")
        log_and_print(logger, f"  - ì‚¬ìš©ì ìš”ì²­ ê¸¸ì´: {len(user_request)}ì")

        log_and_print(logger, f"\nğŸ“‹ ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:")
        log_and_print(logger, f"{'='*80}")
        log_and_print(logger, system_prompt)
        log_and_print(logger, f"{'='*80}")

        log_and_print(logger, f"\nğŸ“‹ ì „ì²´ ì‚¬ìš©ì ìš”ì²­:")
        log_and_print(logger, f"{'='*80}")
        log_and_print(logger, user_request)
        log_and_print(logger, f"{'='*80}")

        contents = [
            {'role': 'user', 'parts': [{'text': system_prompt}]},
            {'role': 'model', 'parts': [{'text': 'ì´í•´í–ˆìŠµë‹ˆë‹¤. ë¹„êµ í›„ JSONë„ í•¨ê»˜ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.'}]},
            {'role': 'user', 'parts': [{'text': user_request}]}
        ]

        log_and_print(logger, f"\nâ³ AI ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
        t0 = time.perf_counter()                     # âœ… (1) ì‹œì‘
        response = model.generate_content(contents)
        rtt = time.perf_counter() - t0               # âœ… (1) ê²½ê³¼

        # í† í° ê³„ì‚°
        usage = getattr(response, "usage_metadata", None)
        if usage:
            p = getattr(usage, "prompt_token_count", 0)
            c = getattr(usage, "candidates_token_count", 0)
            t = getattr(usage, "total_token_count", 0)
            th = getattr(usage, "thoughts_token_count", 0)  # âœ… ì‚¬ê³  í† í°
            tu = getattr(usage, "tool_use_prompt_token_count", 0)
            cc = getattr(usage, "cached_content_token_count", 0)
            resid = t - (p + c + th + tu)  # ë‚¨ëŠ”ë‹¤ë©´ API/ë²„ì „ë³„ ì§‘ê³„ ì°¨ì´
            log_and_print(logger,
                f"ğŸ§¾ í† í° ìƒì„¸ | ì…ë ¥={p}, ì¶œë ¥={c}, ìƒê°={th}, íˆ´í”„ë¡¬í”„íŠ¸={tu}, ìºì‹œ={cc}, í•©ê³„={t}, ì”ì°¨={resid}")
        else:
            log_and_print(logger, "ğŸ§¾ usage_metadata ì—†ìŒ", "warning")    

        full_text = (response.text or "").strip()
        log_and_print(logger, f"  - RTT: {rtt*1000:.0f}ms")  # âœ… (1) ë°€ë¦¬ì´ˆë¡œ ê¸°ë¡

        log_and_print(logger, f"\nğŸ“¤ AI ì‘ë‹µ ê²°ê³¼:")
        log_and_print(logger, f"  - ì‘ë‹µ ê¸¸ì´: {len(full_text)}ì")

        log_and_print(logger, f"\nğŸ“‹ ì „ì²´ AI ì‘ë‹µ:")
        log_and_print(logger, f"{'='*80}")
        log_and_print(logger, full_text)
        log_and_print(logger, f"{'='*80}")

        log_and_print(logger, f"\nğŸ” JSON íŒŒì‹± ì‹œë„:")
        json_obj = _extract_json_block(full_text)

        if not json_obj or "verdict" not in json_obj:
            log_and_print(logger, f"  âŒ JSON íŒŒì‹± ì‹¤íŒ¨", "warning")
            result = {
                "explanation": full_text,
                "json": None,
                "error": "JSON íŒŒì‹± ì‹¤íŒ¨"
            }
        else:
            log_and_print(logger, f"  âœ… JSON íŒŒì‹± ì„±ê³µ")

            # --------- ë³´ì • 1: nonfactual ëª©ë¡ ì •ìƒí™”
            nf = _normalize_nonfactual(json_obj.get("nonfactual_phrases"))
            json_obj["nonfactual_phrases"] = nf

            # --------- ë³´ì • 2: verdict ì •ê·œí™”(OK/ERROR) 
            json_obj["verdict"] = _normalize_verdict(json_obj.get("verdict", ""), json_obj)

            # --------- ë³´ì • 3: corrected_article íƒ€ì…/ì„¹ì…˜ ë³´ì¥ 
            corrected = (json_obj.get("corrected_article", "") or "")
            if isinstance(corrected, dict):
                corrected = "\n".join([
                    "[ì œëª©]",
                    str(corrected.get("title", "")).strip(),
                    "",
                    "[í•´ì‹œíƒœê·¸]",
                    str(corrected.get("hashtags", "")).strip(),
                    "",
                    "[ë³¸ë¬¸]",
                    str(corrected.get("ë³¸ë¬¸", "")).strip(),
                ])
            elif isinstance(corrected, list):
                # ì˜ëª»ëœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì˜¬ ë•ŒëŠ” ë¬¸ìì—´ë¡œ ë³‘í•©
                corrected = "\n".join(str(x) for x in corrected)
            else:
                corrected = str(corrected)

            # ì˜¤ë¥˜ì¸ë° êµì •ë¬¸ì´ ë¹„ì–´ ìˆìœ¼ë©´ ìë™ ìµœì†Œ ë³´ì • ìƒì„±
            if json_obj["verdict"] == "ERROR" and not corrected.strip():
                corrected = _auto_minimal_patch(generated_article, nf)

            # ì„¹ì…˜ ê°•ì œ ë³´ì¥
            corrected = _ensure_sections(corrected) if corrected else corrected
            json_obj["corrected_article"] = corrected

            result = {
                "explanation": full_text,
                "json": json_obj,
                "error": None
            }

        log_and_print(logger, f"\nğŸ“‹ ìµœì¢… ë°˜í™˜ ê²°ê³¼:")
        log_and_print(logger, f"  - explanation ê¸¸ì´: {len(result['explanation'])}ì")
        log_and_print(logger, f"  - json ì¡´ì¬: {result['json'] is not None}")
        
        # Display nonfactual phrases with reasons if they exist
        if result['json'] and 'nonfactual_phrases' in result['json']:
            nonfactual = result['json']['nonfactual_phrases']
            if nonfactual:
                log_and_print(logger, "\nâš ï¸ ë°œê²¬ëœ ì‚¬ì‹¤ ì˜¤ë¥˜ êµ¬ë¬¸:")
                for i, item in enumerate(nonfactual, 1):
                    if isinstance(item, dict):
                        log_and_print(logger, f"  {i}. {item.get('phrase', '')}")
                        log_and_print(logger, f"     â†’ ì´ìœ : {item.get('reason', 'ì‚¬ìœ ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')}")
                    else:
                        log_and_print(logger, f"  {i}. {item}")
                        log_and_print(logger, f"     â†’ ì´ìœ : ìƒì„¸í•œ ì´ìœ ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        log_and_print(logger, f"  - error: {result['error']}")

        log_and_print(logger, f"\nğŸ’¾ ìµœì¢… ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ ì™„ë£Œ")
        log_and_print(logger, f"  - ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_filepath}")

        log_and_print(logger, "\n" + "="*80)
        log_and_print(logger, "ğŸ” CHECK_LLM - ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ì™„ë£Œ")
        log_and_print(logger, "="*80)

        return result

    except Exception as e:
        log_and_print(logger, f"\nâŒ ì˜ˆì™¸ ë°œìƒ: {str(e)}", "error")
        log_and_print(logger, "\n" + "="*80, "error")
        log_and_print(logger, "ğŸ” CHECK_LLM - ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ì‹¤íŒ¨", "error")
        log_and_print(logger, "="*80, "error")

        return {
            "explanation": "",
            "json": None,
            "error": str(e)
        }


if __name__ == "__main__":
    print("ğŸ” ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ë° ìµœì†Œìˆ˜ì • í”„ë¡œê·¸ë¨")
    keyword = input("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë¡œê·¸ íŒŒì¼ëª…ìš©): ").strip()
    generated = input("ìƒì„±ëœ ê¸°ì‚¬(ì œëª©/í•´ì‹œíƒœê·¸/ë³¸ë¬¸ í¬í•¨)ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”: ").strip()
    original = input("ì›ë¬¸ ê¸°ì‚¬ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”: ").strip()

    # ì°¸ê³ : í•„ìš” ì‹œ ì—¬ê¸°ì—ì„œ source_url, published_kstë¥¼ ì¶”ê°€ ì…ë ¥ë°›ì•„ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    result = check_article_facts(generated, original, keyword)
    if result["error"]:
        print("âŒ ì˜¤ë¥˜:", result["error"])
    else:
        print("\n=== ì„¤ëª… ===\n", result["explanation"])
        print("\n=== JSON ===\n", json.dumps(result["json"], ensure_ascii=False, indent=2))
