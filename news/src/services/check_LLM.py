import os
import sys
import json
import re
import time  # âœ… (1) RTT ì¸¡ì •ìš© ì¶”ê°€
import google.generativeai as genai
from news.src.utils.common_utils import get_today_kst_str
from dotenv import load_dotenv
from datetime import datetime
from pathlib import Path
import logging

try:
    from news.src.utils.article_utils import extract_publish_datetime
except Exception:
    extract_publish_datetime = None
# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë‹¤ì–‘í•œ ì‹¤í–‰ í™˜ê²½(.py, PyInstaller)ì—ì„œ .env íŒŒì¼ ë¡œë“œ
# ------------------------------------------------------------------
def _ensure_env_loaded():
    """
    GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì—¬ëŸ¬ ì˜ˆìƒ ê²½ë¡œì—ì„œ .env íŒŒì¼ì„ ì°¾ì•„ ë¡œë“œ
    """
    if os.getenv("GOOGLE_API_KEY"):
        return
    
    if getattr(sys, "frozen", False):
        search_paths = [
            os.path.dirname(sys.executable),
            os.path.join(os.path.expanduser("~"), "Desktop"),
            os.path.join(os.getenv("APPDATA", ""), "NewsGenerator"),
            os.getcwd(),
        ]
        meipass = getattr(sys, "_MEIPASS", None)
        if meipass:
            search_paths.insert(0, meipass)
        for path in search_paths:
            if path and os.path.exists(path):
                env_path = os.path.join(path, ".env")
                if os.path.exists(env_path):
                    load_dotenv(env_path)
                    if os.getenv("GOOGLE_API_KEY"):
                        print(f"âœ… .env íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {env_path}")
                        return
    else:
        load_dotenv()
        if os.getenv("GOOGLE_API_KEY"):
            return
        module_dir = os.path.dirname(__file__)
        load_dotenv(os.path.join(module_dir, ".env"))
        if os.getenv("GOOGLE_API_KEY"):
            return
        if getattr(sys, "frozen", False):
            exe_dir = os.path.dirname(sys.executable)
            load_dotenv(os.path.join(exe_dir, ".env"))
            if os.getenv("GOOGLE_API_KEY"):
                return
        meipass = getattr(sys, "_MEIPASS", None)
        if meipass:
            load_dotenv(os.path.join(meipass, ".env"))

_ensure_env_loaded()

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError(".envì—ì„œ GOOGLE_API_KEYë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
genai.configure(api_key=api_key)

model = genai.GenerativeModel("gemini-2.5-flash")


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì•ˆì „í•œ ë¬¸ìì—´ë¡œ í‚¤ì›Œë“œë¥¼ ë³€í™˜
# ------------------------------------------------------------------
def _safe_keyword(name: str) -> str:
    """
    ë¬¸ìì—´ì—ì„œ ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±, í•˜ì´í”ˆ, ì–¸ë”ìŠ¤ì½”ì–´ë§Œ ë‚¨ê¸°ê³  ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
    :param name: ì›ë³¸ ë¬¸ìì—´
    :return: íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ìì—´
    """
    name = "".join(c for c in name if c.isalnum() or c in (" ", "-", "_")).strip()
    return name.replace(" ", "_") or "log"

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : í”„ë¡œê·¸ë¨ì˜ ê¸°ë³¸ ì‹¤í–‰ ë””ë ‰í† ë¦¬ ê²½ë¡œ íšë“
# ------------------------------------------------------------------
def _get_base_dir() -> Path:
    """
    ê°œë°œ í™˜ê²½ê³¼ PyInstaller ë¹Œë“œ í™˜ê²½ì„ êµ¬ë¶„í•˜ì—¬ ë¡œê·¸ íŒŒì¼ ë“±ì„ ì €ì¥í•  ê¸°ë³¸ ê²½ë¡œë¥¼ ë°˜í™˜
    :return: ê¸°ë³¸ ë””ë ‰í† ë¦¬ì˜ Path ê°ì²´
    """
    if getattr(sys, "frozen", False):
        return Path(sys.executable).parent
    return Path.cwd()

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ê³¼ì •ì„ ê¸°ë¡í•  ë¡œê±°(Logger) ì„¤ì •
# ------------------------------------------------------------------
def setup_check_logging(keyword: str) -> tuple[logging.Logger, str]:
    """
    'ê¸°ì‚¬ ì¬ìƒì„±' í´ë” ë‚´ì— ì˜¤ëŠ˜ ë‚ ì§œì˜ í´ë”ë¥¼ ë§Œë“¤ê³ , í‚¤ì›Œë“œë¥¼ íŒŒì¼ëª…ìœ¼ë¡œ í•˜ëŠ” ë¡œê·¸ íŒŒì¼ì„ ì„¤ì •
    ê¸°ì¡´ news_LLM ë¡œê·¸ íŒŒì¼ì— ì´ì–´ì„œ ê¸°ë¡(mode="a")
    :param keyword: ë¡œê·¸ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  í‚¤ì›Œë“œ
    :return: ì„¤ì •ëœ ë¡œê±° ê°ì²´ì™€ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    """
    current_date = datetime.now().strftime("%Y%m%d")
    base_dir = _get_base_dir()
    log_dir = base_dir / "ê¸°ì‚¬ ì¬ìƒì„±" / f"ì¬ìƒì„±{current_date}"
    log_dir.mkdir(parents=True, exist_ok=True)

    safe_keyword = _safe_keyword(keyword)
    log_filepath = str(log_dir / f"{safe_keyword}.txt")

    logger_name = f"check_llm_{safe_keyword}"
    logger = logging.getLogger(logger_name)
    logger.setLevel(logging.INFO)

    if not logger.handlers:
        fh = logging.FileHandler(log_filepath, encoding="utf-8", mode="a")
        fh.setLevel(logging.INFO)
        fh.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)
        ch.setFormatter(logging.Formatter("%(message)s"))

        logger.addHandler(fh)
        logger.addHandler(ch)

    return logger, log_filepath

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë©”ì‹œì§€ë¥¼ ë¡œê±°ì™€ ì½˜ì†”ì— ë™ì‹œ ì¶œë ¥
# ------------------------------------------------------------------
def log_and_print(logger, message: str, level: str = "info"):
    """
    ì£¼ì–´ì§„ ë©”ì‹œì§€ë¥¼ ì§€ì •ëœ ë¡œê·¸ ë ˆë²¨ë¡œ íŒŒì¼ê³¼ ì½˜ì†”ì— ê¸°ë¡
    :param logger: ì‚¬ìš©í•  ë¡œê±° ê°ì²´
    :param message: ê¸°ë¡í•  ë©”ì‹œì§€
    :param level: ë¡œê·¸ ë ˆë²¨ ('info', 'warning', 'error', 'debug')
    """
    if level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "debug":
        logger.debug(message)


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
# ------------------------------------------------------------------
def generate_check_prompt(keyword: str = "", published_kst: str | None = None) -> str:
    today_kst = get_today_kst_str()
    keyword_info = f"- í‚¤ì›Œë“œ: {keyword}\n" if keyword else ""
    published_line = (
        f"- ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): {published_kst}\n"
        if (published_kst and str(published_kst).strip())
        else "- ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): í™•ì¸ ë¶ˆê°€\n"
    )

    prompt = f"""
    
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‘ ê°œì˜ ê¸°ì‚¬('ìƒì„±ëœ ê¸°ì‚¬'ì™€ 'ì›ë¬¸ ê¸°ì‚¬')ë¥¼ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ë¥¼ íŒë‹¨í•˜ë¼.
        ì‚¬ìš©ìëŠ” ì½¤ë§ˆ(,)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ê¸°ì‚¬ë¥¼ êµ¬ë¶„í•˜ë©°, ì²« ë²ˆì§¸ê°€ 'ìƒì„±ëœ ê¸°ì‚¬', ë‘ ë²ˆì§¸ê°€ 'ì›ë¬¸ ê¸°ì‚¬'ì´ë‹¤.

        [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]
        - ì˜¤ëŠ˜ ë‚ ì§œ(Asia/Seoul): {today_kst}
        - ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): {published_line}
     
        [í‚¤ì›Œë“œ]
        {keyword_info}

        [ë¹„êµ ê¸°ì¤€]
        - ì™„ì „íˆ ë™ì¼í•œ ê²½ìš° â†’ "âœ… ì‚¬ì‹¤ê´€ê³„ì— ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤."
        - í‘œí˜„ ë°©ì‹ì´ ë‹¤ë¥´ì§€ë§Œ ì˜ë¯¸ê°€ ë™ì¼í•œ ê²½ìš° â†’ "âœ… í‘œí˜„ ë°©ì‹ì´ ë‹¤ë¥´ì§€ë§Œ, ì‚¬ì‹¤ê´€ê³„ëŠ” ì¼ì¹˜í•©ë‹ˆë‹¤."
        - ì¼ë¶€ ë‚´ìš©ì´ ë‹¤ë¥´ê±°ë‚˜ ë¹ ì§„ ê²½ìš° â†’ "âš ï¸ ì¼ë¶€ ë‚´ìš©ì´ ì›ë¬¸ê³¼ ë‹¤ë¦…ë‹ˆë‹¤."
        - ëª…í™•í•œ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° â†’ "âŒ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤." + ì–´ë–¤ ë¶€ë¶„ì´ í‹€ë ¸ëŠ”ì§€ ì„¤ëª…

        [ì ê²€ ì‚¬í•­]
        1. 'ìƒì„±ëœ ê¸°ì‚¬'ëŠ” ë°˜ë“œì‹œ ì˜¤ë¡œì§€ 'ì›ë¬¸ ê¸°ì‚¬'ì˜ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œë§Œ ë¹„êµí•˜ë¼. ì™¸ë¶€ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ë¼. 'ì›ë¬¸ ê¸°ì‚¬'ì˜ ì •ë³´ê°€ ì‚¬ì‹¤ì´ë¼ëŠ” ì „ì œë¡œ 'ìƒì„±ëœ ê¸°ì‚¬'ë¥¼ ë¹„êµí•˜ë¼.
        2. 'ìƒì„±ëœ ê¸°ì‚¬'ì˜ ë‚´ìš©ì´ 'ì›ë¬¸ ê¸°ì‚¬'ì˜ íŠ¹ì • ì¸ë¬¼ì˜ ì§ì±…ì´ë‚˜ íŠ¹ì • íšŒì‚¬ì˜ ê¸°ìˆ , ì‚¬ì—…, ì œí’ˆ, ì„œë¹„ìŠ¤ í˜¹ì€ ì‚¬ê±´ì˜ ê²½ìš° ì¼ì–´ë‚œ ì¼ ë“±ì˜ ì •ë³´ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš° 'ì›ë¬¸ ê¸°ì‚¬'ì˜ ì •ë³´ì™€ ì¼ì¹˜í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ìˆ˜ì •í•˜ë¼.
        3. 'ì›ë¬¸ ê¸°ì‚¬'ì— ì—†ëŠ” ì •ë³´ë¥¼ 'ìƒì„±ëœ ê¸°ì‚¬'ê°€ ë„£ì—ˆëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸í•˜ë¼. ì‚¬ì‹¤ê´€ê³„ê°€ í™•ì¸ë˜ì§€ ì•Šì€ ë‚´ìš©ì„ ì„ì˜ë¡œ ì¶”ê°€í–ˆì„ ê²½ìš° 'í—ˆìœ„ ì •ë³´'ë¡œ ê°„ì£¼í•˜ê³  ìˆ˜ì •í•˜ë¼.
        4. 'ì›ë¬¸ ê¸°ì‚¬'ì—ì„œ 'ì˜ˆì •', 'ì¶”ì§„ ì¤‘', 'ê°€ëŠ¥ì„± ìˆìŒ' ë“±ì˜ ë¶ˆí™•ì • í‘œí˜„ì´ ì‚¬ìš©ëœ ê²½ìš°, 'ìƒì„±ëœ ê¸°ì‚¬'ê°€ ì´ë¥¼ ë‹¨ì •ì ìœ¼ë¡œ í‘œí˜„í–ˆëŠ”ì§€ í™•ì¸í•˜ë¼.
        5. ê¸°ì—…ì´ë‚˜ ì¸ë¬¼ ë“±ì˜ ëª…ì˜ˆ í›¼ì†, ì˜¤í•´ ìœ ë°œ, ì •ì •ë³´ë„ ìš”ì²­ ê°€ëŠ¥ì„± ìˆëŠ” ë¯¼ê°í•œ í‘œí˜„ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì§€ì í•˜ë¼.
        6. ë¬¸ì¥ì´ ê°„ê²°í•´ì¡Œë”ë¼ë„, í•µì‹¬ ì˜ë¯¸ê°€ ì™œê³¡ë˜ê±°ë‚˜ ë¹ ì§„ ë¶€ë¶„ì´ ì—†ëŠ”ì§€ í™•ì¸í•˜ë¼.
        7. ì™„ì„±ëœ ê¸°ì‚¬ì˜ ë³¸ë¬¸ ê¸¸ì´ê°€ 300ì ì´í•˜, 800ì ì´ìƒìœ¼ë¡œ ì‘ì„±ë˜ì§€ ì•Šë„ë¡ ìœ ì˜í•˜ë¼.
        8. ì œëª©ì´ë‚˜ í•´ì‹œíƒœê·¸ê°€ ì›ë¬¸ê³¼ ë¶ˆì¼ì¹˜í•˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš°ì— ë‹¨ìˆœ ì‚­ì œí•˜ì§€ ë§ê³ , ì›ë¬¸ ê¸°ì‚¬ ë‚´ìš©ì— ë§ëŠ” ì˜¬ë°”ë¥¸ ì œëª©ê³¼ í•´ì‹œíƒœê·¸ë¡œ êµì²´í•˜ì—¬ ë°˜ë“œì‹œ ê¸°ì¡´ì— ìƒì„±ëœ ê°œìˆ˜ë¥¼ ìœ ì§€í•œë‹¤.
        - [ì œëª©] ì„¹ì…˜ì€ í•­ìƒ 3ê°œ ì œëª©ì„ í¬í•¨í•´ì•¼ í•œë‹¤.
        - [í•´ì‹œíƒœê·¸] ì„¹ì…˜ì€ í•­ìƒ 3~5ê°œì˜ í•´ì‹œíƒœê·¸ë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤.

        [ì˜ˆì™¸ ì‚¬í•­ - ë‹¤ìŒ ê²½ìš°ëŠ” ì‚¬ì‹¤ ì˜¤ë¥˜ë¡œ ê°„ì£¼í•˜ì§€ ë§ ê²ƒ]
        1. 'ì§€ë‚œ Oì›”' 'ì§€ë‚œ OOOOë…„' 'ì§€ë‚œ OOì¼', 'ì˜¤ëŠ” Oì›”' 'ì˜¤ëŠ” OOOOë…„' 'ì˜¤ëŠ” OOì¼' ë“±ì˜ ìƒëŒ€ì  ì‹œê°„ í‘œí˜„ ì‚¬ìš©
        2. 'ì´ë‚ ', 'ì˜¤ëŠ˜' ë“±ì˜ ë¶ˆí•„ìš”í•œ ì‹œì  í‘œí˜„ ìƒëµ
        3. ë°©ì†¡ì¼ì´ 1ì£¼ì¼ ì´ìƒ ì§€ë‚œ ê²½ìš° 'ìµœê·¼ ë°©ì†¡ëœ', 'ì´ì „ ë°©ì†¡ì—ì„œ' ë“±ìœ¼ë¡œ í‘œí˜„í•œ ê²½ìš°
        4. ì—¬ëŸ¬ ë°©ì†¡ì¼ì´ ìˆëŠ” ê²½ìš° ê°€ì¥ ìµœê·¼ ë°©ì†¡ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ ì‹œì  ì¡°ì •
        5. ì›ë¬¸ê³¼ ì¬ìƒì„± ê¸°ì‚¬ ë‚´ìš©ì„ ë¹„êµí–ˆì„ë•Œ ì¬ìƒì„± ê¸°ì‚¬ê°€ [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ê³¼ ë¹„êµí•´ ê³¼ê±°/ë¯¸ë˜ ì‹œì ìœ¼ë¡œ ì •í™•íˆ í‘œí˜„í•œ ê²½ìš°
        6. ì›ë¬¸ ê¸°ì‚¬ì˜ ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ)ì´ ì¬ìƒì„± ê¸°ì‚¬ ì‘ì„± ì‹œì ì¸ [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ë³´ë‹¤ ê³¼ê±°ì¸ ê²½ìš°, ì¬ìƒì„± ê¸°ì‚¬ ë³¸ë¬¸ì´ ê³¼ê±° ì‹œì œë¡œ ì •í™•íˆ í‘œí˜„í•œ ê²½ìš°
        7. [ì œëª©], [í•´ì‹œíƒœê·¸]ì— ì‚¬ìš©ìê°€ ì…ë ¥í•œ [í‚¤ì›Œë“œ]ê°€ í¬í•¨ëœ ê²½ìš°

        âœ… ì›ë¬¸ì— ìˆì§€ë§Œ ì‚¬ìš©ìê°€ ê¸°ì‚¬ì—ì„œ ìƒëµí•´ë„ ë¬¸ì œ ì‚¼ì§€ ì•ŠëŠ”ë‹¤.
        âœ… ìœ„ì˜ ì‹œì œ ê´€ë ¨ ì˜ˆì™¸ ì‚¬í•­ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ëŠ” ì‚¬ì‹¤ ì˜¤ë¥˜ë¡œ ê°„ì£¼í•˜ì§€ ì•ŠëŠ”ë‹¤.
        âŒ ì‚¬ìš©ìê°€ ì›ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì™œê³¡í•´ ë„£ì€ ê²½ìš°, ë°˜ë“œì‹œ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì í•˜ê³  ê·¸ ì´ìœ ë¥¼ ëª…ì‹œí•˜ë¼.
        - ê° ì§€ì  ì‚¬í•­ì€ 'phrase'(ë¬¸ì œ êµ¬ì ˆ)ì™€ 'reason'(ì´ìœ )ì„ í¬í•¨í•œ ê°ì²´ë¡œ ì‘ì„±
        - ì˜ˆì‹œ: {{ "phrase": "ë¬¸ì œ êµ¬ì ˆ", "reason": "êµ¬ì²´ì ì¸ ì´ìœ " }}

        [ì‘ë‹µ í˜•ì‹]
        - ì•„ë˜ JSONë§Œ ì •í™•íˆ ì¶œë ¥í•˜ë¼(ê·¸ ì™¸ í…ìŠ¤íŠ¸ ê¸ˆì§€)
        - corrected_articleëŠ” 'ì‚¬ì‹¤ì´ ì•„ë‹Œ ë¶€ë¶„ë§Œ ìµœì†Œ ìˆ˜ì •' ì›ì¹™ìœ¼ë¡œ ì‘ì„±í•˜ë¼(ë¶ˆí•„ìš”í•œ ì¬ì„œìˆ  ê¸ˆì§€).
        - corrected_articleëŠ” ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì¶œë ¥í•˜ë¼(ê°ì²´/ë°°ì—´ ê¸ˆì§€), [ì œëª©]/[í•´ì‹œíƒœê·¸]/[ë³¸ë¬¸] ì„¹ì…˜ì„ í¬í•¨í•  ê²ƒ.

        [ìµœì¢… ì¶œë ¥: JSON ì „ìš©]
        {{
        "verdict": "OK" ë˜ëŠ” "ERROR",
        "nonfactual_phrases": [
            {{ "phrase": "ë¬¸ì œ êµ¬ì ˆ1", "reason": "ì´ìœ  ì„¤ëª…" }},
            {{ "phrase": "ë¬¸ì œ êµ¬ì ˆ2", "reason": "ì´ìœ  ì„¤ëª…" }}
        ],
        "corrected_article": "ìˆ˜ì •ëœ ì „ì²´ ê¸°ì‚¬ (ë¬¸ì œê°€ ìˆì„ ë•Œë§Œ, [ì œëª©]/[í•´ì‹œíƒœê·¸]/[ë³¸ë¬¸] í¬í•¨)"
        }}
        """
    return prompt

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ ì¶”ì¶œ
# ------------------------------------------------------------------
def _extract_json_block(text: str):
    """
    ë§ˆí¬ë‹¤ìš´ ì½”ë“œ íœìŠ¤(```json) ë˜ëŠ” ì¤‘ê´„í˜¸({})ë¡œ ê°ì‹¸ì¸ JSON ë¬¸ìì—´ì„ ì°¾ì•„ íŒŒì‹±
    :param text: LLMì´ ìƒì„±í•œ ì „ì²´ í…ìŠ¤íŠ¸
    :return: íŒŒì‹±ëœ JSON ê°ì²´, ì‹¤íŒ¨ ì‹œ None
    """
    fence = re.search(r"```json\s*(\{[\s\S]*?\})\s*```", text)
    if fence:
        try:
            return json.loads(fence.group(1))
        except Exception:
            pass
    braces = re.findall(r"(\{[\s\S]*\})", text)
    for blk in braces[::-1]:
        try:
            return json.loads(blk)
        except Exception:
            continue
    return None

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : LLMì´ ìƒì„±í•œ ë‹¤ì–‘í•œ í˜•íƒœì˜ íŒì •(verdict)ì„ 'OK' ë˜ëŠ” 'ERROR'ë¡œ ì •ê·œí™”
# ------------------------------------------------------------------
def _normalize_verdict(raw: str, json_obj: dict) -> str:
    """
    'âœ…', 'ì¼ì¹˜' ë“±ì˜ ê¸ì • í‘œí˜„ì€ 'OK'ë¡œ, 'âŒ', 'ì˜¤ë¥˜' ë“±ì˜ ë¶€ì • í‘œí˜„ì€ 'ERROR'ë¡œ ë³€í™˜
    :param raw: LLMì´ ìƒì„±í•œ ì›ë³¸ verdict ë¬¸ìì—´
    :param json_obj: nonfactual_phrases ì¡´ì¬ ì—¬ë¶€ í™•ì¸ì„ ìœ„í•œ JSON ê°ì²´
    :return: 'OK' ë˜ëŠ” 'ERROR' ë¬¸ìì—´
    """
    v = (raw or "").strip()
    vu = v.upper()
    if vu in ("OK", "ERROR"):
        return vu
    # ì˜ë¯¸ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±
    if "âœ…" in v or ("ì¼ì¹˜" in v and "ì‚¬ì‹¤" in v):
        return "OK"
    if "âŒ" in v or "ì˜¤ë¥˜" in v or "í‹€ë ¸" in v or "ë‹¤ë¦…" in v:
        return "ERROR"
    if "âš ï¸" in v or "ì£¼ì˜" in v or "ê²½ê³ " in v:
        return "ERROR"
    nf = json_obj.get("nonfactual_phrases") or []
    return "ERROR" if nf else "OK"

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ êµ¬ë¬¸(nonfactual_phrases) ëª©ë¡ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
# ------------------------------------------------------------------
def _normalize_nonfactual(nf) -> list[dict]:
    """
    ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì˜¤ë¥˜ êµ¬ë¬¸ ëª©ë¡ì„ {"phrase": ..., "reason": ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ í†µì¼
    :param nf: LLMì´ ìƒì„±í•œ nonfactual_phrases
    :return: ì •ê·œí™”ëœ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    items = []
    if isinstance(nf, list):
        for it in nf:
            if isinstance(it, dict):
                phrase = str(it.get("phrase") or it.get("ë¬¸ì œ êµ¬ì ˆ") or "").strip()
                reason = str(it.get("reason") or it.get("ì´ìœ ") or "").strip()
            else:
                phrase = str(it).strip()
                reason = ""
            if phrase:
                items.append({"phrase": phrase, "reason": reason})
    return items

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : í…ìŠ¤íŠ¸ì— [ì œëª©], [í•´ì‹œíƒœê·¸], [ë³¸ë¬¸] ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ìµœì†Œí•œì˜ ê¸°ë³¸ í‹€ì„ ìƒì„±í•˜ì—¬ ë³´ì¥
# ------------------------------------------------------------------
def _ensure_sections(text: str) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— í•„ìˆ˜ ì„¹ì…˜ì´ ëˆ„ë½ëœ ê²½ìš°, ê¸°ë³¸ ì œëª©ê³¼ í•´ì‹œíƒœê·¸ë¥¼ ì¶”ê°€í•˜ì—¬ ì™„ì „í•œ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    :param text: ë³´ì •í•  í…ìŠ¤íŠ¸
    :return: ì„¹ì…˜ì´ ë³´ì¥ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        text = ""
    has_title = "[ì œëª©]" in text
    has_tags  = "[í•´ì‹œíƒœê·¸]" in text
    has_body  = "[ë³¸ë¬¸]" in text
    if has_title and has_tags and has_body:
        return text.strip()
    # ë³¸ë¬¸ ì¶”ì •
    body = text
    m = re.search(r"\[ë³¸ë¬¸\]\s*(.*)\Z", text, flags=re.S)
    if m:
        body = m.group(1).strip()
    # ê¸°ë³¸ í‹€ ìƒì„±
    rebuilt = []
    rebuilt.append("[ì œëª©]")
    rebuilt.append("ìˆ˜ì • ê¸°ì‚¬ 1")
    rebuilt.append("ìˆ˜ì • ê¸°ì‚¬ 2")
    rebuilt.append("ìˆ˜ì • ê¸°ì‚¬ 3")
    rebuilt.append("")
    rebuilt.append("[í•´ì‹œíƒœê·¸]")
    # í•´ì‹œíƒœê·¸ í›„ë³´ ì¶”ì¶œ
    candidates = list(dict.fromkeys(re.findall(r"#\S+", text)))[:5]
    if not candidates:
        candidates = ["#ë‰´ìŠ¤", "#ì •ë³´", "#ì‚¬ì‹¤ê²€ì¦"]
    rebuilt.append(" ".join(candidates[:5]))
    rebuilt.append("")
    rebuilt.append("[ë³¸ë¬¸]")
    rebuilt.append(body.strip())
    return "\n".join(rebuilt).strip()

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ìˆ˜ì •ëœ ê¸°ì‚¬ê°€ ì—†ì„ ë•Œ, ì˜¤ë¥˜ êµ¬ì ˆì„ ì›ë³¸ì—ì„œ ì œê±°í•˜ì—¬ ìµœì†Œí•œì˜ ìˆ˜ì •ì„ ìˆ˜í–‰
# ------------------------------------------------------------------
def _auto_minimal_patch(generated_article: str, nonfactual_list: list[dict]) -> str:
    """
    LLMì´ ì˜¤ë¥˜(ERROR)ë¡œ íŒì •í–ˆìœ¼ë‚˜ ìˆ˜ì •ëœ ê¸°ì‚¬ë¥¼ ì œê³µí•˜ì§€ ì•Šì€ ê²½ìš°,
    ê°ì§€ëœ ì˜¤ë¥˜ êµ¬ë¬¸(nonfactual_phrases)ì„ ìƒì„±ëœ ê¸°ì‚¬ì—ì„œ ì‚­ì œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìë™ ìˆ˜ì •
    :param generated_article: LLMì´ ìƒì„±í•œ ì›ë³¸ ê¸°ì‚¬
    :param nonfactual_list: ì‚¬ì‹¤ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ íŒë³„ëœ êµ¬ë¬¸ ë¦¬ìŠ¤íŠ¸
    :return: ìµœì†Œí•œìœ¼ë¡œ ìˆ˜ì •ëœ ê¸°ì‚¬
    """
    if not generated_article:
        return ""
    patched = generated_article
    for item in nonfactual_list:
        phrase = item.get("phrase", "")
        if phrase:
            # ê³¼ê²©í•œ ì¹˜í™˜ ë°©ì§€: ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” êµ¬ì ˆë§Œ ì œê±°
            patched = patched.replace(phrase, "")
    return _ensure_sections(patched)


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ìƒì„±ëœ ê¸°ì‚¬ì™€ ì›ë¬¸ ê¸°ì‚¬ë¥¼ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ë¥¼ ê²€ì¦í•˜ëŠ” ë©”ì¸ ë¡œì§
# ------------------------------------------------------------------
def check_article_facts(
    generated_article: str,
    original_article: str,
    keyword: str = "check_LLM",
    source_url: str | None = None,        # âœ… (2) ì‘ì„±ì¼ì‹œ ì£¼ì…ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¶”ê°€
    published_kst: str | None = None      # âœ… (2) ì™¸ë¶€ì—ì„œ ì§ì ‘ ì „ë‹¬ ê°€ëŠ¥
) -> dict:
    """
    ë‘ ê¸°ì‚¬ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ê³ , ì˜¤ë¥˜ê°€ ìˆì„ ê²½ìš° ìˆ˜ì •ëœ ê¸°ì‚¬ë¥¼ í¬í•¨í•œ JSONì„ ë°˜í™˜
    :param generated_article: news_LLMì´ ìƒì„±í•œ ê¸°ì‚¬
    :param original_article: ì›ë³¸ ê¸°ì‚¬ ë³¸ë¬¸
    :param keyword: ë¡œê¹… ë° í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  í‚¤ì›Œë“œ
    :param source_url: ì›ë¬¸ ê¸°ì‚¬ URL(ìˆë‹¤ë©´ ë°œí–‰ì¼ ì¬ì¶”ì¶œ ì‹œë„)
    :param published_kst: 'YYYY-MM-DD HH:MM' ë“± ê°€ë…í˜• KST ë¬¸ìì—´(ìš°ì„  ì£¼ì…)
    :return: ê²€ì¦ ê²°ê³¼ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ('explanation', 'json', 'error' í¬í•¨)
    """
    logger, log_filepath = setup_check_logging(keyword)

    log_and_print(logger, "\n" + "="*80)
    log_and_print(logger, "ğŸ” CHECK_LLM - ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ì‹œì‘")
    log_and_print(logger, "="*80)
    log_and_print(logger, f"\nğŸ“¥ ì…ë ¥ ë°ì´í„°:")
    log_and_print(logger, f"  - ìƒì„±ëœ ê¸°ì‚¬ ê¸¸ì´: {len(generated_article)}ì")
    log_and_print(logger, f"  - ì›ë¬¸ ê¸°ì‚¬ ê¸¸ì´: {len(original_article)}ì")
    log_and_print(logger, f"  - ë¡œê·¸ íŒŒì¼: {log_filepath}")
    if source_url:
        log_and_print(logger, f"  - source_url: {source_url}")

    # âœ… (2) ì‘ì„±ì¼ì‹œ ì£¼ì…: ìš°ì„ ìˆœìœ„ published_kst ì¸ì â†’ URL ì¶”ì¶œ â†’ ë¯¸í™•ì¸
    published_kst_str = (published_kst or "").strip() or None
    if not published_kst_str and source_url and extract_publish_datetime:
        try:
            dt_raw = extract_publish_datetime(source_url)  # ì˜ˆ: '20250901 08:39' ë˜ëŠ” None
            if dt_raw:
                m = re.match(r"^(\d{4})(\d{2})(\d{2})\s+(\d{2}:\d{2})$", dt_raw)
                published_kst_str = (
                    f"{m.group(1)}-{m.group(2)}-{m.group(3)} {m.group(4)}" if m else dt_raw
                )
                log_and_print(logger, f"  - ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(KST): {published_kst_str}")
        except Exception as e:
            log_and_print(logger, f"  - ì‘ì„±ì¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}", "warning")

    try:
        log_and_print(logger, f"\nğŸ¤– AI ëª¨ë¸ í˜¸ì¶œ:")
        # âœ… (2) í”„ë¡¬í”„íŠ¸ì— ì‘ì„±ì¼ì‹œ ì£¼ì…
        system_prompt = generate_check_prompt(keyword=keyword, published_kst=published_kst_str)
        user_request = f"ìƒì„±ëœ ê¸°ì‚¬: {generated_article}, \n\nì›ë¬¸ ê¸°ì‚¬: {original_article}"
        log_and_print(logger, f"  - ëª¨ë¸: gemini-2.5-flash")
        log_and_print(logger, f"  - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(system_prompt)}ì")
        log_and_print(logger, f"  - ì‚¬ìš©ì ìš”ì²­ ê¸¸ì´: {len(user_request)}ì")

        log_and_print(logger, f"\nğŸ“‹ ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:")
        log_and_print(logger, f"{'='*80}")
        log_and_print(logger, system_prompt)
        log_and_print(logger, f"{'='*80}")

        log_and_print(logger, f"\nğŸ“‹ ì „ì²´ ì‚¬ìš©ì ìš”ì²­:")
        log_and_print(logger, f"{'='*80}")
        log_and_print(logger, user_request)
        log_and_print(logger, f"{'='*80}")

        contents = [
            {'role': 'user', 'parts': [{'text': system_prompt}]},
            {'role': 'model', 'parts': [{'text': 'ì´í•´í–ˆìŠµë‹ˆë‹¤. ë¹„êµ í›„ JSONë„ í•¨ê»˜ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.'}]},
            {'role': 'user', 'parts': [{'text': user_request}]}
        ]

        log_and_print(logger, f"\nâ³ AI ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
        t0 = time.perf_counter()                     # âœ… (1) ì‹œì‘
        response = model.generate_content(contents)
        rtt = time.perf_counter() - t0               # âœ… (1) ê²½ê³¼

        # í† í° ê³„ì‚°
        usage = getattr(response, "usage_metadata", None)
        if usage:
            p = getattr(usage, "prompt_token_count", 0)
            c = getattr(usage, "candidates_token_count", 0)
            t = getattr(usage, "total_token_count", 0)
            th = getattr(usage, "thoughts_token_count", 0)  # âœ… ì‚¬ê³  í† í°
            tu = getattr(usage, "tool_use_prompt_token_count", 0)
            cc = getattr(usage, "cached_content_token_count", 0)
            resid = t - (p + c + th + tu)  # ë‚¨ëŠ”ë‹¤ë©´ API/ë²„ì „ë³„ ì§‘ê³„ ì°¨ì´
            log_and_print(logger,
                f"ğŸ§¾ í† í° ìƒì„¸ | ì…ë ¥={p}, ì¶œë ¥={c}, ìƒê°={th}, íˆ´í”„ë¡¬í”„íŠ¸={tu}, ìºì‹œ={cc}, í•©ê³„={t}, ì”ì°¨={resid}")
        else:
            log_and_print(logger, "ğŸ§¾ usage_metadata ì—†ìŒ", "warning")    

        full_text = (response.text or "").strip()
        log_and_print(logger, f"  - RTT: {rtt*1000:.0f}ms")  # âœ… (1) ë°€ë¦¬ì´ˆë¡œ ê¸°ë¡

        log_and_print(logger, f"\nğŸ“¤ AI ì‘ë‹µ ê²°ê³¼:")
        log_and_print(logger, f"  - ì‘ë‹µ ê¸¸ì´: {len(full_text)}ì")

        log_and_print(logger, f"\nğŸ“‹ ì „ì²´ AI ì‘ë‹µ:")
        log_and_print(logger, f"{'='*80}")
        log_and_print(logger, full_text)
        log_and_print(logger, f"{'='*80}")

        log_and_print(logger, f"\nğŸ” JSON íŒŒì‹± ì‹œë„:")
        json_obj = _extract_json_block(full_text)

        if not json_obj or "verdict" not in json_obj:
            log_and_print(logger, f"  âŒ JSON íŒŒì‹± ì‹¤íŒ¨", "warning")
            result = {
                "explanation": full_text,
                "json": None,
                "error": "JSON íŒŒì‹± ì‹¤íŒ¨"
            }
        else:
            log_and_print(logger, f"  âœ… JSON íŒŒì‹± ì„±ê³µ")

            # --------- ë³´ì • 1: nonfactual ëª©ë¡ ì •ìƒí™”
            nf = _normalize_nonfactual(json_obj.get("nonfactual_phrases"))
            json_obj["nonfactual_phrases"] = nf

            # --------- ë³´ì • 2: verdict ì •ê·œí™”(OK/ERROR) 
            json_obj["verdict"] = _normalize_verdict(json_obj.get("verdict", ""), json_obj)

            # --------- ë³´ì • 3: corrected_article íƒ€ì…/ì„¹ì…˜ ë³´ì¥ 
            corrected = (json_obj.get("corrected_article", "") or "")
            if isinstance(corrected, dict):
                corrected = "\n".join([
                    "[ì œëª©]",
                    str(corrected.get("title", "")).strip(),
                    "",
                    "[í•´ì‹œíƒœê·¸]",
                    str(corrected.get("hashtags", "")).strip(),
                    "",
                    "[ë³¸ë¬¸]",
                    str(corrected.get("ë³¸ë¬¸", "")).strip(),
                ])
            elif isinstance(corrected, list):
                # ì˜ëª»ëœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì˜¬ ë•ŒëŠ” ë¬¸ìì—´ë¡œ ë³‘í•©
                corrected = "\n".join(str(x) for x in corrected)
            else:
                corrected = str(corrected)

            # ì˜¤ë¥˜ì¸ë° êµì •ë¬¸ì´ ë¹„ì–´ ìˆìœ¼ë©´ ìë™ ìµœì†Œ ë³´ì • ìƒì„±
            if json_obj["verdict"] == "ERROR" and not corrected.strip():
                corrected = _auto_minimal_patch(generated_article, nf)

            # ì„¹ì…˜ ê°•ì œ ë³´ì¥
            corrected = _ensure_sections(corrected) if corrected else corrected
            json_obj["corrected_article"] = corrected

            result = {
                "explanation": full_text,
                "json": json_obj,
                "error": None
            }

        log_and_print(logger, f"\nğŸ“‹ ìµœì¢… ë°˜í™˜ ê²°ê³¼:")
        log_and_print(logger, f"  - explanation ê¸¸ì´: {len(result['explanation'])}ì")
        log_and_print(logger, f"  - json ì¡´ì¬: {result['json'] is not None}")
        
        # Display nonfactual phrases with reasons if they exist
        if result['json'] and 'nonfactual_phrases' in result['json']:
            nonfactual = result['json']['nonfactual_phrases']
            if nonfactual:
                log_and_print(logger, "\nâš ï¸ ë°œê²¬ëœ ì‚¬ì‹¤ ì˜¤ë¥˜ êµ¬ë¬¸:")
                for i, item in enumerate(nonfactual, 1):
                    if isinstance(item, dict):
                        log_and_print(logger, f"  {i}. {item.get('phrase', '')}")
                        log_and_print(logger, f"     â†’ ì´ìœ : {item.get('reason', 'ì‚¬ìœ ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')}")
                    else:
                        log_and_print(logger, f"  {i}. {item}")
                        log_and_print(logger, f"     â†’ ì´ìœ : ìƒì„¸í•œ ì´ìœ ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        log_and_print(logger, f"  - error: {result['error']}")

        log_and_print(logger, f"\nğŸ’¾ ìµœì¢… ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ ì™„ë£Œ")
        log_and_print(logger, f"  - ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_filepath}")

        log_and_print(logger, "\n" + "="*80)
        log_and_print(logger, "ğŸ” CHECK_LLM - ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ì™„ë£Œ")
        log_and_print(logger, "="*80)

        return result

    except Exception as e:
        log_and_print(logger, f"\nâŒ ì˜ˆì™¸ ë°œìƒ: {str(e)}", "error")
        log_and_print(logger, "\n" + "="*80, "error")
        log_and_print(logger, "ğŸ” CHECK_LLM - ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ì‹¤íŒ¨", "error")
        log_and_print(logger, "="*80, "error")

        return {
            "explanation": "",
            "json": None,
            "error": str(e)
        }


if __name__ == "__main__":
    print("ğŸ” ê¸°ì‚¬ ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ë° ìµœì†Œìˆ˜ì • í”„ë¡œê·¸ë¨")
    keyword = input("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë¡œê·¸ íŒŒì¼ëª…ìš©): ").strip()
    generated = input("ìƒì„±ëœ ê¸°ì‚¬(ì œëª©/í•´ì‹œíƒœê·¸/ë³¸ë¬¸ í¬í•¨)ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”: ").strip()
    original = input("ì›ë¬¸ ê¸°ì‚¬ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”: ").strip()

    # ì°¸ê³ : í•„ìš” ì‹œ ì—¬ê¸°ì—ì„œ source_url, published_kstë¥¼ ì¶”ê°€ ì…ë ¥ë°›ì•„ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    result = check_article_facts(generated, original, keyword)
    if result["error"]:
        print("âŒ ì˜¤ë¥˜:", result["error"])
    else:
        print("\n=== ì„¤ëª… ===\n", result["explanation"])
        print("\n=== JSON ===\n", json.dumps(result["json"], ensure_ascii=False, indent=2))
