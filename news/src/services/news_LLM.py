# news_LLM.py â€” ì†ë„Â·ë¡œê¹… ë³´ê°• + Fast-Pass/Trimmed Compare ì—°ë™
import os
import sys
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
from newspaper import Article
from dotenv import load_dotenv
from datetime import datetime
import logging
from pathlib import Path
from news.src.utils.common_utils import get_today_kst_str 
from time import perf_counter
from google.generativeai.types import GenerationConfig


try:
    from news.src.utils.article_utils import extract_article_content, MIN_BODY_LENGTH as AU_MIN, extract_publish_datetime
except Exception:
    extract_article_content = None
    extract_publish_datetime = None
    AU_MIN = 300

try:
    from . import check_LLM
except ImportError:
    import check_LLM

import re
import json

# ======================================================
# ì¶œë ¥ ì„¹ì…˜ ë³´ì • (LLM ì¶œë ¥ì´ JSON/ì½”ë“œíœìŠ¤ì—¬ë„ ì•ˆì „)
# ======================================================
def _truncate(s: str, n: int) -> str:
    """ë¬¸ìì—´ì„ ìµœëŒ€ nìê¹Œì§€ ìë¥´ê³  ê¹”ë”í•˜ê²Œ ë°˜í™˜."""
    return s if len(s) <= n else s[:n].rstrip()

def _strip_code_fences(s: str) -> str:
    """``` ë˜ëŠ” ```json ì½”ë“œíœìŠ¤ë¥¼ ì œê±°í•´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    if not isinstance(s, str):
        return s
    s = s.strip()
    s = re.sub(r"^```(?:json)?\s*\n?", "", s, flags=re.I)
    s = re.sub(r"\n?```$", "", s, flags=re.I)
    return s.strip()

def _json_loads_maybe(s: str):
    """ë¬¸ìì—´ì´ JSONì´ë©´ íŒŒì‹±í•´ì„œ dict/ë¦¬ìŠ¤íŠ¸ ë°˜í™˜, ì•„ë‹ˆë©´ None."""
    if not isinstance(s, str):
        return None
    try:
        return json.loads(_strip_code_fences(s))
    except Exception:
        return None

def ensure_output_sections(article_text: str, keyword: str, fallback_title: str) -> str:
    """LLM ì¶œë ¥ì´ ì„¹ì…˜ í˜•ì‹ì„ ì§€í‚¤ì§€ ì•Šì•„ë„ [ì œëª©]/[í•´ì‹œíƒœê·¸]/[ë³¸ë¬¸] í˜•íƒœë¡œ ë³µêµ¬."""
    if not article_text:
        article_text = ""
    text = article_text.strip()

    # JSON í˜•íƒœ ì‘ë‹µì¼ ë•Œë„ ë³µêµ¬
    obj = _json_loads_maybe(text)
    if isinstance(obj, dict):
        titles, hashtags, body = [], [], ""
        for k in ("titles", "title_list", "title"):
            v = obj.get(k)
            if isinstance(v, list):
                titles = [str(x).strip() for x in v if str(x).strip()]
                break
            if isinstance(v, str) and v.strip():
                titles = [v.strip()]
                break
        for k in ("hashtags", "tags"):
            v = obj.get(k)
            if isinstance(v, list):
                hashtags = [("#" + str(x).strip().lstrip("#").replace(" ", "")) for x in v if str(x).strip()]
                break
            if isinstance(v, str) and v.strip():
                hashtags = [t if t.startswith("#") else "#" + t for t in v.strip().split()]
        for k in ("body", "content", "article", "text"):
            v = obj.get(k)
            if isinstance(v, str) and v.strip():
                body = v.strip()
                break
        if titles or hashtags or body:
            base = _truncate(f"{keyword} {fallback_title}".strip(), 35) if fallback_title else _truncate(keyword, 35)
            t1 = titles[0] if len(titles) >= 1 else (base or "ì œëª© ì œì•ˆ 1")
            t2 = titles[1] if len(titles) >= 2 else (_truncate(f"{keyword} í•µì‹¬ ì •ë¦¬", 35) if keyword else "ì œëª© ì œì•ˆ 2")
            t3 = titles[2] if len(titles) >= 3 else (_truncate(f"{keyword} í–‰ë³´ ì—…ë°ì´íŠ¸", 35) if keyword else "ì œëª© ì œì•ˆ 3")
            tags = []
            if keyword:
                tags.append("#" + keyword.replace(" ", ""))
            for t in hashtags:
                if t not in tags:
                    tags.append(t)
            for extra in ["#ë‰´ìŠ¤", "#ì´ìŠˆ", "#ì •ë³´"]:
                if len(tags) >= 5: break
                if extra not in tags:
                    tags.append(extra)
            if len(tags) < 3:
                tags = (tags + ["#ë‰´ìŠ¤", "#ì •ë³´", "#ì—…ë°ì´íŠ¸"])[:3]
            tags = tags[:5]
            return "[ì œëª©]\n{}\n{}\n{}\n\n[í•´ì‹œíƒœê·¸]\n{}\n\n[ë³¸ë¬¸]\n{}".format(
                _truncate(t1, 35), _truncate(t2, 35), _truncate(t3, 35),
                " ".join(tags),
                (body or "").strip()
            )

    has_title = "[ì œëª©]" in text
    has_tags  = "[í•´ì‹œíƒœê·¸]" in text
    has_body  = "[ë³¸ë¬¸]" in text
    if has_title and has_tags and has_body:
        return text

    body_match = re.search(r"\[ë³¸ë¬¸\]\s*(.*)\Z", text, flags=re.S)
    body = body_match.group(1).strip() if body_match else text
    found_tags = list(dict.fromkeys(re.findall(r"#\S+", text)))[:5]
    base = _truncate(f"{keyword} {fallback_title}".strip(), 35) if fallback_title else _truncate(keyword, 35)
    title1 = base or "ì œëª© ì œì•ˆ 1"
    title2 = _truncate(f"{keyword} í•µì‹¬ ì •ë¦¬", 35) if keyword else "ì œëª© ì œì•ˆ 2"
    title3 = _truncate(f"{keyword} í–‰ë³´ ì—…ë°ì´íŠ¸", 35) if keyword else "ì œëª© ì œì•ˆ 3"
    tags = []
    if keyword:
        tags.append("#" + keyword.replace(" ", ""))
    for t in found_tags:
        if t not in tags:
            tags.append(t)
    for extra in ["#ë‰´ìŠ¤", "#ì´ìŠˆ", "#ì •ë³´"]:
        if len(tags) >= 5: break
        if extra not in tags:
            tags.append(extra)
    if len(tags) < 3:
        tags = (tags + ["#ë‰´ìŠ¤", "#ì •ë³´", "#ì—…ë°ì´íŠ¸"])[:3]
    tags = tags[:5]
    rebuilt = []
    rebuilt.append("[ì œëª©]"); rebuilt.append(title1); rebuilt.append(title2); rebuilt.append(title3)
    rebuilt.append(""); rebuilt.append("[í•´ì‹œíƒœê·¸]"); rebuilt.append(" ".join(tags))
    rebuilt.append(""); rebuilt.append("[ë³¸ë¬¸]"); rebuilt.append(body.strip())
    return "\n".join(rebuilt).strip()

# ======================================================
# í™˜ê²½/ì„¤ì •
# ======================================================
def _ensure_env_loaded():
    """ë‹¤ì–‘í•œ ë°°í¬ í™˜ê²½ì—ì„œ .envë¥¼ ì°¾ê³  GOOGLE_API_KEYë¥¼ ë¡œë“œ."""
    if os.getenv("GOOGLE_API_KEY"): return
    load_dotenv()
    if os.getenv("GOOGLE_API_KEY"): return
    module_dir = os.path.dirname(__file__)
    load_dotenv(os.path.join(module_dir, ".env"))
    if os.getenv("GOOGLE_API_KEY"): return
    if getattr(sys, "frozen", False):
        exe_dir = os.path.dirname(sys.executable)
        load_dotenv(os.path.join(exe_dir, ".env"))
    meipass = getattr(sys, "_MEIPASS", None)
    if meipass:
        load_dotenv(os.path.join(meipass, ".env"))

_ensure_env_loaded()

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError(".envì—ì„œ GOOGLE_API_KEYë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
genai.configure(api_key=api_key)

# âš ï¸ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ëŠ” generate_article ì•ˆì—ì„œ system_instructionê³¼ í•¨ê»˜ ìƒì„± (ìˆ˜ì •ì‚¬í•­ â‘¡)
# model = genai.GenerativeModel("gemini-2.5-flash")

FAST_MODE = os.getenv("FAST_MODE", "0") == "1"
LOG_LEVEL = os.getenv("NEWS_LOG_LEVEL", "INFO").upper()

def _safe_keyword(name: str) -> str:
    """íŒŒì¼ëª… ì•ˆì „í™”ë¥¼ ìœ„í•´ í‚¤ì›Œë“œì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ê³  ê³µë°±ì€ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½."""
    name = "".join(c for c in name if c.isalnum() or c in (" ", "-", "_")).strip()
    return name.replace(" ", "_") or "log"

def _get_base_dir() -> Path:
    """PyInstaller ì‹¤í–‰ íŒŒì¼/ì¼ë°˜ ì‹¤í–‰ êµ¬ë¶„í•˜ì—¬ ê¸°ì¤€ ë””ë ‰í† ë¦¬ ê²°ì •."""
    if getattr(sys, "frozen", False):
        return Path(sys.executable).parent
    return Path.cwd()

def setup_logging(keyword: str) -> tuple[logging.Logger, str]:
    """í‚¤ì›Œë“œ ê¸°ë°˜ íŒŒì¼ ë¡œê·¸ + ì½˜ì†” ë¡œê·¸ ì„¤ì •ì„ ìƒì„±í•˜ê³  ë°˜í™˜."""
    current_date = datetime.now().strftime("%Y%m%d")
    base_dir = _get_base_dir()
    log_dir = base_dir / "ê¸°ì‚¬ ì¬ìƒì„±" / f"ì¬ìƒì„±{current_date}"
    log_dir.mkdir(parents=True, exist_ok=True)

    safe_keyword = _safe_keyword(keyword)
    # Use distinct suffix to avoid collision with finalized article files
    log_filepath = str(log_dir / f"{safe_keyword}_log.txt")

    logger_name = f"news_llm_{safe_keyword}"
    logger = logging.getLogger(logger_name)

    level_map = {"DEBUG": logging.DEBUG, "INFO": logging.INFO, "WARNING": logging.WARNING, "ERROR": logging.ERROR}
    logger.setLevel(level_map.get(LOG_LEVEL, logging.INFO))

    if not logger.handlers:
        fh = logging.FileHandler(log_filepath, encoding="utf-8")
        fh.setLevel(level_map.get(LOG_LEVEL, logging.INFO))
        fh.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        ch = logging.StreamHandler()
        ch.setLevel(level_map.get(LOG_LEVEL, logging.INFO))
        ch.setFormatter(logging.Formatter("%(message)s"))

        logger.addHandler(fh)
        logger.addHandler(ch)

    return logger, log_filepath

def log_and_print(logger, message: str, level: str = "info"):
    """loggerì™€ ì½˜ì†”ì— ë™ì‹œì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥."""
    if level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "debug":
        logger.debug(message)

# ======================================================
# ê¸°ì‚¬ ì¶”ì¶œê¸°
# ======================================================
def extract_title_and_body(url, logger=None):
    """
    newspaper3kë¡œ 1ì°¨ íŒŒì‹±ì„ ì‹œë„í•˜ê³ , ë³¸ë¬¸ì´ ì§§ìœ¼ë©´ ë„¤ì´ë²„ CP ì „ìš© íŒŒì„œë¡œ í´ë°±.
    ë„¤íŠ¸ì›Œí¬/íŒŒì‹± ì˜ˆì™¸ëŠ” ë‚´ë¶€ì—ì„œ ì²˜ë¦¬í•˜ì—¬ í•˜ìœ„ ë‹¨ê³„ê°€ ê³„ì† ì§„í–‰ë˜ë„ë¡ ë³´ê°•. (ìˆ˜ì •ì‚¬í•­ â‘£)
    """
    if logger:
        log_and_print(logger, f"\n  ğŸ“„ ê¸°ì‚¬ ì¶”ì¶œ ì„¸ë¶€ ê³¼ì •:")
        log_and_print(logger, f"    - newspaper ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê¸°ì‚¬ ë‹¤ìš´ë¡œë“œ ì‹œë„...")

    title, body = "", ""

    # 1) newspaper ì‹œë„
    try:
        article = Article(url, language='ko')
        article.download()
        article.parse()
        title = (article.title or "").strip()
        body = (article.text or "").strip()
        if logger:
            log_and_print(logger, f"    - ë‹¤ìš´ë¡œë“œëœ ì œëª©: {title}")
            log_and_print(logger, f"    - ë‹¤ìš´ë¡œë“œëœ ë³¸ë¬¸ ê¸¸ì´: {len(body)}ì")
    except Exception as e:
        if logger:
            log_and_print(logger, f"    âš ï¸ newspaper ì²˜ë¦¬ ì‹¤íŒ¨: {e}", "warning")

    # 2) ë³¸ë¬¸ ê¸¸ì´ ë¯¸ë‹¬ â†’ í´ë°±
    if len(body) < 50:
        if logger:
            log_and_print(logger, f"    âš ï¸ ë³¸ë¬¸ì´ ì§§ì•„ fallbackìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.", "warning")
            log_and_print(logger, f"    - fallback: extract_naver_cp_article() í˜¸ì¶œ...")
        try:
            t2, b2 = extract_naver_cp_article(url, logger)
            title = t2 or title or "ì œëª© ì—†ìŒ"
            body = b2 or body or ""
            if logger:
                log_and_print(logger, f"    - fallback ê²°ê³¼ ì œëª©: {title}")
                log_and_print(logger, f"    - fallback ê²°ê³¼ ë³¸ë¬¸ ê¸¸ì´: {len(body)}ì")
        except Exception as e:
            if logger:
                log_and_print(logger, f"    âš ï¸ fallback ì¤‘ ì˜ˆì™¸: {e}", "warning")
    else:
        if logger:
            log_and_print(logger, f"    âœ… ë³¸ë¬¸ ê¸¸ì´ ì¶©ë¶„ - newspaper ê²°ê³¼ ì‚¬ìš©")

    return title, body

def extract_naver_cp_article(url, logger=None):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤(CP) êµ¬ì¡°ì— ë§ì¶˜ ê°„ë‹¨ íŒŒì„œ.
    (5ë²ˆ í•­ëª©ì˜ HTTP ìƒíƒœ/ì˜ˆì™¸ í™•ì¥ì€ ì´ë²ˆ ìš”ì²­ì—ì„œ ì œì™¸)
    """
    if logger:
        log_and_print(logger, f"      ğŸ”„ ë„¤ì´ë²„ CP ê¸°ì‚¬ fallback ì²˜ë¦¬:")
        log_and_print(logger, f"        - requestsë¡œ HTML ì§ì ‘ ë‹¤ìš´ë¡œë“œ...")
    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(url, headers=headers, timeout=7)
    soup = BeautifulSoup(res.text, 'html.parser')
    if logger:
        log_and_print(logger, f"        - HTML ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(res.text)}ì")
    title_tag = soup.select_one('h2.media_end_head_headline')
    title = title_tag.text.strip() if title_tag else "ì œëª© ì—†ìŒ"
    if logger:
        log_and_print(logger, f"        - ì œëª© íƒœê·¸ ê²€ìƒ‰ ê²°ê³¼: {'ì°¾ìŒ' if title_tag else 'ì°¾ì§€ ëª»í•¨'}")
        log_and_print(logger, f"        - ì¶”ì¶œëœ ì œëª©: {title}")
    body_area = soup.select_one('article#dic_area')
    body = body_area.get_text(separator="\n").strip() if body_area else "ë³¸ë¬¸ ì—†ìŒ"
    if logger:
        log_and_print(logger, f"        - ë³¸ë¬¸ ì˜ì—­ ê²€ìƒ‰ ê²°ê³¼: {'ì°¾ìŒ' if body_area else 'ì°¾ì§€ ëª»í•¨'}")
        log_and_print(logger, f"        - ì¶”ì¶œëœ ë³¸ë¬¸ ê¸¸ì´: {len(body)}ì")
    return title, body

# ======================================================
# í”„ë¡¬í”„íŠ¸ (ë³€ê²½ ê¸ˆì§€)
# ======================================================
def generate_system_prompt(keyword: str, today_kst: str, published_kst: str | None = None) -> str:
    """ì‹œì œ ê·œì¹™/ì¶œë ¥ í˜•ì‹ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ë‚´ìš© ë³€ê²½ ê¸ˆì§€)."""
    prompt = (
        f"""
        [System message]
        - í‚¤ì›Œë“œ, ê¸°ì‚¬ ì œëª©,  ë³¸ë¬¸ ìˆœìœ¼ë¡œ ì‚¬ìš©ìê°€ ì…ë ¥í•œë‹¤.
        - **ìµœì¢… ì¶œë ¥ì€ [ì œëª©], [í•´ì‹œíƒœê·¸], [ë³¸ë¬¸]ì˜ ì„¸ ì„¹ì…˜ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ë°˜ë“œì‹œ ì‘ì„±í•  ê²ƒ.** [Role]
        - ë‹¹ì‹ ì€ ì œê³µëœ ê¸°ì‚¬ ì œëª©ê³¼ ë³¸ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì‹¤ì„ ìœ ì§€í•˜ë©° ì¬êµ¬ì„±í•˜ëŠ” ì „ë¬¸ ê¸°ìì´ì ì—ë””í„°ì´ë‹¤.
        - ìµœìš°ì„  ëª©í‘œëŠ” ì‚¬ì‹¤ ì™œê³¡ ì—†ì´ ê°€ë…ì„±ê³¼ ë…¼ë¦¬ ì „ê°œë¥¼ ê°œì„ í•˜ê³ , ì˜¤ëŠ˜(KST) ê¸°ì¤€ìœ¼ë¡œ ì‹œì œë¥¼ ì¼ê´€ë˜ê²Œ ë§ì¶”ëŠ” ê²ƒì´ë‹¤.
        - ë³¸ë¬¸ ì‘ì„± ì „ 1) [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼] 2) [ì‹œì œ ë³€í™˜ ê·œì¹™], 3) [News Generation Process], 4) [ì¶œë ¥ í˜•ì‹]ì„ ë°˜ë“œì‹œ í™•ì¸í•˜ê³  ì¤€ìˆ˜í•œë‹¤.
        - ì¶”ì¸¡/ì „ë§ì„± í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ë¬¸ì²´ëŠ” ì¼ê´€ëœ ê¸°ì‚¬ ë¬¸ì²´(~ì´ë‹¤/~í–ˆë‹¤)ë¡œ ì‘ì„±í•˜ë©° Markdown ë¬¸ë²•ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.

        [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]
        - ì˜¤ëŠ˜ ë‚ ì§œ(Asia/Seoul): {today_kst}
        - ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): {published_kst or 'íŒŒì•… ë¶ˆê°€'}

        [ì‹œì œ ë³€í™˜ ê·œì¹™]
        - ì›ë¬¸ì— í¬í•¨ëœ ë‚ ì§œ/ì‹œê°„ í‘œí˜„, ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼ê³¼ [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì„ ë¹„êµí•˜ì—¬ ì‹œì œ ë° ë‚ ì§œ í‘œí˜„ì„ í˜„ì¬ ê¸°ì‚¬ë¥¼ ì‘ì„±í•˜ëŠ” ì‹œì ì— ë§ê²Œ ì¼ê´€ë˜ê²Œ ì¡°ì •í•œë‹¤.
        - ë‚ ì§œê°€ ì´ë¯¸ ì§€ë‚œ ì‹œì  í˜¹ì€ ì´ë¯¸ ë°œìƒí•œ ì‚¬ì‹¤ì€ ê³¼ê±° ì‹œì œ(â€¦í–ˆë‹¤/â€¦ì´ì—ˆë‹¤), ì§„í–‰ ì¤‘ì¸ ì‚¬ì‹¤ì€ í˜„ì¬ ì‹œì œ(â€¦í•œë‹¤), ì˜ˆì •ëœ ì‚¬ì‹¤ì€ ë¯¸ë˜ ì§€í–¥ ì„œìˆ (â€¦í•  ì˜ˆì •ì´ë‹¤/â€¦ë¡œ ì˜ˆì •ë¼ ìˆë‹¤)ë¡œ ê¸°ìˆ í•œë‹¤.
        - ì¶”ì¸¡ì„± í‘œí˜„(â€¦í•  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤, â€¦ì „ë§ì´ë‹¤)ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.
        - ë‚ ì§œë¥¼ ë…¸ì¶œí•  í•„ìš”ê°€ ì—†ìœ¼ë©´ ì§ì ‘ì ì¸ ë‚ ì§œ í‘œê¸°ëŠ” í”¼í•˜ê³ , 'ë‹¹ì‹œ', 'ì´í›„', 'ì´ì „', 'ê°™ì€ ë‚ 'ê³¼ ê°™ì€ ìƒëŒ€ì  ì‹œê°„ í‘œí˜„ì„ ì‚¬ìš©í•œë‹¤.
        - ì¸ìš©ë¬¸ ë‚´ì˜ ë‚ ì§œë¥¼ ì œì™¸í•˜ê³  ë‚ ì§œê°€ ì£¼ì–´ì§€ëŠ” ê²½ìš° ì‹œì œë¥¼ ì•„ë˜ ê·œì¹™ê³¼ ê°™ì´ ë³€ê²½í•œë‹¤. 
        - [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì„ ê¸°ì¤€ìœ¼ë¡œ ë™ì¼ ì¼ì˜ ê²½ìš° "Oì¼"ë¡œ í‘œê¸°í•œë‹¤. "Oì›” Oì¼", "ì˜¤ëŠ˜ OOì¼", "ì˜¤ëŠ˜(OOì¼)" ë“±ì˜ í‘œí˜„ ê¸ˆì§€.
        - [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì„ ê¸°ì¤€ìœ¼ë¡œ ë™ì¼ ì›”ì˜ ê³¼ê±°ì¸ ê²½ìš° "Oì›” Oì¼, Oì¼ -> ì§€ë‚œ Oì¼", ë™ì¼ ì›”ì˜ ë¯¸ë˜ì¸ ê²½ìš° "Oì›” Oì¼, Oì¼ -> ì˜¤ëŠ” Oì¼"ë¡œ í‘œê¸°í•œë‹¤.
        - [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì„ ê¸°ì¤€ìœ¼ë¡œ ì§ì „ ì›”ì¸ ê³¼ê±°ì¸ ê²½ìš°(ì˜ˆ: [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì´ 2025ë…„ 9ì›” 1ì¼ì¸ ê²½ìš°, 2025ë…„ 8ì›” 20ì¼ -> ì§€ë‚œë‹¬ 20ì¼) "Oì›” Oì¼, Oì¼ -> ì§€ë‚œë‹¬ Oì¼"ë¡œ í‘œê¸°í•œë‹¤.
        - [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì„ ê¸°ì¤€ìœ¼ë¡œ ë…„ë„ê°€ ì£¼ì–´ì§„ ê³¼ê±°ì¸ ê²½ìš° "OOOOë…„ Oì›” Oì¼, "OOOOë…„" -> ì§€ë‚œ OOOOë…„, "ì§€ë‚œ OOOOë…„ Oì›” Oì¼"ìœ¼ë¡œ í‘œê¸°í•œë‹¤.
        - [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì„ ê¸°ì¤€ìœ¼ë¡œ ë…„ë„ê°€ ì£¼ì–´ì§„ ë¯¸ë˜ì¸ ê²½ìš° "OOOOë…„ Oì›” Oì¼, "OOOOë…„" -> ì˜¤ëŠ” OOOOë…„, "ì˜¤ëŠ” OOOOë…„ Oì›” Oì¼"ìœ¼ë¡œ í‘œê¸°í•œë‹¤.

        [News Generation Process]
        1. ì œëª© ìƒì„± 
        - ìš°ì„ ìˆœìœ„: **1. ì…ë ¥ëœ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ê³ , 2. ì œê³µëœ ê¸°ì‚¬ ì œëª©ì„ ì¸ìš©í•˜ê³ , 3. ë³¸ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ 3ê°œì˜ ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ì œëª©ì„ ìƒì„±í•œë‹¤.**
        - **í‚¤ì›Œë“œëŠ” ìµœëŒ€í•œ ì•ìª½ì— ë°°ì¹˜í•˜ê³ , ê´€ë ¨ì„±ì´ ì ì–´ë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ë„ë¡ ì‘ì„±í•œë‹¤.**.
        - ì œëª© ìœ í˜•ì€ ë‹¤ìŒê³¼ ê°™ì´ ë‹¤ì–‘ì„±ì„ í™•ë³´í•œë‹¤:
        * 1ë²ˆ ì œëª©: í•µì‹¬ ì‚¬ì‹¤ì„ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•˜ëŠ” ì „í†µì  ë‰´ìŠ¤ ì œëª©
        * 2ë²ˆ ì œëª©: ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” ì°½ì˜ì ì¸ ì œëª©
        * 3ë²ˆ ì œëª©: ê¸°ì‚¬ ë‚´ìš©ì˜ í•µì‹¬ ê°€ì¹˜ë‚˜ ì˜í–¥ë ¥ì„ ê°•ì¡°í•˜ëŠ” ì œëª©
        - 25~40ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê³  ê°•ë ¬í•œ ì¸ìƒì„ ì£¼ë„ë¡ ì‘ì„±í•œë‹¤.
        - ë¬¸ì¥ ë¶€í˜¸ëŠ” ìµœì†Œí™”í•˜ê³ , í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‰¼í‘œ(,)ë¥¼ ì‚¬ìš©í•œë‹¤.
        - ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” í‘œí˜„ ê¸ˆì§€ (ì˜ˆ: '?', 'ì™œ', 'ì–´ë–»ê²Œ', 'ë¬´ì—‡ì´' ë“± ì‚¬ìš© ê¸ˆì§€)
        - ì‚¬ìš© ê¸ˆì§€ ê¸°í˜¸: ë§ˆì¹¨í‘œ(.), ì½œë¡ (:), ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(*, #, &), Markdown ë¬¸ë²•
        - ì‚¬ìš© ê°€ëŠ¥ ê¸°í˜¸: ì‰¼í‘œ(,), ë”°ì˜´í‘œ(' '), ìŒë”°ì˜´í‘œ(" ") 

        2. ë³¸ë¬¸ ìƒì„±: ì…ë ¥ëœ ê¸°ì‚¬ ë³¸ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ ë‹´ì€ ê°„ê²°í•œ ê¸°ì‚¬ë¥¼ ì‘ì„±í•œë‹¤.
        - **ì´ ê³¼ì •ì—ì„œ ì›ë¬¸ì˜ í•µì‹¬ ì‚¬ì‹¤ê´€ê³„(ì¸ìš©ë¬¸, ë°œì–¸ ëŒ€ìƒ, ë°œì–¸ ë‚´ìš©, í‘œí˜„, ë‚ ì§œ, ì œê³µëœ ì£¼ìš” ìˆ˜ì¹˜ ë“±ì˜ í•µì‹¬ ì •ë³´)ê°€ ëˆ„ë½ë˜ì§€ ì•Šë„ë¡ ê°ë³„íˆ ìœ ì˜í•  ê²ƒ. ëª©í‘œëŠ” ì‚¬ì‹¤ì„ ìœ ì§€í•œ ì •ë³´ì˜ ì†ì‹¤ ì—†ëŠ” ì••ì¶•ì´ë‹¤.**
        - **ê³µë°± í¬í•¨ 300~900ì ë‚´ì™¸ë¡œ ì™„ì„±** (ì ˆëŒ€ 1000ì ì´ˆê³¼ ê¸ˆì§€, ì›ë¬¸ì´ ì§§ìœ¼ë©´ ë¶ˆí•„ìš”í•œ ë‚´ìš© ì¶”ê°€ ê¸ˆì§€)
        - ì¶œë ¥ ì§ì „ì— ìŠ¤ìŠ¤ë¡œ ê¸€ììˆ˜ë¥¼ ì„¸ê³ , 900ìë¥¼ ë„˜ìœ¼ë©´ ë¬¸ì¥ì„ ì¤„ì—¬ 900ì ì´ë‚´ë¡œ ì¡°ì •í•œë‹¤.
        - í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ì „ë‹¬ (ì¤‘ë³µ ì œê±°, ì¥í™©í•œ ì„¤ëª… ìƒëµ)
        - **ì›ë¬¸ì˜ ì£¼ìš” ì‚¬ì‹¤ì€ ëª¨ë‘ í¬í•¨í•˜ë˜, í‘œí˜„ ë°©ì‹ì€ ì™„ì „íˆ ë³€ê²½**
        - ë¬¸ì¥ì€ ì§§ê³  ëª…í™•í•˜ê²Œ (í•œ ë¬¸ì¥ë‹¹ 15~20ì ë‚´ì™¸ ê¶Œì¥)
        - **ì¸ìš©ë¬¸ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€ (ë‹¨ì–´ í•˜ë‚˜ë„ ë³€ê²½ ê¸ˆì§€)**
        - ë¹„ê²©ì‹ì²´ë¥¼ (ì˜ˆ: "~ì´ë‹¤", "~í–ˆë‹¤", "~í•œë‹¤")ë¥¼ ì¼ê´€ë˜ê²Œ ì‚¬ìš©, **ì„œìˆ ì‹("~ìŠµë‹ˆë‹¤", "~ì…ë‹ˆë‹¤")í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.**
        - ë§ì¶¤ë²• ì •í™•íˆ ì¤€ìˆ˜
        - '...', '~~', '!!' ë“± ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€

        3. ì œëª© ë° ë³¸ë¬¸ ê²€í†  
        - ì œëª©ê³¼ ë³¸ë¬¸ì—ì„œ **ê¸ˆì§€ëœ ê¸°í˜¸(â€¦, *, #, &) ì‚¬ìš© ì—¬ë¶€ í™•ì¸ ë° ìˆ˜ì •
        - ì…ë ¥ëœ ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ì œê³µëœ ì •ë³´ ì™¸ ì¶”ì¸¡Â·í—ˆêµ¬Â·ì™¸ë¶€ ìë£Œ ì¶”ê°€ ì—¬ë¶€ ê²€í†  í›„ ìˆ˜ì •

        4. í‚¤ì›Œë“œ ìƒì„±
        - ìƒì„±ëœ ë³¸ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ 5ê°œ ë‚´ì™¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•œë‹¤.

        5. ì¶œë ¥í˜•ì‹ì— ë§ê²Œ ì¶œë ¥í•œë‹¤.  

        [ì¶œë ¥ í˜•ì‹]  

        - ì œëª© (3ê°œ ì œê³µ, ê° ì œëª© ë‹¹ ìµœëŒ€ 35ì ë‚´ì™¸)
        - í•´ì‹œíƒœê·¸ (5ê°œ ë‚´ì™¸)
        - ë³¸ë¬¸ ë‚´ìš©
        -**ì•„ë˜ ì˜ˆì‹œ í˜•ì‹ì„ ë°˜ë“œì‹œ, ê·¸ë¦¬ê³  ì •í™•íˆ ì¤€ìˆ˜í• ê²ƒ** 
        [ì œëª©]
        (ì—¬ê¸°ì— ìƒì„±í•œ ì œëª© 1)
        (ì—¬ê¸°ì— ìƒì„±í•œ ì œëª© 2)
        (ì—¬ê¸°ì— ìƒì„±í•œ ì œëª© 3)

        [í•´ì‹œíƒœê·¸]
        #(í•´ì‹œíƒœê·¸1) #(í•´ì‹œíƒœê·¸2) #(í•´ì‹œíƒœê·¸3) ...

        [ë³¸ë¬¸]
        (ê³µë°± í¬í•¨ 300~800ì ë‚´ì™¸ì˜ ë³¸ë¬¸ ë‚´ìš©)"""
    )
    return prompt


def _is_fact_ok_text(verdict: str) -> bool:
    """ì‚¬ì‹¤ê²€ì¦ ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ OKì¸ì§€ íŒë³„."""
    return (verdict or "").strip().upper() == "OK"

# Fast-Passì— í•„ìš”í•œ íŒ¨í„´
_NUM_PAT = re.compile(r"(?:\d{4}\.\d{1,2}\.\d{1,2}|\d{4}-\d{1,2}-\d{1,2}|\d{1,2}ì›”\s?\d{1,2}ì¼|\d{4}ë…„|\d{1,3}(?:,\d{3})+|\d+%|\d+ëª…|\d+ê±´|\d+ê°œ|\d+ì›|\d+ì–µ|\d+ì¡°|\d+íšŒ|\d+ì¼|\d+ì‹œê°„|\d+ë¶„|\d+ì´ˆ|\d+ì„¸|\d+ìœ„|\d+ì )")
_QUOTE_PAT = re.compile(r"[â€œâ€\"']([^â€œâ€\"']{2,200})[â€œâ€\"']")

def _extract_numbers(text: str) -> set[str]:
    """ë¬¸ì„œì—ì„œ ìˆ«ì/ë‹¨ìœ„ íŒ¨í„´ì„ ì°¾ì•„ ì§‘í•©ìœ¼ë¡œ ë°˜í™˜."""
    return set(m.group(0) for m in _NUM_PAT.finditer(text or ""))

def _extract_quotes(text: str) -> set[str]:
    """ë¬¸ì„œì—ì„œ ì¸ìš©ë¬¸(ë”°ì˜´í‘œ ë‚´ë¶€)ì„ ì¶”ì¶œí•´ ì§‘í•©ìœ¼ë¡œ ë°˜í™˜."""
    return set(m.group(1).strip() for m in _QUOTE_PAT.finditer(text or ""))

def _fast_pass_consistency(generated: str, original: str) -> bool:
    """
    Fast-Pass: ìƒì„±ë¬¸ì´ ì›ë¬¸ ìˆ«ì/ì¸ìš©ë¬¸ì„ 'ì´ˆê³¼'ë¡œ í¬í•¨í•˜ì§€ ì•Šìœ¼ë©´ í†µê³¼.
    - ìƒì„±ë¬¸ì— ìˆëŠ” ìˆ«ì/ì¸ìš©ì´ ì›ë¬¸ ì§‘í•©ì˜ ë¶€ë¶„ì§‘í•©ì´ë©´ True.
    """
    if not generated or not original:
        return False
    gen_nums = _extract_numbers(generated)
    org_nums = _extract_numbers(original)
    if gen_nums and not gen_nums.issubset(org_nums):
        return False
    gen_quotes = _extract_quotes(generated)
    org_quotes = _extract_quotes(original)
    if gen_quotes and not gen_quotes.issubset(org_quotes):
        return False
    return True

def _safe_response_text(resp) -> str:
    """
    Gemini ì‘ë‹µì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ë¥¼ êº¼ë‚¸ë‹¤. (ìˆ˜ì •ì‚¬í•­ â‘¢)
    - í›„ë³´ ì—†ìŒ/ì°¨ë‹¨ ë“±ìœ¼ë¡œ .textê°€ ë¹„ê±°ë‚˜ ì˜ˆì™¸ê°€ ë‚  ìˆ˜ ìˆì–´ ë°©ì§€.
    """
    try:
        if not getattr(resp, "candidates", None):
            return ""
        # ì•ˆì „ì„± ì°¨ë‹¨ ì—¬ë¶€ (ê°„ë‹¨ ì§„ë‹¨ìš©)
        safety = getattr(resp.candidates[0], "safety_ratings", None)
        if safety:
            blocked = any(getattr(r, "blocked", False) for r in safety)
            if blocked:
                return ""
        return getattr(resp, "text", "") or ""
    except Exception:
        return ""

# ======================================================
# ë©”ì¸
# ======================================================
def generate_article(state: dict) -> dict:
    """
    URL/í‚¤ì›Œë“œë¥¼ ë°›ì•„:
      1) ê¸°ì‚¬ ì¶”ì¶œ
      2) ë°œí–‰ì¼ ì¶”ì¶œ(ì„ í–‰) ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
      3) Geminië¡œ ê¸°ì‚¬ ì¬êµ¬ì„±
      4) Fast-Pass ë˜ëŠ” check_LLMë¡œ ì‚¬ì‹¤ê²€ì¦
      5) ê²°ê³¼/ë¡œê¹… ë°˜í™˜
    """
    url = state.get("url")
    keyword = state.get("keyword")

    t_total_start = perf_counter()  # â± ì´ ì†Œìš”ì‹œê°„ ì¸¡ì • ì‹œì‘
    logger, log_filepath = setup_logging(keyword or "ë¡œê·¸")

    title = (state.get("title") or "").strip()
    body = (state.get("body") or "").strip()

    try:
        log_and_print(logger, "\n" + "="*80)
        log_and_print(logger, "ğŸ“° NEWS_LLM - ê¸°ì‚¬ ì¬êµ¬ì„± ì‹œì‘")
        log_and_print(logger, "="*80)
        log_and_print(logger, f"\nğŸ“¥ ì…ë ¥ ë°ì´í„°:")
        log_and_print(logger, f"  - URL: {url}")
        log_and_print(logger, f"  - í‚¤ì›Œë“œ: {keyword}")
        log_and_print(logger, f"  - ë¡œê·¸ íŒŒì¼: {log_filepath}")

        # 1) ê¸°ì‚¬ ì¶”ì¶œ
        t_extract_start = perf_counter()
        if (not title or not body) or (len(body) < AU_MIN):
            log_and_print(logger, "\nğŸ”— ê¸°ì‚¬ ì¶”ì¶œ ë‹¨ê³„: ì™¸ë¶€ ì¶”ì¶œ ë¯¸í¡ â†’ article_utils ì‹œë„")
            if extract_article_content is not None:
                try:
                    t2, b2 = extract_article_content(url, progress_callback=None)
                    if len(b2 or "") >= AU_MIN:
                        title, body = t2, b2
                        log_and_print(logger, f"  âœ… article_utils ì„±ê³µ: ë³¸ë¬¸ {len(body)}ì")
                except Exception as e:
                    log_and_print(logger, f"  âš ï¸ article_utils ì‹¤íŒ¨: {e}", "warning")
        if not title or not body:
            log_and_print(logger, "  ğŸ” ë‚´ë¶€ ì¶”ì¶œê¸°ë¡œ í´ë°±")
            t3, b3 = extract_title_and_body(url, logger)
            if len((b3 or "")) > len(body or ""):
                title, body = t3, b3
        if not body:
            raise ValueError("ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: ë³¸ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        t_extract = perf_counter() - t_extract_start
        log_and_print(logger, f"â± ê¸°ì‚¬ ì¶”ì¶œ ë‹¨ê³„ ì†Œìš”: {t_extract:.2f}s")

        # 1.5) ğŸ†• ë°œí–‰ì¼ ì¶”ì¶œ â€”â€” ìƒì„± ì „ì— ìˆ˜í–‰ (ìˆ˜ì •ì‚¬í•­ â‘ )
        today_kst = get_today_kst_str()
        published_kst = None
        if extract_publish_datetime is not None:
            try:
                published_kst = extract_publish_datetime(url)
                if published_kst:
                    log_and_print(logger, f"ğŸ—“ï¸ ë°œí–‰ì¼ ì¶”ì¶œ ì„±ê³µ: {published_kst}")
                else:
                    log_and_print(logger, "ğŸ—“ï¸ ë°œí–‰ì¼ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸ì œê³µ")
            except Exception as e:
                log_and_print(logger, f"ğŸ—“ï¸ ë°œí–‰ì¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}", "warning")

        # 2) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± + ëª¨ë¸ êµ¬ì„± (system_instruction ì‚¬ìš© / ìˆ˜ì •ì‚¬í•­ â‘¡)
        system_prompt = generate_system_prompt(keyword or "", today_kst, published_kst)
        user_request = f"í‚¤ì›Œë“œ: {keyword}\nì œëª©: {title}\në³¸ë¬¸: {body}"

        model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            system_instruction=system_prompt
            # generation_config=GenerationConfig(
            #     max_output_tokens=
            # )
        )

        # 3) ìƒì„± í˜¸ì¶œ
        t_gen_start = perf_counter()
        log_and_print(logger, f"\nâ³ Gemini AI í˜¸ì¶œ ì¤‘... ëª¨ë¸: gemini-2.5-flash")
        # user ì…ë ¥ë§Œ ì „ë‹¬

        response = model.generate_content(user_request)

        # í† í° ê³„ì‚°
        usage = getattr(response, "usage_metadata", None)
        if usage:
            p = getattr(usage, "prompt_token_count", 0)
            c = getattr(usage, "candidates_token_count", 0)
            t = getattr(usage, "total_token_count", 0)
            th = getattr(usage, "thoughts_token_count", 0)  # âœ… ì‚¬ê³  í† í°
            tu = getattr(usage, "tool_use_prompt_token_count", 0)
            cc = getattr(usage, "cached_content_token_count", 0)
            resid = t - (p + c + th + tu)  # ë‚¨ëŠ”ë‹¤ë©´ API/ë²„ì „ë³„ ì§‘ê³„ ì°¨ì´
            log_and_print(logger,
                f"ğŸ§¾ í† í° ìƒì„¸ | ì…ë ¥={p}, ì¶œë ¥={c}, ìƒê°={th}, íˆ´í”„ë¡¬í”„íŠ¸={tu}, ìºì‹œ={cc}, í•©ê³„={t}, ì”ì°¨={resid}")
        else:
            log_and_print(logger, "ğŸ§¾ usage_metadata ì—†ìŒ", "warning")

        t_gen = perf_counter() - t_gen_start
        log_and_print(logger, f"â± ê¸°ì‚¬ ìƒì„± ì†Œìš”: {t_gen:.2f}s")

        # ì‘ë‹µ ì•ˆì „ ì¶”ì¶œ (ìˆ˜ì •ì‚¬í•­ â‘¢)
        article_text = _safe_response_text(response).strip()
        if not article_text:
            log_and_print(logger, "âš ï¸ LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ(ì°¨ë‹¨/ë¹ˆ í›„ë³´ ê°€ëŠ¥ì„±).", "warning")

        # ì„¹ì…˜ ê°•ì œ ë³´ì •
        article_text = ensure_output_sections(article_text, keyword or "", title)
        log_and_print(logger, f"\nğŸ“Š ê¸°ì‚¬ ê¸¸ì´ ë¹„êµ: ì›ë³¸ {len(body)}ì â†’ ì¬êµ¬ì„± {len(article_text)}ì")

        # 4) ì‚¬ì‹¤ê²€ì¦(Fast-Pass ìš°ì„ )
        if FAST_MODE and _fast_pass_consistency(article_text, body):
            # (ìˆ˜ì •ì‚¬í•­ â‘§) Fast-Pass ë‚´ë¶€ ì§„ë‹¨ ë¡œê·¸ ê°•í™”
            log_and_print(
                logger,
                f"âš¡ FAST-PASS í†µê³¼ â†’ nums={_extract_numbers(article_text)} quotes={_extract_quotes(article_text)}"
            )
            verdict = "OK"
            corrected_article = ""
            display_text = article_text
            display_kind = "article"
        else:
            t_fc_start = perf_counter()
            log_and_print(logger, f"\nğŸ” ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ë‹¨ê³„: check_LLM.check_article_facts í˜¸ì¶œ")
            check_res = check_LLM.check_article_facts(
                article_text,
                body,
                (keyword or "check_LLM"),
                source_url=url,                  # ì›ë¬¸ ë§í¬ ì „ë‹¬ (ë¡œê¹…/ì¶”ì ìš©)
                published_kst=published_kst,     # ì‹œì œ ì°¸ê³ ìš©
            )
            t_factcheck = perf_counter() - t_fc_start
            log_and_print(logger, f"â± ì‚¬ì‹¤ê²€ì¦ ì†Œìš”: {t_factcheck:.2f}s")

            verdict = ""
            corrected_article = ""
            explanation = ""
            if isinstance(check_res, dict):
                json_obj = check_res.get("json")
                explanation = check_res.get("explanation", "")
                if json_obj:
                    if isinstance(json_obj, str):
                        try:
                            parsed = json.loads(json_obj)
                        except Exception:
                            parsed = None
                        if isinstance(parsed, dict):
                            verdict_val = parsed.get("verdict", "")
                            corrected_article_val = parsed.get("corrected_article", "")
                        else:
                            verdict_val = ""
                            corrected_article_val = ""
                    else:
                        verdict_val = json_obj.get("verdict", "")
                        corrected_article_val = json_obj.get("corrected_article", "")
                    verdict = str(verdict_val or "").strip().upper()
                    corrected_article = str(corrected_article_val or "").strip()

            if _is_fact_ok_text(verdict):
                display_text = article_text
                display_kind = "article"
                log_and_print(logger, "  âœ… ì‚¬ì‹¤ê´€ê³„ ì´ìƒ ì—†ìŒ â†’ ê¸°ì‚¬ ì±„íƒ")
            else:
                if verdict == "ERROR" and corrected_article:
                    display_text = corrected_article
                    display_kind = "article"
                    log_and_print(logger, "  âœï¸ ì˜¤ë¥˜ ë°œê²¬ + êµì •ë³¸ ì œê³µ â†’ êµì • ê¸°ì‚¬ ì±„íƒ")
                else:
                    warn = "[ì‚¬ì‹¤ê²€ì¦]\nê²€ì¦ ê²½ê³  ë˜ëŠ” íŒŒì‹± ì‹¤íŒ¨\n\n" + (explanation or "ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    display_text = warn
                    display_kind = "fact_check"
                    log_and_print(logger, "  âš ï¸ ì‚¬ì‹¤ê´€ê³„ ì´ìŠˆ ë˜ëŠ” ê²€ì¦ ì‹¤íŒ¨ â†’ fact_check í‘œì¶œ")

        result = {
            "url": url,
            "keyword": keyword,
            "title": title,
            "original_body": body,
            "generated_article": article_text,
            "fact_check_result": verdict or "UNKNOWN",
            "corrected_article": corrected_article if not FAST_MODE else "",
            "display_text": display_text,
            "display_kind": display_kind,
            "error": None
        }

        log_and_print(logger, f"\nğŸ“‹ display_kind: {display_kind}")
        t_total = perf_counter() - t_total_start
        log_and_print(logger, f"â± ì´ ì²˜ë¦¬ ì‹œê°„: {t_total:.2f}s")
        log_and_print(logger, "\n" + "="*80)
        log_and_print(logger, "ğŸ“° NEWS_LLM - ê¸°ì‚¬ ì¬êµ¬ì„± ì™„ë£Œ")
        log_and_print(logger, "="*80)

        # Windowsì—ì„œ ë¡œê·¸ íŒŒì¼ ìë™ ì˜¤í”ˆì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ê¸°ì‚¬ íŒŒì¼ê³¼ í˜¼ë™ ë°©ì§€)
        # if os.name == 'nt' and 'log_filepath' in locals() and os.path.exists(log_filepath):
        #     try:
        #         os.startfile(log_filepath)
        #         log_and_print(logger, f"\nğŸ“‚ ìƒì„±ëœ íŒŒì¼ì„ ì—½ë‹ˆë‹¤: {log_filepath}")
        #     except Exception as e:
        #         log_and_print(logger, f"\nâš ï¸ íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", "warning")

        return result

    except Exception as e:
        try:
            log_and_print(logger, f"\nâŒ ì˜ˆì™¸ ë°œìƒ: {str(e)}", "error")
            t_total = perf_counter() - t_total_start
            log_and_print(logger, f"â± ì´ ì²˜ë¦¬ ì‹œê°„(ì˜ˆì™¸ ë°œìƒ): {t_total:.2f}s", "error")
            log_and_print(logger, "\n" + "="*80, "error")
            log_and_print(logger, "ğŸ“° NEWS_LLM - ê¸°ì‚¬ ì¬êµ¬ì„± ì‹¤íŒ¨", "error")
            log_and_print(logger, "="*80, "error")
        except Exception:
            pass

        return {
            "url": state.get("url"),
            "keyword": state.get("keyword"),
            "title": state.get("title") or "",
            "original_body": state.get("body") or "",
            "generated_article": "",
            "fact_check_result": "",
            "display_text": f"ì˜¤ë¥˜: {str(e)}",
            "display_kind": "error",
            "error": str(e)
        }

if __name__ == "__main__":
    print("ğŸ”— ê¸°ì‚¬ URLê³¼ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ Geminiê°€ ì¬ì‘ì„±í•œ ê¸°ì‚¬ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.")
    url = input("ê¸°ì‚¬ URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    keyword = input("í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

    print(f"\nğŸ“ í‚¤ì›Œë“œ: {keyword}")
    print(f"ğŸ”— URL: {url}")
    print("="*50)
    print("ì²˜ë¦¬ ê³¼ì •ì´ ì‹œì‘ë©ë‹ˆë‹¤. ëª¨ë“  ê³¼ì •ì€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.")
    print("="*50)

    result = generate_article({"url": url, "keyword": keyword})

    if result["error"]:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", result["error"])
    else:
        print("\nâœ… ê²°ê³¼:\n")
        print(result["display_text"])
        print(f"\nğŸ“ ë¡œê·¸ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
