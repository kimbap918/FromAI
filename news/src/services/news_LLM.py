# news_LLM.py â€” ì†ë„Â·ë¡œê¹… ë³´ê°• + Fast-Pass/Trimmed Compare ì—°ë™
import os
import sys
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
from newspaper import Article
from dotenv import load_dotenv
from datetime import datetime
import logging
from pathlib import Path
from news.src.utils.common_utils import get_today_kst_str 
from time import perf_counter
 


try:
    from news.src.utils.article_utils import extract_article_content, MIN_BODY_LENGTH as AU_MIN, extract_publish_datetime
except Exception:
    extract_article_content = None
    extract_publish_datetime = None
    AU_MIN = 300

try:
    from . import check_LLM
except ImportError:
    import check_LLM

import re
import json


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ``` ë˜ëŠ” ```json ì½”ë“œíœìŠ¤ë¥¼ ì œê±°í•´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
# ------------------------------------------------------------------
def _strip_code_fences(s: str) -> str:
    """``` ë˜ëŠ” ```json ì½”ë“œíœìŠ¤ë¥¼ ì œê±°í•´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    if not isinstance(s, str):
        return s
    s = s.strip()
    s = re.sub(r"^```(?:json)?\s*\n?", "", s, flags=re.I)
    s = re.sub(r"\n?```$", "", s, flags=re.I)
    return s.strip()

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë¬¸ìì—´ì´ JSONì´ë©´ íŒŒì‹±í•´ dict/list ë°˜í™˜, ì•„ë‹ˆë©´ None
# ------------------------------------------------------------------
def _json_loads_maybe(s: str):
    """ë¬¸ìì—´ì´ JSONì´ë©´ íŒŒì‹±í•´ì„œ dict/ë¦¬ìŠ¤íŠ¸ ë°˜í™˜, ì•„ë‹ˆë©´ None."""
    if not isinstance(s, str):
        return None
    try:
        return json.loads(_strip_code_fences(s))
    except Exception:
        return None

def ensure_output_sections(article_text: str, keyword: str, fallback_title: str) -> str:
    """
    LLMì˜ ì¶œë ¥ì´ ì§€ì •ëœ ì„¹ì…˜ í˜•ì‹([ì œëª©]/[í•´ì‹œíƒœê·¸]/[ë³¸ë¬¸])ì„ ë”°ë¥´ì§€ ì•ŠëŠ” ê²½ìš°ì—ë„
    ì•ˆì „í•˜ê²Œ ì¬êµ¬ì„±í•˜ì—¬ ì¼ê´€ëœ ê²°ê³¼ë¥¼ ë°˜í™˜

    - JSON í˜•íƒœì˜ ì‘ë‹µ(text ë‚´ ì½”ë“œíœìŠ¤ í¬í•¨ ê°€ëŠ¥)ë„ ê°ì§€í•˜ì—¬ ì ì ˆí•œ í‚¤ë¥¼ ë§¤í•‘í•´ ë³µì›í•œë‹¤.
    - ì„¹ì…˜ì´ ëˆ„ë½ë˜ê±°ë‚˜ ìˆœì„œ/í˜•ì‹ì´ ê¹¨ì§„ ê²½ìš° ê¸°ë³¸ ê·œì¹™ê³¼ í‚¤ì›Œë“œ ê¸°ë°˜ì˜ í•©ë¦¬ì  ê¸°ë³¸ê°’ì„ ì±„ì›Œ ë„£ëŠ”ë‹¤.

    :param article_text: LLMì´ ìƒì„±í•œ ì›ë¬¸ í…ìŠ¤íŠ¸(ììœ  í˜•ì‹ ë˜ëŠ” JSON/ì½”ë“œíœìŠ¤ í¬í•¨ ê°€ëŠ¥)
    :param keyword: ì œëª©/í•´ì‹œíƒœê·¸ ë³µì› ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•  í‚¤ì›Œë“œ
    :param fallback_title: ì…ë ¥ ê¸°ì‚¬ì—ì„œ ì–»ì€ ì œëª©(ì—†ì„ ìˆ˜ ìˆìŒ). ì œëª© ë³µì› ì‹œ ì°¸ê³ 
    :return: [ì œëª©]\n(ì œëª©1)\n(ì œëª©2)\n(ì œëª©3)\n\n[í•´ì‹œíƒœê·¸]\n#... #...\n\n[ë³¸ë¬¸]\n... í˜•ì‹ì˜ ë¬¸ìì—´
    """
    if not article_text:
        article_text = ""
    text = article_text.strip()

    def build_output(titles: list[str], tags: list[str], body_text: str) -> str:
        lines: list[str] = ["[ì œëª©]"]
        if titles:
            lines.extend(titles)
        lines += ["", "[í•´ì‹œíƒœê·¸]", " ".join(tags), "", "[ë³¸ë¬¸]", (body_text or "").strip()]
        return "\n".join(lines).strip()

    def norm_tags(raw_tags: list[str]) -> list[str]:
        # í‚¤ì›Œë“œë¥¼ ìš°ì„  í¬í•¨, ì¤‘ë³µ ì œê±°, ìµœëŒ€ 5ê°œ ìœ ì§€. ê¸°ë³¸ ë³´ì¡° íƒœê·¸ë¡œ 3ê°œ ì±„ì›€
        tags: list[str] = []
        if keyword:
            tags.append("#" + keyword.replace(" ", ""))
        for t in raw_tags:
            if t not in tags:
                tags.append(t)
        for extra in ("#ë‰´ìŠ¤", "#ì´ìŠˆ", "#ì •ë³´"):
            if len(tags) >= 5: break
            if extra not in tags:
                tags.append(extra)
        if len(tags) < 3:
            tags = (tags + ["#ë‰´ìŠ¤", "#ì •ë³´", "#ì—…ë°ì´íŠ¸"])[:3]
        return tags[:5]

    # 1) ì„¹ì…˜ì´ ì´ë¯¸ ëª¨ë‘ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if "[ì œëª©]" in text and "[í•´ì‹œíƒœê·¸]" in text and "[ë³¸ë¬¸]" in text:
        return text.strip()

    # 2) JSON ì‘ë‹µì´ë©´ í‚¤ ë§¤í•‘ë§Œ ìˆ˜í–‰
    obj = _json_loads_maybe(text)
    if isinstance(obj, dict):
        get = obj.get
        # ì œëª© ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”
        titles_field = get("titles") or get("title_list") or get("title")
        titles: list[str] = []
        if isinstance(titles_field, list):
            titles = [str(x).strip() for x in titles_field if str(x).strip()][:3]
        elif isinstance(titles_field, str) and titles_field.strip():
            titles = [titles_field.strip()]

        # í•´ì‹œíƒœê·¸ ì •ê·œí™”
        tags_field = get("hashtags") or get("tags")
        raw_tags: list[str] = []
        if isinstance(tags_field, list):
            raw_tags = ["#" + str(x).strip().lstrip("#").replace(" ", "") for x in tags_field if str(x).strip()]
        elif isinstance(tags_field, str) and tags_field.strip():
            raw_tags = [t if t.startswith("#") else "#" + t for t in tags_field.strip().split()]

        # ë³¸ë¬¸ ì •ê·œí™”
        body_field = get("body") or get("content") or get("article") or get("text") or ""
        body = body_field.strip() if isinstance(body_field, str) else ""

        if titles or raw_tags or body:
            out_titles = titles if titles else ([str(fallback_title).strip()] if fallback_title else [])
            out_tags = norm_tags(raw_tags)
            return build_output(out_titles, out_tags, body)

    # 3) ê·¸ ì™¸ì—ëŠ” ì›ë¬¸ì—ì„œ ë³¸ë¬¸/í•´ì‹œíƒœê·¸ í›„ë³´ë§Œ ê°„ë‹¨ ì¶”ì¶œ í›„ ì¡°ë¦½
    m = re.search(r"\[ë³¸ë¬¸\]\s*(.*)\Z", text, flags=re.S)
    body = m.group(1).strip() if m else text
    found_tags = list(dict.fromkeys(re.findall(r"#\S+", text)))[:5]
    out_titles = [str(fallback_title).strip()] if fallback_title else []
    out_tags = norm_tags(found_tags)
    return build_output(out_titles, out_tags, body)

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë‹¤ì–‘í•œ ì‹¤í–‰ í™˜ê²½ì—ì„œ .envë¥¼ íƒìƒ‰í•˜ì—¬ GOOGLE_API_KEY ë¡œë“œ
# ------------------------------------------------------------------
def _ensure_env_loaded():
    """
    ë‹¤ì–‘í•œ ë°°í¬ í™˜ê²½(ê°œë°œ, íŒ¨í‚¤ì§•(PyInstaller), ì„ì‹œ ì‹¤í–‰ ë””ë ‰í† ë¦¬ ë“±)ì—ì„œ .envë¥¼ íƒìƒ‰í•´
    GOOGLE_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ë¡œë“œ

    íƒìƒ‰ ìˆœì„œ ê°œìš”:
    1) í˜„ì¬ í™˜ê²½ë³€ìˆ˜ì— ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆë‹¤ë©´ ì¦‰ì‹œ ì¢…ë£Œ
    2) ê¸°ë³¸ load_dotenv()
    3) ëª¨ë“ˆ ê²½ë¡œ ê¸°ì¤€ .env
    4) PyInstaller ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ ê¸°ì¤€ .env
    5) _MEIPASS ì„ì‹œ ê²½ë¡œ ê¸°ì¤€ .env
    """
    if os.getenv("GOOGLE_API_KEY"): return
    load_dotenv()
    if os.getenv("GOOGLE_API_KEY"): return
    module_dir = os.path.dirname(__file__)
    load_dotenv(os.path.join(module_dir, ".env"))
    if os.getenv("GOOGLE_API_KEY"): return
    if getattr(sys, "frozen", False):
        exe_dir = os.path.dirname(sys.executable)
        load_dotenv(os.path.join(exe_dir, ".env"))
    meipass = getattr(sys, "_MEIPASS", None)
    if meipass:
        load_dotenv(os.path.join(meipass, ".env"))

_ensure_env_loaded()

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError(".envì—ì„œ GOOGLE_API_KEYë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
genai.configure(api_key=api_key)

# âš ï¸ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ëŠ” generate_article ì•ˆì—ì„œ system_instructionê³¼ í•¨ê»˜ ìƒì„±
# model = genai.GenerativeModel("gemini-2.5-flash")

FAST_MODE = os.getenv("FAST_MODE", "0") == "1"
LOG_LEVEL = os.getenv("NEWS_LOG_LEVEL", "INFO").upper()

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : íŒŒì¼ëª… ì•ˆì „í™”ë¥¼ ìœ„í•´ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì¹˜í™˜
# ------------------------------------------------------------------
def _safe_keyword(name: str) -> str:
    """íŒŒì¼ëª… ì•ˆì „í™”ë¥¼ ìœ„í•´ í‚¤ì›Œë“œì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ê³  ê³µë°±ì€ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½."""
    name = "".join(c for c in name if c.isalnum() or c in (" ", "-", "_")).strip()
    return name.replace(" ", "_") or "log"

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì¼ë°˜ ì‹¤í–‰/íŒ¨í‚¤ì§•(PyInstaller) ì—¬ë¶€ì— ë”°ë¼ ê¸°ì¤€ ë””ë ‰í† ë¦¬ ë°˜í™˜
# ------------------------------------------------------------------
def _get_base_dir() -> Path:
    """PyInstaller ì‹¤í–‰ íŒŒì¼/ì¼ë°˜ ì‹¤í–‰ êµ¬ë¶„í•˜ì—¬ ê¸°ì¤€ ë””ë ‰í† ë¦¬ ê²°ì •."""
    if getattr(sys, "frozen", False):
        return Path(sys.executable).parent
    return Path.cwd()

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : í‚¤ì›Œë“œ ê¸°ë°˜ íŒŒì¼/ì½˜ì†” ë¡œê·¸ í•¸ë“¤ëŸ¬ êµ¬ì„± ë° ê²½ë¡œ ë°˜í™˜
# ------------------------------------------------------------------
def setup_logging(keyword: str) -> tuple[logging.Logger, str]:
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ì˜ íŒŒì¼ ë¡œê·¸ì™€ ì½˜ì†” ë¡œê·¸ í•¸ë“¤ëŸ¬ë¥¼ êµ¬ì„±í•´ ë°˜í™˜

    - íŒŒì¼ ì €ì¥ ê²½ë¡œ: `ê¸°ì‚¬ ì¬ìƒì„±/ì¬ìƒì„±YYYYMMDD/{í‚¤ì›Œë“œ}_log.txt`
    - ë¡œê·¸ ë ˆë²¨: í™˜ê²½ë³€ìˆ˜ `NEWS_LOG_LEVEL`(ê¸°ë³¸ INFO)
    - ë™ì¼ ë¡œê±° ë‹¤ì¤‘ ì´ˆê¸°í™” ë°©ì§€: í•¸ë“¤ëŸ¬ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì¬ì‚¬ìš©

    :param keyword: ë¡œê·¸ íŒŒì¼ëª…ì„ êµ¬ì„±í•  í‚¤ì›Œë“œ
    :return: (logger ì¸ìŠ¤í„´ìŠ¤, ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ë¬¸ìì—´)
    """
    current_date = datetime.now().strftime("%Y%m%d")
    base_dir = _get_base_dir()
    log_dir = base_dir / "ê¸°ì‚¬ ì¬ìƒì„±" / f"ì¬ìƒì„±{current_date}"
    log_dir.mkdir(parents=True, exist_ok=True)

    safe_keyword = _safe_keyword(keyword)
    log_filepath = str(log_dir / f"{safe_keyword}_log.txt")

    logger_name = f"news_llm_{safe_keyword}"
    logger = logging.getLogger(logger_name)

    level_map = {"DEBUG": logging.DEBUG, "INFO": logging.INFO, "WARNING": logging.WARNING, "ERROR": logging.ERROR}
    logger.setLevel(level_map.get(LOG_LEVEL, logging.INFO))

    if not logger.handlers:
        fh = logging.FileHandler(log_filepath, encoding="utf-8")
        fh.setLevel(level_map.get(LOG_LEVEL, logging.INFO))
        fh.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        ch = logging.StreamHandler()
        ch.setLevel(level_map.get(LOG_LEVEL, logging.INFO))
        ch.setFormatter(logging.Formatter("%(message)s"))

        logger.addHandler(fh)
        logger.addHandler(ch)

    return logger, log_filepath

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : loggerì™€ ì½˜ì†”ì— ë™ì‹œ ì¶œë ¥(ë ˆë²¨ë³„ ë¶„ê¸°)
# ------------------------------------------------------------------
def log_and_print(logger, message: str, level: str = "info"):
    """loggerì™€ ì½˜ì†”ì— ë™ì‹œì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥."""
    if level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "debug":
        logger.debug(message)

# ======================================================
# ê¸°ì‚¬ ì¶”ì¶œê¸°
# ======================================================
# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : URLë¡œë¶€í„° ì œëª©/ë³¸ë¬¸ ì¶”ì¶œ, ë¶€ì¡± ì‹œ ë„¤ì´ë²„ CP íŒŒì„œë¡œ í´ë°±
# ------------------------------------------------------------------
def extract_title_and_body(url, logger=None):
    """
    ì…ë ¥ URLì—ì„œ ê¸°ì‚¬ ì œëª©ê³¼ ë³¸ë¬¸ì„ ì¶”ì¶œ

    ì ˆì°¨ ê°œìš”:
    1) newspaper3kë¥¼ í†µí•œ 1ì°¨ íŒŒì‹± ì‹œë„(title, text)
    2) ë³¸ë¬¸ ê¸¸ì´ê°€ ë¶€ì¡±(<50ì)í•˜ê±°ë‚˜ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë„¤ì´ë²„ CP ì „ìš© íŒŒì„œë¡œ í´ë°±
    3) ëª¨ë“  ì˜ˆì™¸ëŠ” ë‚´ë¶€ì—ì„œ í•¸ë“¤ë§í•˜ì—¬ ìƒìœ„ ë¡œì§ì´ ê³„ì† ì§„í–‰ë˜ë„ë¡ ë³´ì¥

    :param url: ê¸°ì‚¬ URL
    :param logger: ì„ íƒì  ë¡œê±°(ì„¸ë¶€ ê³¼ì • ë¡œê¹…)
    :return: (title: str, body: str)
    """
    if logger:
        log_and_print(logger, f"\n  ğŸ“„ ê¸°ì‚¬ ì¶”ì¶œ ì„¸ë¶€ ê³¼ì •:")
        log_and_print(logger, f"    - newspaper ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê¸°ì‚¬ ë‹¤ìš´ë¡œë“œ ì‹œë„...")

    title, body = "", ""

    # 1) newspaper ì‹œë„
    try:
        article = Article(url, language='ko')
        article.download()
        article.parse()
        title = (article.title or "").strip()
        body = (article.text or "").strip()
        if logger:
            log_and_print(logger, f"    - ë‹¤ìš´ë¡œë“œëœ ì œëª©: {title}")
            log_and_print(logger, f"    - ë‹¤ìš´ë¡œë“œëœ ë³¸ë¬¸ ê¸¸ì´: {len(body)}ì")
    except Exception as e:
        if logger:
            log_and_print(logger, f"    âš ï¸ newspaper ì²˜ë¦¬ ì‹¤íŒ¨: {e}", "warning")

    # 2) ë³¸ë¬¸ ê¸¸ì´ ë¯¸ë‹¬ â†’ í´ë°±
    if len(body) < 50:
        if logger:
            log_and_print(logger, f"    âš ï¸ ë³¸ë¬¸ì´ ì§§ì•„ fallbackìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.", "warning")
            log_and_print(logger, f"    - fallback: extract_naver_cp_article() í˜¸ì¶œ...")
        try:
            t2, b2 = extract_naver_cp_article(url, logger)
            title = t2 or title or "ì œëª© ì—†ìŒ"
            body = b2 or body or ""
            if logger:
                log_and_print(logger, f"    - fallback ê²°ê³¼ ì œëª©: {title}")
                log_and_print(logger, f"    - fallback ê²°ê³¼ ë³¸ë¬¸ ê¸¸ì´: {len(body)}ì")
        except Exception as e:
            if logger:
                log_and_print(logger, f"    âš ï¸ fallback ì¤‘ ì˜ˆì™¸: {e}", "warning")
    else:
        if logger:
            log_and_print(logger, f"    âœ… ë³¸ë¬¸ ê¸¸ì´ ì¶©ë¶„ - newspaper ê²°ê³¼ ì‚¬ìš©")

    return title, body

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë„¤ì´ë²„ ë‰´ìŠ¤(CP) DOMì„ ì´ìš©í•œ ì œëª©/ë³¸ë¬¸ ì§ì ‘ ì¶”ì¶œ
# ------------------------------------------------------------------
def extract_naver_cp_article(url, logger=None):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤(CP) í˜ì´ì§€ì˜ ì „í˜•ì ì¸ DOM êµ¬ì¡°ë¥¼ í™œìš©í•´ ì œëª©ê³¼ ë³¸ë¬¸ì„ ì¶”ì¶œ

    - ì œëª©: `h2.media_end_head_headline`
    - ë³¸ë¬¸: `article#dic_area` í…ìŠ¤íŠ¸(ê°œí–‰ ìœ ì§€)

    :param url: ë„¤ì´ë²„ ë‰´ìŠ¤(CP) URL
    :param logger: ì„ íƒì  ë¡œê±°(ë‹¤ìš´ë¡œë“œ/íŒŒì‹± ê³¼ì • ë¡œê¹…)
    :return: (title: str, body: str)
    """
    if logger:
        log_and_print(logger, f"      ğŸ”„ ë„¤ì´ë²„ CP ê¸°ì‚¬ fallback ì²˜ë¦¬:")
        log_and_print(logger, f"        - requestsë¡œ HTML ì§ì ‘ ë‹¤ìš´ë¡œë“œ...")
    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(url, headers=headers, timeout=7)
    soup = BeautifulSoup(res.text, 'html.parser')
    if logger:
        log_and_print(logger, f"        - HTML ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(res.text)}ì")
    title_tag = soup.select_one('h2.media_end_head_headline')
    title = title_tag.text.strip() if title_tag else "ì œëª© ì—†ìŒ"
    if logger:
        log_and_print(logger, f"        - ì œëª© íƒœê·¸ ê²€ìƒ‰ ê²°ê³¼: {'ì°¾ìŒ' if title_tag else 'ì°¾ì§€ ëª»í•¨'}")
        log_and_print(logger, f"        - ì¶”ì¶œëœ ì œëª©: {title}")
    body_area = soup.select_one('article#dic_area')
    body = body_area.get_text(separator="\n").strip() if body_area else "ë³¸ë¬¸ ì—†ìŒ"
    if logger:
        log_and_print(logger, f"        - ë³¸ë¬¸ ì˜ì—­ ê²€ìƒ‰ ê²°ê³¼: {'ì°¾ìŒ' if body_area else 'ì°¾ì§€ ëª»í•¨'}")
        log_and_print(logger, f"        - ì¶”ì¶œëœ ë³¸ë¬¸ ê¸¸ì´: {len(body)}ì")
    return title, body


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‹œì œ ê·œì¹™/ì¶œë ¥ í˜•ì‹ì„ í¬í•¨í•œ Gemini ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
# ------------------------------------------------------------------

def generate_system_prompt(keyword: str, today_kst: str, published_kst: str | None = None) -> str:
    """
    Gemini ëª¨ë¸ì— ì£¼ì…í•  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±
    - ì—­í• (Role), ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼, ì‹œì œ ë³€í™˜ ê·œì¹™, ì‚¬ì‹¤ ë³´ì¡´ ì²´í¬ë¦¬ìŠ¤íŠ¸, ìƒì„± ì ˆì°¨, ì¶œë ¥ í˜•ì‹ í¬í•¨
    - fact-check í”„ë¡¬í”„íŠ¸(ë‚´ë¶€ ì²´ì»¤)ì˜ íŒì •/ì˜ˆì™¸ ê¸°ì¤€ê³¼ ì •í•©ì„± ìµœì í™”
    :param keyword: ìƒì„±í•  ê¸°ì‚¬ ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ(ì œëª©/í•´ì‹œíƒœê·¸ ê°€ì´ë“œì— ë°˜ì˜)
    :param today_kst: ì˜¤ëŠ˜ ë‚ ì§œ(Asia/Seoul) ë¬¸ìì—´
    :param published_kst: ì›ë¬¸ ê¸°ì‚¬ ë°œí–‰ì¼ ë¬¸ìì—´(ê°€ë…í˜•, ì„ íƒ)
    :return: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    prompt = (
        f"""
        [System message]
        - ì…ë ¥ ìˆœì„œ: â‘  í‚¤ì›Œë“œ â‘¡ ê¸°ì‚¬ ì œëª© â‘¢ ê¸°ì‚¬ ë³¸ë¬¸.
        - **ìµœì¢… ì¶œë ¥ì€ [ì œëª©], [í•´ì‹œíƒœê·¸], [ë³¸ë¬¸] ì„¸ ì„¹ì…˜ìœ¼ë¡œë§Œ ì‘ì„±.** ë‹¤ë¥¸ ë©”íƒ€ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª… ê¸ˆì§€.

        [Role]
        - ë‹¹ì‹ ì€ ì‚¬ì‹¤ì„ ìœ ì§€í•˜ë©° ê°€ë…ì„±ì„ ë†’ì´ëŠ” ì „ë¬¸ ê¸°ì/ì—ë””í„°ì´ë‹¤.
        - ìµœìš°ì„  ëª©í‘œ: **ì›ë¬¸ í•µì‹¬ ì‚¬ì‹¤ 100% ë³´ì¡´**, **ì™¸ë¶€ ì •ë³´/ì¶”ì • ì¶”ê°€ ê¸ˆì§€**, **KST ê¸°ì¤€ ì‹œì œ ì¼ê´€í™”**.
        - ë¬¸ì²´ëŠ” ~ì´ë‹¤/~í–ˆë‹¤/~í•œë‹¤ë¡œ ì¼ê´€. Markdown ë¬¸ë²• ì‚¬ìš© ê¸ˆì§€.

        [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]
        - ì˜¤ëŠ˜(Asia/Seoul): {today_kst}
        - ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ): {published_kst or 'íŒŒì•… ë¶ˆê°€'}

        [ì‹œì œ ë³€í™˜ ê·œì¹™]
        - [ì˜¤ëŠ˜(KST)]ì™€ ì›ë¬¸ ì„œìˆ  ì‹œì ì„ ë¹„êµí•´ ì‹œì œ í†µì¼:
        * ì´ë¯¸ ë°œìƒ: ê³¼ê±°í˜•(â€¦í–ˆë‹¤/â€¦ì´ì—ˆë‹¤)
        * ì§„í–‰ ì¤‘: í˜„ì¬í˜•(â€¦í•œë‹¤)
        * ì˜ˆì •: ë¯¸ë˜ ì„œìˆ (â€¦í•  ì˜ˆì •ì´ë‹¤/â€¦ë¡œ ì˜ˆì •ë¼ ìˆë‹¤)
        - **ì¶”ì¸¡/ì „ë§ í‘œí˜„(â€¦ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤/ì „ë§ì´ë‹¤) ê¸ˆì§€.**
        - ë‚ ì§œê°€ ë¶ˆí•„ìš”í•˜ë©´ ì§ì ‘ ë‚ ì§œ ëŒ€ì‹  **ìƒëŒ€ì‹œì  í‘œí˜„** ì‚¬ìš©(â€˜ë‹¹ì‹œâ€™, â€˜ì´í›„â€™, â€˜ì´ì „â€™, â€˜ê°™ì€ ë‚ â€™ ë“±).
        - **ì¸ìš©ë¬¸ ë‚´ë¶€ì˜ ë‚ ì§œ/í‘œí˜„ì€ ìˆ˜ì •í•˜ì§€ ì•ŠëŠ”ë‹¤.**
        - ìƒëŒ€ì‹œì  í‘œê¸° ê·œì¹™(ì²´ì»¤ ì˜ˆì™¸ì™€ ì •í•©):
        * ì˜¤ëŠ˜ê³¼ ê°™ì€ ë‚  â†’ â€œOì¼â€ë§Œ ì‚¬ìš©(â€œOì›” Oì¼â€, â€œì˜¤ëŠ˜ OOì¼â€, "ì˜¤ëŠ˜" ê¸ˆì§€)
        * ê°™ì€ ë‹¬ ê³¼ê±° â†’ â€œì§€ë‚œ Oì¼â€
        * ê°™ì€ ë‹¬ ë¯¸ë˜ â†’ â€œì˜¤ëŠ” Oì¼â€
        * ì§ì „ ë‹¬ ê³¼ê±° â†’ â€œì§€ë‚œë‹¬ Oì¼â€
        * ê³¼ê±° ì—°ë„ ëª…ì‹œ â†’ â€œì§€ë‚œ OOOOë…„â€, í•„ìš” ì‹œ â€œì§€ë‚œ OOOOë…„ Oì›” Oì¼â€
        * ë¯¸ë˜ ì—°ë„ ëª…ì‹œ â†’ â€œì˜¤ëŠ” OOOOë…„â€, í•„ìš” ì‹œ â€œì˜¤ëŠ” OOOOë…„ Oì›” Oì¼â€
        - [ì˜¤ëŠ˜(KST) ê¸°ì¤€ì¼]ì˜ ì˜¤ëŠ˜(Asia/Seoul)ê³¼ ì›ë¬¸ ê¸°ì‚¬ ì‘ì„±ì¼(ì‚¬ì´íŠ¸ ì¶”ì¶œ)ì˜ ë‚ ì§œê°€ 1ê°œì›” ì´ìƒ ì°¨ì´ê°€ ë‚˜ëŠ” ê²½ìš°, ê¸°ì‚¬ ì‘ì„± ì‹œ ì˜¤ëŠ˜(Asia/Seoul) ë‚ ì§œë¥¼ ë”°ë¥¼ ê²ƒ.

        [Fact Ledger(ë‚´ë¶€ ì ê²€ìš©, ì¶œë ¥ ê¸ˆì§€)]
        - ë³¸ë¬¸ ì‘ì„± ì „, ì›ë¬¸ì—ì„œ ì•„ë˜ í•­ëª©ë§Œ **ë‚´ë¶€ì ìœ¼ë¡œ** ì¶”ì¶œí•´ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì•„ë¼(ì¶œë ¥í•˜ì§€ ë§ ê²ƒ).
        1) ì¸ë¬¼/ì¡°ì§ì˜ ì •í™•í•œ ëª…ì¹­Â·ì§í•¨
        2) ìˆ˜ì¹˜Â·ë‚ ì§œÂ·ì§€ëª…Â·ì œí’ˆëª… ë“± ê³ ìœ  í‘œê¸°
        3) ì¸ìš©ë¬¸(ë”°ì˜´í‘œ í¬í•¨)ê³¼ í™”ì
        4) ì‚¬ê±´ì˜ ìƒíƒœ(ì˜ˆì •/ì¶”ì§„ ì¤‘/ê°€ëŠ¥ì„±)ì™€ ë‹¨ì • ì—¬ë¶€
        - ì‘ì„± ì¤‘/í›„ ì ê²€:
        - Ledgerì— ì—†ëŠ” **ìƒˆë¡œìš´ ìˆ˜ì¹˜/ì£¼ì¥/ë°°ê²½**ì„ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ.
        - ë¶ˆí™•ì • í‘œí˜„ì„ **ë‹¨ì •**ìœ¼ë¡œ ë°”ê¾¸ì§€ ë§ ê²ƒ.
        - ì¸ìš©ë¬¸ì€ **ì›ë¬¸ ê·¸ëŒ€ë¡œ**(ë‹¨ì–´ í•˜ë‚˜ë„ ë³€ê²½ ê¸ˆì§€).
        - ëª¨í˜¸í•˜ë©´ **í•´ë‹¹ ë¬¸ì¥ ìƒëµ**ì„ ìš°ì„ (ë¶ˆí•„ìš”í•œ ì¶”ì • ê¸ˆì§€).

        [News Generation Process]
        1) ì œëª© ìƒì„±(3ê°œ)
        - ìš°ì„ ìˆœìœ„: **â‘  ì…ë ¥ í‚¤ì›Œë“œ í¬í•¨(ì›ë¬¸ê³¼ ë¬´ê´€í•˜ë©´ ë¬´ë¦¬í•˜ê²Œ ë„£ì§€ ë§ ê²ƒ) â‘¡ ì œê³µëœ ê¸°ì‚¬ ì œëª©ì˜ í•µì‹¬ ì˜ë¯¸ ë°˜ì˜ â‘¢ ë³¸ë¬¸ í•µì‹¬ ë°˜ì˜**.
        - ë‹¤ì–‘ì„±: 
            * 1ë²ˆ: ì „í†µì Â·ì‚¬ì‹¤ ì¤‘ì‹¬
            * 2ë²ˆ: ì£¼ëª©ë„ ë†’ì€ ì°½ì˜í˜•(ì„ ì •ì  ê¸ˆì§€)
            * 3ë²ˆ: ì˜í–¥/ì˜ì˜ ê°•ì¡°
        - **25~35ì ê¶Œì¥, ìµœëŒ€ 35ì.** ë¬¼ìŒí‘œ/ì˜ë¬¸ ìœ ë„ ê¸ˆì§€(?, ì™œ, ì–´ë–»ê²Œ ë“±).
        - ì‚¬ìš© ê°€ëŠ¥: ì‰¼í‘œ(,), ë”°ì˜´í‘œ(' "), í•„ìš” ìµœì†Œí•œì˜ ê´„í˜¸.
        - ê¸ˆì§€(ì œëª© í•œì •): ë§ˆì¹¨í‘œ(.), ì½œë¡ (:), ì—˜ë¦¬ì‹œìŠ¤(â€¦), ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(*, #, &).

        2) ë³¸ë¬¸ ìƒì„±(ì›ë¬¸ ì¬êµ¬ì„±)
        - ëª©í‘œ: **ì •ë³´ ì†ì‹¤ ì—†ëŠ” ì••ì¶•**. ì›ë¬¸ í•µì‹¬ ì‚¬ì‹¤Â·ìˆ˜ì¹˜Â·ì¸ìš©Â·í™”ìÂ·ë‚ ì§œë¥¼ ëª¨ë‘ ë³´ì¡´.
        - **ê³µë°± í¬í•¨ 300~800ì**ë¡œ ì‘ì„±(800ì ì´ˆê³¼ ê¸ˆì§€). ì¶œë ¥ ì§ì „ ìŠ¤ìŠ¤ë¡œ ê¸€ì ìˆ˜ ì ê²€.
        - ë¬¸ì¥ ê°„ê²°Â·ëª…í™•(í•œ ë¬¸ì¥ 15~20ì ê¶Œì¥), ì¤‘ë³µ/êµ°ë”ë”ê¸° ì œê±°.
        - **ì¸ìš©ë¬¸ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ê³  í™”ì ì†ì„±ë„ ë³´ì¡´.
        - **ìƒˆ ì •ë³´/ì¶”ì •/ì™¸ë¶€ ë§¥ë½ ì¶”ê°€ ê¸ˆì§€.** â€˜ë…¼ë€/ì˜í˜¹/íŒŒì¥â€™ ë“± ê°€ì¹˜ íŒë‹¨ì–´ ì„ì˜ ì¶”ê°€ ê¸ˆì§€.
        - ê¸°ì—…/ì¸ë¬¼ì˜ ëª…ì¹­Â·ì§í•¨Â·ì œí’ˆëª… ë“±ì€ ì›ë¬¸ í‘œê¸°ë¥¼ ì¡´ì¤‘.
        - **ê¸ˆì§€ ê¸°í˜¸(â€¦, *, #, &)** ëŠ” ë³¸ë¬¸ì— ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ(í•´ì‹œíƒœê·¸ ì„¹ì…˜ ì œì™¸).

        3) ì‹œì œ/ì •í•©ì„± ìµœì¢… ì ê²€
        - ì²´ì»¤ ì˜ˆì™¸ í—ˆìš© ë²”ìœ„ ì¤€ìˆ˜: â€˜ì§€ë‚œ/ì˜¤ëŠ”â€™, â€˜ì´ë‚ /ì˜¤ëŠ˜â€™ ìƒëµ, 1ì£¼ ì´ìƒ ì§€ë‚œ ë°©ì†¡ì˜ â€˜ìµœê·¼/ì´ì „â€™ ì²˜ë¦¬ ë“±.
        - ë¶ˆí™•ì •â†’ë‹¨ì • ë³€í™˜ ì—¬ë¶€, ê³ ìœ ëª…ì‚¬Â·ìˆ˜ì¹˜ ì˜¤íƒ€, ì¸ìš©ë¬¸ ë³€í˜• ì—¬ë¶€ ìµœì¢… í™•ì¸.
        - [ì œëª©]=3ê°œ, [í•´ì‹œíƒœê·¸]=**3~5ê°œ** ê·œì¹™ ì¤€ìˆ˜.

        4) í•´ì‹œíƒœê·¸ ìƒì„±(3~5ê°œ)
        - **ìƒì„±ëœ ë³¸ë¬¸ì— ì‹¤ì œ ë“±ì¥í•˜ëŠ” í•µì‹¬ëª…ì‚¬/ê³ ìœ ëª…ì‚¬ë§Œ ì‚¬ìš©.**
        - ê³¼ë„í•œ ì¼ë°˜ì–´Â·ì¶”ì •ì–´ ê¸ˆì§€. ì˜ì–´ íƒœê·¸ëŠ” ì›ë¬¸ì— ìˆì„ ë•Œë§Œ.
        - í•´ì‹œíƒœê·¸ ì„¹ì…˜ì—ì„œë§Œ `#` ì‚¬ìš©.

        [ì¶œë ¥ í˜•ì‹(ì—„ìˆ˜)]
        - ì˜¤ì§ ì•„ë˜ ë¸”ë¡ë§Œ ì¶œë ¥í•œë‹¤. ê·¸ ì™¸ í…ìŠ¤íŠ¸/ì£¼ì„ ê¸ˆì§€.

        [ì œëª©]
        (ì œëª© 1)
        (ì œëª© 2)
        (ì œëª© 3)

        [í•´ì‹œíƒœê·¸]
        #(íƒœê·¸1) #(íƒœê·¸2) #(íƒœê·¸3)

        [ë³¸ë¬¸]
        (ê³µë°± í¬í•¨ 300~800ì ë³¸ë¬¸)
        """
    )
    return prompt



# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ì‚¬ì‹¤ê²€ì¦ ê²°ê³¼(verdict)ê°€ OKì¸ì§€ ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  íŒë³„
# ------------------------------------------------------------------
def _is_fact_ok_text(verdict: str) -> bool:
    """ì‚¬ì‹¤ê²€ì¦ ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ OKì¸ì§€ íŒë³„."""
    return (verdict or "").strip().upper() == "OK"

# Fast-Passì— í•„ìš”í•œ íŒ¨í„´
_NUM_PAT = re.compile(r"(?:\d{4}\.\d{1,2}\.\d{1,2}|\d{4}-\d{1,2}-\d{1,2}|\d{1,2}ì›”\s?\d{1,2}ì¼|\d{4}ë…„|\d{1,3}(?:,\d{3})+|\d+%|\d+ëª…|\d+ê±´|\d+ê°œ|\d+ì›|\d+ì–µ|\d+ì¡°|\d+íšŒ|\d+ì¼|\d+ì‹œê°„|\d+ë¶„|\d+ì´ˆ|\d+ì„¸|\d+ìœ„|\d+ì )")
_QUOTE_PAT = re.compile(r"[â€œâ€\"']([^â€œâ€\"']{2,200})[â€œâ€\"']")

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë¬¸ì„œì—ì„œ ìˆ«ì/ë‹¨ìœ„ íŒ¨í„´ì„ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ì§‘í•©ìœ¼ë¡œ ë°˜í™˜
# ------------------------------------------------------------------
def _extract_numbers(text: str) -> set[str]:
    """ë¬¸ì„œì—ì„œ ìˆ«ì/ë‹¨ìœ„ íŒ¨í„´ì„ ì°¾ì•„ ì§‘í•©ìœ¼ë¡œ ë°˜í™˜."""
    return set(m.group(0) for m in _NUM_PAT.finditer(text or ""))

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ë¬¸ì„œì—ì„œ ì¸ìš©ë¬¸(ë”°ì˜´í‘œ ë‚´ë¶€ í…ìŠ¤íŠ¸)ì„ ì¶”ì¶œí•˜ì—¬ ì§‘í•©ìœ¼ë¡œ ë°˜í™˜
# ------------------------------------------------------------------
def _extract_quotes(text: str) -> set[str]:
    """ë¬¸ì„œì—ì„œ ì¸ìš©ë¬¸(ë”°ì˜´í‘œ ë‚´ë¶€)ì„ ì¶”ì¶œí•´ ì§‘í•©ìœ¼ë¡œ ë°˜í™˜."""
    return set(m.group(1).strip() for m in _QUOTE_PAT.finditer(text or ""))

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : Fast-Pass(ê²½ëŸ‰ ì¼ì¹˜ ê²€ì‚¬) â€” ìƒì„±ë¬¸ ìˆ«ì/ì¸ìš©ì´ ì›ë¬¸ì˜ ë¶€ë¶„ì§‘í•©ì´ë©´ í†µê³¼
# ------------------------------------------------------------------
def _fast_pass_consistency(generated: str, original: str) -> bool:
    """
    Fast-Pass: ìƒì„±ë¬¸ì´ ì›ë¬¸ ìˆ«ì/ì¸ìš©ë¬¸ì„ 'ì´ˆê³¼'ë¡œ í¬í•¨í•˜ì§€ ì•Šìœ¼ë©´ í†µê³¼.
    - ìƒì„±ë¬¸ì— ìˆëŠ” ìˆ«ì/ì¸ìš©ì´ ì›ë¬¸ ì§‘í•©ì˜ ë¶€ë¶„ì§‘í•©ì´ë©´ True.
    """
    if not generated or not original:
        return False
    gen_nums = _extract_numbers(generated)
    org_nums = _extract_numbers(original)
    if gen_nums and not gen_nums.issubset(org_nums):
        return False
    gen_quotes = _extract_quotes(generated)
    org_quotes = _extract_quotes(original)
    if gen_quotes and not gen_quotes.issubset(org_quotes):
        return False
    return True

# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : Gemini ì‘ë‹µ ê°ì²´ì—ì„œ ì°¨ë‹¨/ëˆ„ë½ì„ ê³ ë ¤í•´ ì•ˆì „í•˜ê²Œ text ì¶”ì¶œ
# ------------------------------------------------------------------
def _safe_response_text(resp) -> str:
    """
    Gemini API ì‘ë‹µ ê°ì²´ì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ

    - í›„ë³´ ë¯¸ì¡´ì¬, ì•ˆì „ì„± ì°¨ë‹¨, í•„ë“œ ëˆ„ë½ ë“±ìœ¼ë¡œ ì¸í•´ `.text` ì ‘ê·¼ ì‹œ ì˜ˆì™¸ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°©ì§€ ë¡œì§ì„ í¬í•¨
    - ì°¨ë‹¨ ì—¬ë¶€ëŠ” 1ë²ˆ í›„ë³´ì˜ `safety_ratings` ë‚´ `blocked` í”Œë˜ê·¸ë¥¼ ì°¸ê³ 

    :param resp: genai.GenerativeModel.generate_content()ì˜ ì‘ë‹µ ê°ì²´
    :return: ì¶”ì¶œëœ í…ìŠ¤íŠ¸(ì—†ê±°ë‚˜ ì°¨ë‹¨ ì‹œ ë¹ˆ ë¬¸ìì—´)
    """
    try:
        if not getattr(resp, "candidates", None):
            return ""
        # ì•ˆì „ì„± ì°¨ë‹¨ ì—¬ë¶€ (ê°„ë‹¨ ì§„ë‹¨ìš©)
        safety = getattr(resp.candidates[0], "safety_ratings", None)
        if safety:
            blocked = any(getattr(r, "blocked", False) for r in safety)
            if blocked:
                return ""
        return getattr(resp, "text", "") or ""
    except Exception:
        return ""


# ------------------------------------------------------------------
# ì‘ì„±ì : ìµœì¤€í˜
# ê¸°ëŠ¥ : ê¸°ì‚¬ ì¶”ì¶œ â†’ ë°œí–‰ì¼ ì¶”ì¶œ â†’ í”„ë¡¬í”„íŠ¸ êµ¬ì„± â†’ ìƒì„± â†’ ì‚¬ì‹¤ê²€ì¦ â†’ ê²°ê³¼ ë°˜í™˜
# ------------------------------------------------------------------
def generate_article(state: dict) -> dict:
    """
    ìƒì„± íŒŒì´í”„ë¼ì¸ì˜ ë©”ì¸ í•¨ìˆ˜. ì…ë ¥ ìƒíƒœ(`state`)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ì‚¬ë¥¼ ì¬êµ¬ì„±í•˜ê³ , í•„ìš” ì‹œ
    ì‚¬ì‹¤ê²€ì¦ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì¢… í‘œì¶œ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ ì •ë³´ë¥¼ ë°˜í™˜

    ì²˜ë¦¬ ì ˆì°¨:
    1) ê¸°ì‚¬ ì¶”ì¶œ: `article_utils.extract_article_content`(ê°€ëŠ¥ ì‹œ) â†’ ì‹¤íŒ¨/ë¶€ì¡± ì‹œ ë‚´ë¶€ ì¶”ì¶œê¸°ë¡œ í´ë°±
    2) ë°œí–‰ì¼ ì¶”ì¶œ(ì„ í–‰): ì‹œì œ ë³€í™˜ ê°€ì´ë“œë¥¼ ìœ„í•´ `extract_publish_datetime` í˜¸ì¶œ ì‹œë„
    3) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±: `generate_system_prompt`ë¡œ ì‹œì œ/í˜•ì‹ ê·œì¹™ í¬í•¨ í”„ë¡¬í”„íŠ¸ ìƒì„±
    4) Gemini í˜¸ì¶œ: `gemini-2.5-flash`ë¡œ ê¸°ì‚¬ ì¬êµ¬ì„±, ì‘ë‹µ í…ìŠ¤íŠ¸ ì•ˆì „ ì¶”ì¶œ í›„ ì„¹ì…˜ ê°•ì œ ë³´ì •
    5) ì‚¬ì‹¤ê²€ì¦:
       - FAST_MODE=1 ì´ê³  ìˆ«ì/ì¸ìš©ë¬¸ ë¶€ë¶„ì§‘í•© ê²€ì‚¬(Fast-Pass) í†µê³¼ ì‹œ ë°”ë¡œ ê¸°ì‚¬ ì±„íƒ
       - ê·¸ ì™¸ì—” `check_LLM.check_article_facts` í˜¸ì¶œë¡œ ê²€ì¦, ì˜¤ë¥˜ êµì •ë³¸ ìˆìœ¼ë©´ êµì • ê¸°ì‚¬ ì±„íƒ
    6) ê²°ê³¼/ë¡œê·¸ ë°˜í™˜: ì „ì²´ ì†Œìš”ì‹œê°„ê³¼ ê³¼ì • ìƒì„¸ë¥¼ ë¡œê·¸ì— ë‚¨ê¸°ê³  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

    :param state: ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        - url: ê¸°ì‚¬ URL (í•„ìˆ˜)
        - keyword: í•µì‹¬ í‚¤ì›Œë“œ(ë¡œê·¸/í”„ë¡¬í”„íŠ¸/í•´ì‹œíƒœê·¸ì— ì‚¬ìš©)
        - title: ì‚¬ì „ ì œê³µëœ ì œëª©(ì„ íƒ)
        - body: ì‚¬ì „ ì œê³µëœ ë³¸ë¬¸(ì„ íƒ)
    :return: ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        - url, keyword, title, original_body, generated_article
        - fact_check_result(OK/ERROR/UNKNOWN)
        - corrected_article(FAST_MODEê°€ ì•„ë‹ ë•Œë§Œ ì±„ì›Œì§ˆ ìˆ˜ ìˆìŒ)
        - display_text(ìµœì¢… í‘œì¶œ í…ìŠ¤íŠ¸), display_kind(article/fact_check/error)
        - error(ì—ëŸ¬ ë©”ì‹œì§€ ë˜ëŠ” None)
    """
    url = state.get("url")
    keyword = state.get("keyword")

    t_total_start = perf_counter()  # â± ì´ ì†Œìš”ì‹œê°„ ì¸¡ì • ì‹œì‘
    logger, log_filepath = setup_logging(keyword or "ë¡œê·¸")

    title = (state.get("title") or "").strip()
    body = (state.get("body") or "").strip()

    try:
        log_and_print(logger, "\n" + "="*80)
        log_and_print(logger, "ğŸ“° NEWS_LLM - ê¸°ì‚¬ ì¬êµ¬ì„± ì‹œì‘")
        log_and_print(logger, "="*80)
        log_and_print(logger, f"\nğŸ“¥ ì…ë ¥ ë°ì´í„°:")
        log_and_print(logger, f"  - URL: {url}")
        log_and_print(logger, f"  - í‚¤ì›Œë“œ: {keyword}")
        log_and_print(logger, f"  - ë¡œê·¸ íŒŒì¼: {log_filepath}")

        # 1) ê¸°ì‚¬ ì¶”ì¶œ
        t_extract_start = perf_counter()
        if (not title or not body) or (len(body) < AU_MIN):
            log_and_print(logger, "\nğŸ”— ê¸°ì‚¬ ì¶”ì¶œ ë‹¨ê³„: ì™¸ë¶€ ì¶”ì¶œ ë¯¸í¡ â†’ article_utils ì‹œë„")
            if extract_article_content is not None:
                try:
                    t2, b2 = extract_article_content(url, progress_callback=None)
                    if len(b2 or "") >= AU_MIN:
                        title, body = t2, b2
                        log_and_print(logger, f"  âœ… article_utils ì„±ê³µ: ë³¸ë¬¸ {len(body)}ì")
                except Exception as e:
                    log_and_print(logger, f"  âš ï¸ article_utils ì‹¤íŒ¨: {e}", "warning")
        if not title or not body:
            log_and_print(logger, "  ğŸ” ë‚´ë¶€ ì¶”ì¶œê¸°ë¡œ í´ë°±")
            t3, b3 = extract_title_and_body(url, logger)
            if len((b3 or "")) > len(body or ""):
                title, body = t3, b3
        if not body:
            raise ValueError("ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: ë³¸ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        t_extract = perf_counter() - t_extract_start
        log_and_print(logger, f"â± ê¸°ì‚¬ ì¶”ì¶œ ë‹¨ê³„ ì†Œìš”: {t_extract:.2f}s")

        # 1.5) ë°œí–‰ì¼ ì¶”ì¶œ â€”â€” ìƒì„± ì „ì— ìˆ˜í–‰
        today_kst = get_today_kst_str()
        published_kst = None
        if extract_publish_datetime is not None:
            try:
                published_kst = extract_publish_datetime(url)
                if published_kst:
                    log_and_print(logger, f"ğŸ—“ï¸ ë°œí–‰ì¼ ì¶”ì¶œ ì„±ê³µ: {published_kst}")
                else:
                    log_and_print(logger, "ğŸ—“ï¸ ë°œí–‰ì¼ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸ì œê³µ")
            except Exception as e:
                log_and_print(logger, f"ğŸ—“ï¸ ë°œí–‰ì¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}", "warning")

        # 2) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± + ëª¨ë¸ êµ¬ì„± (system_instruction ì‚¬ìš©)
        system_prompt = generate_system_prompt(keyword or "", today_kst, published_kst)
        user_request = f"í‚¤ì›Œë“œ: {keyword}\nì œëª©: {title}\në³¸ë¬¸: {body}"

        model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            system_instruction=system_prompt
            # generation_config=GenerationConfig(
            #     max_output_tokens=
            # )
        )

        # 3) ìƒì„± í˜¸ì¶œ
        t_gen_start = perf_counter()
        log_and_print(logger, f"\nâ³ Gemini AI í˜¸ì¶œ ì¤‘... ëª¨ë¸: gemini-2.5-flash")
        # user ì…ë ¥ë§Œ ì „ë‹¬

        response = model.generate_content(user_request)

        # í† í° ê³„ì‚°
        usage = getattr(response, "usage_metadata", None)
        if usage:
            p = getattr(usage, "prompt_token_count", 0)
            c = getattr(usage, "candidates_token_count", 0)
            t = getattr(usage, "total_token_count", 0)
            th = getattr(usage, "thoughts_token_count", 0)  
            tu = getattr(usage, "tool_use_prompt_token_count", 0)
            cc = getattr(usage, "cached_content_token_count", 0)
            resid = t - (p + c + th + tu)  # ë‚¨ëŠ”ë‹¤ë©´ API/ë²„ì „ë³„ ì§‘ê³„ ì°¨ì´
            log_and_print(logger,
                f"ğŸ§¾ í† í° ìƒì„¸ | ì…ë ¥={p}, ì¶œë ¥={c}, ìƒê°={th}, íˆ´í”„ë¡¬í”„íŠ¸={tu}, ìºì‹œ={cc}, í•©ê³„={t}, ì”ì°¨={resid}")
        else:
            log_and_print(logger, "ğŸ§¾ usage_metadata ì—†ìŒ", "warning")

        t_gen = perf_counter() - t_gen_start
        log_and_print(logger, f"â± ê¸°ì‚¬ ìƒì„± ì†Œìš”: {t_gen:.2f}s")

        # ì‘ë‹µ ì•ˆì „ ì¶”ì¶œ 
        article_text = _safe_response_text(response).strip()
        if not article_text:
            log_and_print(logger, "âš ï¸ LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ(ì°¨ë‹¨/ë¹ˆ í›„ë³´ ê°€ëŠ¥ì„±).", "warning")

        # ì„¹ì…˜ ê°•ì œ ë³´ì •
        article_text = ensure_output_sections(article_text, keyword or "", title)
        log_and_print(logger, f"\nğŸ“Š ê¸°ì‚¬ ê¸¸ì´ ë¹„êµ: ì›ë³¸ {len(body)}ì â†’ ì¬êµ¬ì„± {len(article_text)}ì")

        # 4) ì‚¬ì‹¤ê²€ì¦(Fast-Pass ìš°ì„ )
        if FAST_MODE and _fast_pass_consistency(article_text, body):
            # Fast-Pass ë‚´ë¶€ ì§„ë‹¨ ë¡œê·¸ ê°•í™”
            log_and_print(
                logger,
                f"âš¡ FAST-PASS í†µê³¼ â†’ nums={_extract_numbers(article_text)} quotes={_extract_quotes(article_text)}"
            )
            verdict = "OK"
            corrected_article = ""
            display_text = article_text
            display_kind = "article"
        else:
            t_fc_start = perf_counter()
            log_and_print(logger, f"\nğŸ” ì‚¬ì‹¤ê´€ê³„ ê²€ì¦ ë‹¨ê³„: check_LLM.check_article_facts í˜¸ì¶œ")
            check_res = check_LLM.check_article_facts(
                article_text,
                body,
                (keyword or "check_LLM"),
                source_url=url,                  # ì›ë¬¸ ë§í¬ ì „ë‹¬ (ë¡œê¹…/ì¶”ì ìš©)
                published_kst=published_kst,     # ì‹œì œ ì°¸ê³ ìš©
            )
            t_factcheck = perf_counter() - t_fc_start
            log_and_print(logger, f"â± ì‚¬ì‹¤ê²€ì¦ ì†Œìš”: {t_factcheck:.2f}s")

            verdict = ""
            corrected_article = ""
            explanation = ""
            if isinstance(check_res, dict):
                json_obj = check_res.get("json")
                explanation = check_res.get("explanation", "")
                if json_obj:
                    if isinstance(json_obj, str):
                        try:
                            parsed = json.loads(json_obj)
                        except Exception:
                            parsed = None
                        if isinstance(parsed, dict):
                            verdict_val = parsed.get("verdict", "")
                            corrected_article_val = parsed.get("corrected_article", "")
                        else:
                            verdict_val = ""
                            corrected_article_val = ""
                    else:
                        verdict_val = json_obj.get("verdict", "")
                        corrected_article_val = json_obj.get("corrected_article", "")
                    verdict = str(verdict_val or "").strip().upper()
                    corrected_article = str(corrected_article_val or "").strip()

            if _is_fact_ok_text(verdict):
                display_text = article_text
                display_kind = "article"
                log_and_print(logger, "  âœ… ì‚¬ì‹¤ê´€ê³„ ì´ìƒ ì—†ìŒ â†’ ê¸°ì‚¬ ì±„íƒ")
            else:
                if verdict == "ERROR" and corrected_article:
                    display_text = corrected_article
                    display_kind = "article"
                    log_and_print(logger, "  âœï¸ ì˜¤ë¥˜ ë°œê²¬ + êµì •ë³¸ ì œê³µ â†’ êµì • ê¸°ì‚¬ ì±„íƒ")
                else:
                    warn = "[ì‚¬ì‹¤ê²€ì¦]\nê²€ì¦ ê²½ê³  ë˜ëŠ” íŒŒì‹± ì‹¤íŒ¨\n\n" + (explanation or "ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    display_text = warn
                    display_kind = "fact_check"
                    log_and_print(logger, "  âš ï¸ ì‚¬ì‹¤ê´€ê³„ ì´ìŠˆ ë˜ëŠ” ê²€ì¦ ì‹¤íŒ¨ â†’ fact_check í‘œì¶œ")

        result = {
            "url": url,
            "keyword": keyword,
            "title": title,
            "original_body": body,
            "generated_article": article_text,
            "fact_check_result": verdict or "UNKNOWN",
            "corrected_article": corrected_article if not FAST_MODE else "",
            "display_text": display_text,
            "display_kind": display_kind,
            "error": None
        }

        log_and_print(logger, f"\nğŸ“‹ display_kind: {display_kind}")
        t_total = perf_counter() - t_total_start
        log_and_print(logger, f"â± ì´ ì²˜ë¦¬ ì‹œê°„: {t_total:.2f}s")
        log_and_print(logger, "\n" + "="*80)
        log_and_print(logger, "ğŸ“° NEWS_LLM - ê¸°ì‚¬ ì¬êµ¬ì„± ì™„ë£Œ")
        log_and_print(logger, "="*80)

        return result

    except Exception as e:
        try:
            log_and_print(logger, f"\nâŒ ì˜ˆì™¸ ë°œìƒ: {str(e)}", "error")
            t_total = perf_counter() - t_total_start
            log_and_print(logger, f"â± ì´ ì²˜ë¦¬ ì‹œê°„(ì˜ˆì™¸ ë°œìƒ): {t_total:.2f}s", "error")
            log_and_print(logger, "\n" + "="*80, "error")
            log_and_print(logger, "ğŸ“° NEWS_LLM - ê¸°ì‚¬ ì¬êµ¬ì„± ì‹¤íŒ¨", "error")
            log_and_print(logger, "="*80, "error")
        except Exception:
            pass

        return {
            "url": state.get("url"),
            "keyword": state.get("keyword"),
            "title": state.get("title") or "",
            "original_body": state.get("body") or "",
            "generated_article": "",
            "fact_check_result": "",
            "display_text": f"ì˜¤ë¥˜: {str(e)}",
            "display_kind": "error",
            "error": str(e)
        }

if __name__ == "__main__":
    print("ğŸ”— ê¸°ì‚¬ URLê³¼ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ Geminiê°€ ì¬ì‘ì„±í•œ ê¸°ì‚¬ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.")
    url = input("ê¸°ì‚¬ URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    keyword = input("í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

    print(f"\nğŸ“ í‚¤ì›Œë“œ: {keyword}")
    print(f"ğŸ”— URL: {url}")
    print("="*50)
    print("ì²˜ë¦¬ ê³¼ì •ì´ ì‹œì‘ë©ë‹ˆë‹¤. ëª¨ë“  ê³¼ì •ì€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.")
    print("="*50)

    result = generate_article({"url": url, "keyword": keyword})

    if result["error"]:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", result["error"])
    else:
        print("\nâœ… ê²°ê³¼:\n")
        print(result["display_text"])
        print(f"\nğŸ“ ë¡œê·¸ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
